{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3328d63d-4ec3-4c22-b4b0-7cb48450c0ef",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Reinforcement Learning - Sutton and Barto\n",
    "# Exercise 7.2\n",
    "\n",
    "n-step TD Methods Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb34b0a7-000d-4ec4-ac03-6559d69b9462",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from RandomWalk import randomwalk\n",
    "import n_step_TD as agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336514a4-6658-4a20-9616-9f28d0bd85f2",
   "metadata": {},
   "source": [
    "# Random Walk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a7e774-aa3c-4ad8-b58d-e7471df0911d",
   "metadata": {},
   "source": [
    "## Initialize Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a735ab69-91e7-4069-bdd4-5792926319a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actions: [array([0, 1]), array([ 0, -1])]\n"
     ]
    }
   ],
   "source": [
    "env = randomwalk()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ecffac0a-15cc-4259-a2d4-3c41114474ef",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\users\\cafaya\\OneDrive - Emerson\\Documents\\MyTrainings\\AI_Training\\RL_Sutton_Barton_Studies\\Chapter 7\\RandomWalk.py:92: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "  self.ax.set_xticklabels([\"0\", \"T\", \"A\", \"B\", \"C\", \"D\", \"E\", \"T\"])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAi8AAAB4CAYAAAA6wBIiAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAARRklEQVR4nO3de1DU9cLH8c8isl6CRUEuGhIeFQgvJ9cpsWPmJYRGp8x6aJoon9Jy6E6NZffsQtNYw2kSzUIZy2morJlKh+Kph6YzYpRS2QkZ6+hAHFZFEfESqOzzh7KP6y6oJ3Z/fOX9YnZgv/td/PCd3w8+/va3uza32+0WAACAIUKsDgAAAHA+KC8AAMAolBcAAGAUygsAADAK5QUAABiF8gIAAIxCeQEAAEahvAAAAKNQXgAAgFEoLwAAwChBKS+FhYVKSkpSv3795HQ69c0333Q6t7y8XDabzeeyffv2YEQFAAA9XMDLS0lJiR588EE98cQTqqqq0pQpU5SVlaXa2tou71dTU6OGhgbPZdSoUYGOCgAADGAL9BszXnHFFZowYYJWrFjhGUtNTdX111+v/Px8n/nl5eWaNm2ampqaFBkZGchoAADAQKGB/OZtbW3asmWLHnvsMa/xjIwMbdq0qcv7XnbZZfrjjz906aWX6sknn9S0adP8zmttbVVra6vnent7u/bv36+oqCjZbLY//0MAAICAc7vdamlp0dChQxUS0vUDQwEtL42NjTpx4oRiY2O9xmNjY+VyufzeJz4+XqtWrZLT6VRra6veeecdzZgxQ+Xl5brqqqt85ufn5+u5554LSH4AABBcdXV1uvjii7ucE9Dy0uHMIyBut7vToyLJyclKTk72XE9PT1ddXZ2WLVvmt7wsWbJEeXl5nuvNzc0aPny46uqkiIhu+gEuEL/9Jr355t0aNGiQ1VF6nKamJklibfz4r5dfliT9xeIcPdHiu++WxHbjD/tU515uOrlPiaXxtlvSGik8PPysUwNaXqKjo9WnTx+foyx79uzxORrTlUmTJundd9/1e5vdbpfdbvcZj4igvJwpPFwKCwtTv379rI7S44SFhUkSa+NHx68RdidfbDedY226EHbqM0vj7dS6nMspHwF9tlFYWJicTqfKysq8xsvKyjR58uRz/j5VVVWKj4/v7ngAAMBAAX/YKC8vTzk5OZo4caLS09O1atUq1dbWatGiRZJOPuxTX1+vtWvXSpIKCgp0ySWXKC0tTW1tbXr33Xe1fv16rV+/PtBRAQCAAQJeXrKzs7Vv3z4tXbpUDQ0NGjNmjDZu3KjExERJUkNDg9drvrS1temRRx5RfX29+vfvr7S0NG3YsEHXXnttoKMCAAADBOWE3dzcXOXm5vq9rbi42Ov64sWLtXjx4iCkAgAAJuK9jQAAgFEoLwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjEJ5AQAARqG8AAAAo1BeAACAUSgvAADAKJQXAABgFMoLAAAwCuUFAAAYhfICAACMQnkBAABGobwAAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK5QUAABgl1OoAF6q2tjB99dV0/fOfaTp6tL+ioxv1t7/9Q2PG/Gx1NABALxemME3VVMWd+hiogSo/9WECykuAlJRk69//HqoZM/5HUVH7tG3bWK1ff6PcbpvGjt1mdTwAQC82QAPklFMuubRd2+WU0+pI54XyEgA7dozSv/71F91ww4caO/bkkZakpF1qbo5UWdk1Skv7WSEhbotTAgB6qwM6oJf1sqT/LzImCco5L4WFhUpKSlK/fv3kdDr1zTffdDn/66+/ltPpVL9+/TRixAitXLkyGDG7TXV1isLCWpWW9ovX+F//WqWWlgjV119sUTLAXO2SvpRULOlrSdR/oPcKeHkpKSnRgw8+qCeeeEJVVVWaMmWKsrKyVFtb63f+zp07de2112rKlCmqqqrS448/rvvvv1/r168PdNRus3dvjKKjGxUS0u41Hhu7W5K0Z0+MFbEAY1VKSpI0U9J/S7pa0mhJPAAL9E4BLy+vvfaa7rzzTi1YsECpqakqKChQQkKCVqxY4Xf+ypUrNXz4cBUUFCg1NVULFizQHXfcoWXLlgU6arc5cmSA+vc/6jPeMXbkSP9gRwKMVa+TpaX+jPGdOlli9gU7EADLBbS8tLW1acuWLcrIyPAaz8jI0KZNm/zep6Kiwmf+rFmz9P333+vYsWMBy9rdbLbOD2rbbEEMAhhupaQjkk6cMX5C0gFJa4IdCIDlAlpeGhsbdeLECcXGxnqNx8bGyuVy+b2Py+XyO//48eNqbGz0md/a2qqDBw96Xaw2YMARHTkywGf86NGTR1z8HZUB4N/X8i0uHdyS/hHELAB6hqCcsGs741CD2+32GTvbfH/jkpSfny+Hw+G5JCQkdEPiPycmZo8aG6PV3u69vHv2xHpuB3BuBqjzX1QhkngQFuh9AlpeoqOj1adPH5+jLHv27PE5utIhLi7O7/zQ0FBFRUX5zF+yZImam5s9l7q6uu77Af5DKSnVamuz65dfUr3Gf/xxvMLDD2rYsN8tSgaY5yadfKaRPyckzQtiFgA9Q0Bf5yUsLExOp1NlZWWaO3euZ7ysrEzXXXed3/ukp6fr008/9Rr74osvNHHiRPXt29dnvt1ul91u797gf9KoUb9qxIjftGHDbLW22jV48H79/PNY/frrKM2du57XeAHOwy2SCiX9KO+Hj0IkXSnJ/28SAGczUiMVdupDkoZoiC7VpZKkHdqhY+q555kG/EXq8vLylJOTo4kTJyo9PV2rVq1SbW2tFi1aJOnkkZP6+nqtXbtWkrRo0SK98cYbysvL08KFC1VRUaGioiK99957gY7arbKzS/Tll9NVXj7N8/YA8+Z9yNsDAOepv6T/lfSUpCJJhyVFSLpb0rOSfP9LA+BczNZsRSrScz3t1IckFahAB3TAmmDnIODlJTs7W/v27dPSpUvV0NCgMWPGaOPGjUpMTJQkNTQ0eL3mS1JSkjZu3KiHHnpIy5cv19ChQ/X6669r3jyzDg6HhbUpK6tUWVmlVkcBjBch6e+Slkk6KMkhXh4c+LMKVGB1hP9YUPb/3Nxc5ebm+r2tuLjYZ2zq1KnaunVrgFMBME1fSb5nvgHobYLybCMAAIDuQnkBAABGobwAAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK5QUAABiF8gIAAIxCeQEAAEahvAAAAKNQXgAAgFEoLwAAwCiUFwAAYBTKCwAAMArlBQAAGIXyAgAAjEJ5AQAARqG8AAAAo1BeAACAUSgvAADAKJQXAABgFMoLAAAwCuUFAAAYhfICAACMEtDy0tTUpJycHDkcDjkcDuXk5OjAgQNd3mf+/Pmy2Wxel0mTJgUyJgAAMEhoIL/5Lbfcot9//12lpaWSpLvuuks5OTn69NNPu7xfZmam1qxZ47keFhYWyJgAAMAgASsv1dXVKi0t1ebNm3XFFVdIkt566y2lp6erpqZGycnJnd7XbrcrLi4uUNEAAIDBAlZeKioq5HA4PMVFkiZNmiSHw6FNmzZ1WV7Ky8sVExOjyMhITZ06VS+++KJiYmL8zm1tbVVra6vnenNzsyTp4MFu+kEuIC0tUltbm/744w+ro/Q4bW1tksTa+NFy6jO7lC+2m86xNl1oO/WZpfF2al3cbvdZpwasvLhcLr+FIyYmRi6Xq9P7ZWVl6aabblJiYqJ27typp556StOnT9eWLVtkt9t95ufn5+u5557zGU9I+HP5L1xvWh0AhnnZ6gA92ZvsT0B3a2lpkcPh6HLOeZeXZ5991m9ZON13330nSbLZbD63ud1uv+MdsrOzPV+PGTNGEydOVGJiojZs2KAbbrjBZ/6SJUuUl5fnud7e3q79+/crKiqqy38nWA4ePKiEhATV1dUpIiLC6jg9CmvTOdbGP9alc6xN51ibzvWktXG73WppadHQoUPPOve8y8u9996rm2++ucs5l1xyiX766Sft3r3b57a9e/cqNjb2nP+9+Ph4JSYmaseOHX5vt9vtPkdkIiMjz/n7B0tERITlG0ZPxdp0jrXxj3XpHGvTOdamcz1lbc52xKXDeZeX6OhoRUdHn3Veenq6mpubVVlZqcsvv1yS9O2336q5uVmTJ08+539v3759qqurU3x8/PlGBQAAF6CAvc5LamqqMjMztXDhQm3evFmbN2/WwoULNXv2bK+TdVNSUvTxxx9Lkg4dOqRHHnlEFRUV2rVrl8rLyzVnzhxFR0dr7ty5gYoKAAAMEtAXqVu3bp3Gjh2rjIwMZWRkaNy4cXrnnXe85tTU1HieIdSnTx9t27ZN1113nUaPHq3bb79do0ePVkVFhcLDwwMZNWDsdrueeeYZvycb93asTedYG/9Yl86xNp1jbTpn6trY3OfynCQAAIAegvc2AgAARqG8AAAAo1BeAACAUSgvAADAKJSXALDZbF1e5s+fb3VEy23atEl9+vRRZmam1VF6jPnz53ttJ1FRUcrMzNRPP/1kdbQeweVy6b777tOIESNkt9uVkJCgOXPm6Msvv7Q6mmVO32b69u2r2NhYXXPNNVq9erXa29utjme5M/epjktv/71zIfyNCth7G/VmDQ0Nnq9LSkr09NNPq6amxjPWv39/K2L1KKtXr9Z9992nt99+W7W1tRo+fLjVkXqEzMxMrVmzRtLJP9ZPPvmkZs+erdraWouTWWvXrl268sorFRkZqVdeeUXjxo3TsWPH9Pnnn+uee+7R9u3brY5omY5t5sSJE9q9e7dKS0v1wAMP6MMPP9Qnn3yi0NDe/Wv+9H2qg2lPC+5uF8LfqN69VQdIXFyc52uHwyGbzeY11tsdPnxY77//vr777ju5XC4VFxfr6aeftjpWj2C32z3bSlxcnB599FFdddVV2rt3r4YMGWJxOuvk5ubKZrOpsrJSAwcO9IynpaXpjjvusDCZ9U7fZoYNG6YJEyZo0qRJmjFjhoqLi7VgwQKLE1rr9PXBSRfC3ygeNkLQlZSUKDk5WcnJybr11lu1Zs2ac3oL9N7m0KFDWrdunUaOHKmoqCir41hm//79Ki0t1T333ONVXDr0xPcys9r06dM1fvx4ffTRR1ZHAQKC8oKgKyoq0q233irp5CHdQ4cO9erzFk732Wef6aKLLtJFF12k8PBwffLJJyopKVFISO/dVX/99Ve53W6lpKRYHcUoKSkp2rVrl9UxLHf6PtVxef75562OhT+Jh40QVDU1NaqsrPT8jzA0NFTZ2dlavXq1Zs6caXE6602bNk0rVqyQdPKIQ2FhobKyslRZWanExESL01mj46iczWazOIlZ3G43aybvfarD4MGDLUqD7kJ5QVAVFRXp+PHjGjZsmGfM7Xarb9++ampq0qBBgyxMZ72BAwdq5MiRnutOp1MOh0NvvfWWXnjhBQuTWWfUqFGy2Wyqrq7W9ddfb3UcY1RXVyspKcnqGJY7c5/ChaH3HotG0B0/flxr167Vq6++qh9++MFz+fHHH5WYmKh169ZZHbHHsdlsCgkJ0dGjR62OYpnBgwdr1qxZWr58uQ4fPuxz+4EDB4Ifqof76quvtG3bNs2bN8/qKEBAcOQFQfPZZ5+pqalJd955pxwOh9dtN954o4qKinTvvfdalK5naG1tlcvlkiQ1NTXpjTfe0KFDhzRnzhyLk1mrsLBQkydP1uWXX66lS5dq3LhxOn78uMrKyrRixQpVV1dbHdEyHdvM6U+Vzs/P1+zZs3XbbbdZHc9yp+9THUJDQxUdHW1RInQHyguCpqioSDNnzvQpLpI0b948vfTSS9q6dasmTJhgQbqeobS0VPHx8ZKk8PBwpaSk6IMPPtDVV19tbTCLJSUlaevWrXrxxRf18MMPq6GhQUOGDJHT6fQ5n6G36dhmQkNDNWjQII0fP16vv/66br/99l59oneH0/epDsnJyb36tYEuBDY3z1EFAAAGoZYDAACjUF4AAIBRKC8AAMAolBcAAGAUygsAADAK5QUAABiF8gIAAIxCeQEAAEahvAAAAKNQXgAAgFEoLwAAwCiUFwAAYJT/A4dL5S1HFPhWAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "env.render()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191f8ba3-ef87-41b6-b29a-dc14a3285688",
   "metadata": {},
   "source": [
    "## Test the policy $\\pi(s)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d5eefa68-d5e4-4a6a-a98c-1776b118e5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action taken: 0\n",
      "Action taken: 1\n",
      "Action taken: 0\n",
      "Action taken: 1\n",
      "Action taken: 0\n",
      "Action taken: 0\n",
      "Action taken: 0\n",
      "Action taken: 1\n",
      "Action taken: 0\n",
      "Action taken: 1\n"
     ]
    }
   ],
   "source": [
    "for i in range (10):\n",
    "    action = env.policy()\n",
    "    print(f\"Action taken: {action}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ccd79d7-3da3-4fb9-90ce-e9d91b86d0eb",
   "metadata": {},
   "source": [
    "# Execute both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65023c94-dd3f-4d25-b7a9-a8fb806643dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "State Values: [[0.  0.5 0.5 0.5 0.5 0.5 0. ]]\n"
     ]
    }
   ],
   "source": [
    "size = env.observation_space[1]\n",
    "\n",
    "n = 4\n",
    "state_values = agent.initialize_state_values((env.observation_space[0],env.observation_space[1]))\n",
    "print(f\"State Values: {state_values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4454dc92-6fb0-4d92-90c0-797de87b481c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1 Finished | Average Steps: 14.0\n",
      "Episode: 2 Finished | Average Steps: 14.0\n",
      "Episode: 3 Finished | Average Steps: 14.0\n",
      "Episode: 4 Finished | Average Steps: 12.0\n",
      "Episode: 5 Finished | Average Steps: 14.0\n",
      "Episode: 6 Finished | Average Steps: 18.0\n",
      "Episode: 7 Finished | Average Steps: 16.0\n",
      "Episode: 8 Finished | Average Steps: 6.0\n",
      "Episode: 9 Finished | Average Steps: 8.0\n",
      "Episode: 10 Finished | Average Steps: 8.0\n",
      "alpha: 0.1\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 124\n",
      "Total Average of Steps Per Episode: 12.4\n"
     ]
    }
   ],
   "source": [
    "n_step_td_history = agent.n_step_td_estimating(env, state_values, episodes=10, n=n, alpha=0.1, debug=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d7cccdd-b0cd-4777-9ba7-54dae55eed07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.45 , 0.405, 0.45 , 0.5  , 0.5  ]),\n",
       " array([0.405  , 0.37305, 0.405  , 0.45   , 0.5    ]),\n",
       " array([0.3645    , 0.34890345, 0.3645    , 0.39939034, 0.5       ]),\n",
       " array([0.3645    , 0.41810254, 0.440245  , 0.45490749, 0.55      ]),\n",
       " array([0.32805   , 0.33866306, 0.38940345, 0.451227  , 0.55      ]),\n",
       " array([0.29971767, 0.27431708, 0.33997167, 0.4399706 , 0.55      ]),\n",
       " array([0.29971767, 0.30264383, 0.42487705, 0.53295825, 0.595     ]),\n",
       " array([0.29971767, 0.30264383, 0.48238934, 0.57966243, 0.6355    ]),\n",
       " array([0.24277131, 0.2451415 , 0.46412218, 0.57966243, 0.6355    ]),\n",
       " array([0.24277131, 0.2451415 , 0.53313396, 0.65952657, 0.67195   ])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_step_td_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75c20229-9da9-4bc9-b49e-d0fcf4e18e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_values = agent.initialize_state_values((env.observation_space[0],env.observation_space[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4275232-177e-4dbe-81b3-8030c17d985f",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Step: 0\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 5\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 6\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 1-5: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 2-6: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5\n",
      "Transitions 4-7: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 4-7: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0\n",
      "Transitions 5-7: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 5-7: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.5\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -2.0\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -2.0\n",
      "err_sum: -2.0 | State Value [0 3]: 0.3\n",
      "Transitions 1-5: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 2-6: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3\n",
      "Transitions 4-7: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 4-7: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8\n",
      "Transitions 5-7: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 5-7: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.8\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -1.8\n",
      "err_sum: -1.8 | State Value [0 2]: 0.31999999999999995\n",
      "Transitions 2-6: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.11999999999999994\n",
      "Transitions 4-7: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 4-7: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6199999999999999\n",
      "Transitions 5-7: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 5-7: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9399999999999998\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.44\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -1.44\n",
      "err_sum: -1.44 | State Value [0 3]: 0.156\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.31999999999999995\n",
      "Transitions 4-7: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 4-7: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.82\n",
      "Transitions 5-7: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 5-7: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.14\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.64\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -1.64\n",
      "err_sum: -1.64 | State Value [0 2]: 0.15599999999999994\n",
      "Transitions 4-7: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 4-7: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5\n",
      "Transitions 5-7: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 5-7: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6559999999999999\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.156\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -1.156\n",
      "err_sum: -1.156 | State Value [0 1]: 0.3844\n",
      "Transitions 5-7: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 5-7: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.15599999999999994\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5404\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -0.5404\n",
      "err_sum: -0.5404 | State Value [0 2]: 0.10195999999999994\n",
      "Transitions 6-7: [array([0, 1]), array([0, 0])]\n",
      "Rewards 6-7: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3844\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: -0.3844\n",
      "err_sum: -0.3844 | State Value [0 1]: 0.34596000000000005\n",
      "Transitions 7-7: [array([0, 0])]\n",
      "Rewards 7-7: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "State_Values: [[0.      0.34596 0.10196 0.156   0.5     0.5     0.     ]]\n",
      "State_Values: [0.34596 0.10196 0.156   0.5     0.5    ]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 5\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 6\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 7\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 8\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 9\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 10\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 11\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 12\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.18996000000000005\n",
      "Transitions 1-5: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20808000000000001\n",
      "Transitions 2-6: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20808000000000001\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20808000000000001\n",
      "Transitions 4-8: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20808000000000001\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20808000000000001\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.01811999999999997\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.01811999999999997\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.01811999999999997\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.12007999999999991\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.46603999999999995\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5679999999999998\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9139599999999999\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.9139599999999999\n",
      "err_sum: -0.9139599999999999 | State Value [0 3]: 0.06460400000000001\n",
      "Transitions 1-5: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.39804000000000006\n",
      "Transitions 2-6: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.39804000000000006\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.39804000000000006\n",
      "Transitions 4-8: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.39804000000000006\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.39804000000000006\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.11668400000000001\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.11668400000000001\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.11668400000000001\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.21864399999999995\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.564604\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6665639999999999\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.012524\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -1.012524\n",
      "err_sum: -1.012524 | State Value [0 4]: 0.3987476\n",
      "Transitions 2-6: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.28135600000000005\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.28135600000000005\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.28135600000000005\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.1793960000000001\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.16656399999999993\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2685239999999999\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6144839999999999\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.6144839999999999\n",
      "err_sum: -0.6144839999999999 | State Value [0 3]: 0.0031556000000000153\n",
      "Transitions 3-7: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3428044\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3428044\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3428044\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.24084440000000007\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.10511559999999998\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20707559999999992\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5530356\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.5530356\n",
      "err_sum: -0.5530356 | State Value [0 2]: 0.04665643999999994\n",
      "Transitions 4-8: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3428044\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3428044\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3428044\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2961479600000001\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.049812039999999946\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.09646847999999988\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.4424284799999999\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.4424284799999999\n",
      "err_sum: -0.4424284799999999 | State Value [0 1]: 0.30171715200000004\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.298561552\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.298561552\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.298561552\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2519051120000001\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.049812039999999946\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.09646847999999988\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3981856319999999\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.3981856319999999\n",
      "err_sum: -0.3981856319999999 | State Value [0 2]: 0.006837876799999948\n",
      "Transitions 6-10: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.298561552\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.298561552\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.298561552\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2917236752000001\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.009993476799999956\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.016831353599999904\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3185485055999999\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.3185485055999999\n",
      "err_sum: -0.3185485055999999 | State Value [0 3]: -0.02869925055999998\n",
      "Transitions 7-11: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.006837876799999948\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.30855502879999996\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3153929055999999\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6171100575999999\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.6171100575999999\n",
      "err_sum: -0.6171100575999999 | State Value [0 2]: -0.054873128960000045\n",
      "Transitions 8-12: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.054873128960000045\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.24684402304\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.19197089407999995\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.49368804608\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.49368804608\n",
      "err_sum: -0.49368804608 | State Value [0 1]: 0.25234834739200007\n",
      "Transitions 9-13: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.054873128960000045\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.19747521843200003\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.14260208947199998\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.39495043686400005\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.39495043686400005\n",
      "err_sum: -0.39495043686400005 | State Value [0 2]: -0.09436817264640004\n",
      "Transitions 10-13: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 10-13: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.25234834739200007\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.15798017474560003\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.41032852213760007\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.41032852213760007\n",
      "err_sum: -0.41032852213760007 | State Value [0 1]: 0.21131549517824005\n",
      "Transitions 11-13: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-13: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.09436817264640004\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.11694732253184001\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.11694732253184001\n",
      "err_sum: -0.11694732253184001 | State Value [0 2]: -0.10606290489958405\n",
      "Transitions 12-13: [array([0, 1]), array([0, 0])]\n",
      "Rewards 12-13: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.21131549517824005\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: -0.21131549517824005\n",
      "err_sum: -0.21131549517824005 | State Value [0 1]: 0.19018394566041605\n",
      "Transitions 13-13: [array([0, 0])]\n",
      "Rewards 13-13: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "State_Values: [[ 0.          0.19018395 -0.1060629  -0.02869925  0.3987476   0.5\n",
      "   0.        ]]\n",
      "State_Values: [ 0.19018395 -0.1060629  -0.02869925  0.3987476   0.5       ]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "Transitions 0-3: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 0-3: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.02869925055999998\n",
      "Transitions 1-3: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-3: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.13476215545958403\n",
      "Transitions 2-3: [array([0, 1]), array([0, 0])]\n",
      "Rewards 2-3: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.055421790200832016\n",
      "Transitions 3-3: [array([0, 0])]\n",
      "Rewards 3-3: [0]\n",
      "err_sum: -0.055421790200832016\n",
      "err_sum: -0.055421790200832016 | State Value [0 3]: -0.03424142958008318\n",
      "Transitions 1-3: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-3: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.10606290489958405\n",
      "Transitions 2-3: [array([0, 1]), array([0, 0])]\n",
      "Rewards 2-3: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.084121040760832\n",
      "Transitions 3-3: [array([0, 0])]\n",
      "Rewards 3-3: [0]\n",
      "err_sum: -0.084121040760832\n",
      "err_sum: -0.084121040760832 | State Value [0 2]: -0.11447500897566724\n",
      "Transitions 2-3: [array([0, 1]), array([0, 0])]\n",
      "Rewards 2-3: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.19018394566041605\n",
      "Transitions 3-3: [array([0, 0])]\n",
      "Rewards 3-3: [0]\n",
      "err_sum: -0.19018394566041605\n",
      "err_sum: -0.19018394566041605 | State Value [0 1]: 0.17116555109437445\n",
      "Transitions 3-3: [array([0, 0])]\n",
      "Rewards 3-3: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 3 Finished | Average Steps: 3.0\n",
      "State_Values: [[ 0.          0.17116555 -0.11447501 -0.03424143  0.3987476   0.5\n",
      "   0.        ]]\n",
      "State_Values: [ 0.17116555 -0.11447501 -0.03424143  0.3987476   0.5       ]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 5\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 6\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 7\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 8\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 9\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 10\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 11\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 12\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 13\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 14\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 15\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 16\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 17\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 18\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 19\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 20\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 21\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 22\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 1-5: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 2-6: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 3-7: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8420570578812927\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3552796668569598\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3552796668569598\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3552796668569598\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.5606866475314174\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0474640385557503\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.6012524\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.6354938295800832\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.236746229580083\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.736746229580083\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.736746229580083\n",
      "err_sum: 2.736746229580083 | State Value [0 3]: 0.23943319337792512\n",
      "Transitions 1-5: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 2-6: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7737894155977421\n",
      "Transitions 3-7: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7737894155977421\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7737894155977421\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7737894155977421\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7737894155977421\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7737894155977421\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756672\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8420570578812927\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3552796668569598\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3552796668569598\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3552796668569598\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.2870120245734091\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.773789415597742\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5132226089756671\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.6012524000000001\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.3618192066220751\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.963071606622075\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.463071606622075\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.463071606622075\n",
      "err_sum: 2.463071606622075 | State Value [0 4]: 0.6450547606622075\n",
      "Transitions 2-6: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2605668066220749\n",
      "Transitions 3-7: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2605668066220749\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2605668066220749\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2605668066220749\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2605668066220749\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.2605668066220749\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.7595297696378747\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.7595297696378747\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3288344489056255\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0883642185435\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0883642185435\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0883642185435\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0200965762599494\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.26056680662207476\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1102230246251565e-16\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.1144750089756674\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.8750418155977422\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.2299870549355347\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.7299870549355347\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.7299870549355347\n",
      "err_sum: 2.7299870549355347 | State Value [0 5]: 0.7729987054935534\n",
      "Transitions 3-7: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.5335655121156283\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.2930952817535029\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.2930952817535029\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.5335655121156282\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.06826764228355076\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8277974119214254\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8277974119214254\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8277974119214254\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7595297696378748\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1102230246251565e-16\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.5335655121156282\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.6480405210912954\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.40860732771337\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.7635525670511627\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.9905538615576095\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.9905538615576095\n",
      "err_sum: 2.9905538615576095 | State Value [0 4]: 0.9441101468179685\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.5335655121156283\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.592150667909264\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.592150667909264\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.5335655121156284\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.06826764228355053\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.126852798077186\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.126852798077186\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.126852798077186\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0585851557936354\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.220446049250313e-16\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.5335655121156285\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.6480405210912958\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.4086073277133706\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.4644971808954024\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.6914984754018487\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.6914984754018487\n",
      "err_sum: 2.6914984754018487 | State Value [0 3]: 0.50858304091811\n",
      "Transitions 5-9: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2644156645754434\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.323000820369079\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.323000820369079\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2644156645754434\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.33741748982373554\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3960026456173713\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3960026456173713\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3960026456173713\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0585851557936357\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2644156645754434\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.3788906735511106\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.8703076326330006\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.9261974858150321\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.1531987803214787\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.1531987803214787\n",
      "err_sum: 2.1531987803214787 | State Value [0 2]: 0.10084486905648064\n",
      "Transitions 6-10: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2644156645754434\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1076809423369314\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1076809423369314\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2644156645754435\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.33741748982373543\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1806827675852234\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1806827675852234\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1806827675852234\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8432652777614879\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2644156645754434\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.1635707955189627\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.6549877546008527\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.7108776077828842\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.9378789022893308\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.9378789022893308\n",
      "err_sum: 1.9378789022893308 | State Value [0 3]: 0.7023709311470431\n",
      "Transitions 7-11: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.07062777434651035\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.9138930521079982\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.9138930521079982\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.07062777434651035\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5312053800526686\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3744706578141566\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3744706578141566\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3744706578141566\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.843265277761488\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1102230246251565e-16\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.07062777434651024\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.9697829052900296\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.2674119741429866\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.323301827325018\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.5503031218314647\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.5503031218314647\n",
      "err_sum: 1.5503031218314647 | State Value [0 4]: 1.099140459001115\n",
      "Transitions 8-12: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.07062777434651035\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.0689233642911447\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.0689233642911447\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.07062777434651035\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5312053800526686\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.529500969997303\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.529500969997303\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.529500969997303\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9982955899446344\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1102230246251565e-16\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.07062777434651024\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.9697829052900296\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.2674119741429866\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.1682715151418717\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.3952728096483182\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.3952728096483182\n",
      "err_sum: 1.3952728096483182 | State Value [0 3]: 0.8418982121118749\n",
      "Transitions 9-13: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.9982955899446343\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.9982955899446343\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.601833154399179\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6001287443438132\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6001287443438132\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6001287443438132\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9293960833263128\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.06889950661832145\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.8991551309435194\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.0572569188316445\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.9581164598305296\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.1851177543369762\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.1851177543369762\n",
      "err_sum: 1.1851177543369762 | State Value [0 2]: 0.21935664449017828\n",
      "Transitions 10-14: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8797838145109367\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4816169689101155\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.361400783421052\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.361400783421052\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.361400783421052\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6906681224035518\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8108843078926151\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8797838145109366\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.09914045900111479\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.058961328887010334\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.040179130114104566\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.186822164392342\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 0.186822164392342\n",
      "err_sum: 0.186822164392342 | State Value [0 3]: 0.8605804285511091\n",
      "Transitions 11-15: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8797838145109367\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4816169689101155\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.361400783421052\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.361400783421052\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.361400783421052\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6719859059643176\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7922020914533809\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8797838145109366\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.09914045900111479\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.040279112447776155\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.058861346553338745\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.16813994795310783\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 0.16813994795310783\n",
      "err_sum: 0.16813994795310783 | State Value [0 4]: 1.1159544537964257\n",
      "Transitions 12-16: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 12-16: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.601833154399179\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4984309637054265\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4984309637054265\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4984309637054265\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8090160862486919\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.08758172305755552\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1102230246251565e-16\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.7806433555098217\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.9200629269587126\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.804108473162287\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.0311097676687335\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.0311097676687335\n",
      "err_sum: 1.0311097676687335 | State Value [0 5]: 0.8761096822604268\n",
      "Transitions 13-17: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 13-17: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8965978093062474\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8965978093062474\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8965978093062474\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.20718293184951286\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.6894148774567346\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.7049441311660524\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.485587486675874\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.625007058124765\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.5090526043283394\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.6329429220679126\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.6329429220679126\n",
      "err_sum: 1.6329429220679126 | State Value [0 4]: 1.279248746003217\n",
      "Transitions 14-18: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 14-18: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.6894148774567346\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.7493069789697733\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.764836232679091\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.545479588188913\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.684899159637804\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.405650413634587\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.5295407313741602\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.5295407313741602\n",
      "err_sum: 2.5295407313741602 | State Value [0 3]: 1.113534501688525\n",
      "Transitions 15-19: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 15-19: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.9423689505941505\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.002261052107189\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.764836232679091\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.545479588188913\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.431945086500388\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.152696340497171\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 2.276586658236744\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 2.276586658236744\n",
      "err_sum: 2.276586658236744 | State Value [0 2]: 0.4470153103138527\n",
      "Transitions 16-20: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards 16-20: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.9423689505941505\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.7746023862835147\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.5371775668554166\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 2.090162256541564\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.9766277548530389\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.697379008849822\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 1.821269326589395\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 1.821269326589395\n",
      "err_sum: 1.821269326589395 | State Value [0 1]: 0.353292483753314\n",
      "Transitions 17-21: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 17-21: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.8322334356893641\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.594808616261266\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.1477933059474132\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 1.0342588042588883\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.7550100582556714\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.8789003759952445\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 0.8789003759952445\n",
      "err_sum: 0.8789003759952445 | State Value [0 2]: 0.5349053479133772\n",
      "Transitions 18-22: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 18-22: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.23742481942809812\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.2276698326585247\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.11413533096999973\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.1651134150332172\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.04122309729364404\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: -0.04122309729364404\n",
      "err_sum: -0.04122309729364404 | State Value [0 3]: 1.1094121919591606\n",
      "Transitions 19-23: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 19-23: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.4650946520866228\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.3556824601274622\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.07643371412424527\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.20032403186381842\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 0.20032403186381842\n",
      "err_sum: 0.20032403186381842 | State Value [0 2]: 0.5549377510997591\n",
      "Transitions 20-23: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 20-23: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.10941219195916063\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.38866093796237755\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.2647706202228044\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: -0.2647706202228044\n",
      "err_sum: -0.2647706202228044 | State Value [0 3]: 1.0829351299368801\n",
      "Transitions 21-23: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 21-23: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.2792487460032169\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.15535842826364377\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: -0.15535842826364377\n",
      "err_sum: -0.15535842826364377 | State Value [0 4]: 1.2637129031768526\n",
      "Transitions 22-23: [array([0, 5]), array([0, 6])]\n",
      "Rewards 22-23: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.12389031773957315\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 0.12389031773957315\n",
      "err_sum: 0.12389031773957315 | State Value [0 5]: 0.8884987140343842\n",
      "Transitions 23-23: [array([0, 6])]\n",
      "Rewards 23-23: [1]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 6]: 0.0\n",
      "Episode: 4 Finished | Average Steps: 23.0\n",
      "State_Values: [[0.         0.35329248 0.55493775 1.08293513 1.2637129  0.88849871\n",
      "  0.        ]]\n",
      "State_Values: [0.35329248 0.55493775 1.08293513 1.2637129  0.88849871]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards: [0, 0, 0, 0, 0, 1]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 4]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.19443641590249594\n",
      "Transitions 1-5: [array([0, 4]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.4581493190793485\n",
      "Transitions 2-5: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 2-5: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.5410844490162287\n",
      "Transitions 3-5: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 3-5: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.8047973521930812\n",
      "Transitions 4-5: [array([0, 5]), array([0, 6])]\n",
      "Rewards 4-5: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.6932960662274654\n",
      "Transitions 5-5: [array([0, 6])]\n",
      "Rewards 5-5: [1]\n",
      "err_sum: -0.6932960662274654\n",
      "err_sum: -0.6932960662274654 | State Value [0 3]: 1.0136055233141337\n",
      "Transitions 1-5: [array([0, 4]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.2637129031768526\n",
      "Transitions 2-5: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 2-5: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.27731842649098626\n",
      "Transitions 3-5: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 3-5: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.5410313296678388\n",
      "Transitions 4-5: [array([0, 5]), array([0, 6])]\n",
      "Rewards 4-5: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.42953004370222303\n",
      "Transitions 5-5: [array([0, 6])]\n",
      "Rewards 5-5: [1]\n",
      "err_sum: -0.42953004370222303\n",
      "err_sum: -0.42953004370222303 | State Value [0 4]: 1.2207598988066304\n",
      "Transitions 2-5: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 2-5: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.013605523314133672\n",
      "Transitions 3-5: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 3-5: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.23436542212076406\n",
      "Transitions 4-5: [array([0, 5]), array([0, 6])]\n",
      "Rewards 4-5: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.12286413615514824\n",
      "Transitions 5-5: [array([0, 6])]\n",
      "Rewards 5-5: [1]\n",
      "err_sum: -0.12286413615514824\n",
      "err_sum: -0.12286413615514824 | State Value [0 3]: 1.001319109698619\n",
      "Transitions 3-5: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 3-5: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.22075989880663038\n",
      "Transitions 4-5: [array([0, 5]), array([0, 6])]\n",
      "Rewards 4-5: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.10925861284101457\n",
      "Transitions 5-5: [array([0, 6])]\n",
      "Rewards 5-5: [1]\n",
      "err_sum: -0.10925861284101457\n",
      "err_sum: -0.10925861284101457 | State Value [0 4]: 1.209834037522529\n",
      "Transitions 4-5: [array([0, 5]), array([0, 6])]\n",
      "Rewards 4-5: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.11150128596561582\n",
      "Transitions 5-5: [array([0, 6])]\n",
      "Rewards 5-5: [1]\n",
      "err_sum: 0.11150128596561582\n",
      "err_sum: 0.11150128596561582 | State Value [0 5]: 0.8996488426309458\n",
      "Transitions 5-5: [array([0, 6])]\n",
      "Rewards 5-5: [1]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 6]: 0.0\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "State_Values: [[0.         0.35329248 0.55493775 1.00131911 1.20983404 0.89964884\n",
      "  0.        ]]\n",
      "State_Values: [0.35329248 0.55493775 1.00131911 1.20983404 0.89964884]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]), array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6480266259453049\n",
      "Transitions 1-5: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.202964377045064\n",
      "Transitions 2-5: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.556256860798378\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.111194611898137\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -2.464487095651451\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: -2.464487095651451\n",
      "err_sum: -2.464487095651451 | State Value [0 3]: 0.7548704001334738\n",
      "Transitions 1-5: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5549377510997591\n",
      "Transitions 2-5: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9082302348530731\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4631679859528322\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.8164604697061462\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: -1.8164604697061462\n",
      "err_sum: -1.8164604697061462 | State Value [0 2]: 0.3732917041291445\n",
      "Transitions 2-5: [array([0, 1]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.353292483753314\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7265841878824585\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0798766716357724\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: -1.0798766716357724\n",
      "err_sum: -1.0798766716357724 | State Value [0 1]: 0.24530481658973677\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.3732917041291445\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6185965207188813\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: -0.6185965207188813\n",
      "err_sum: -0.6185965207188813 | State Value [0 2]: 0.3114320520572563\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.24530481658973677\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: -0.24530481658973677\n",
      "err_sum: -0.24530481658973677 | State Value [0 1]: 0.2207743349307631\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "State_Values: [[0.         0.22077433 0.31143205 0.7548704  1.20983404 0.89964884\n",
      "  0.        ]]\n",
      "State_Values: [0.22077433 0.31143205 0.7548704  1.20983404 0.89964884]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]), array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.7548704 , 1.20983404, 0.89964884])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards: [0, 0, 0, 1]\n",
      "Transitions 0-3: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 0-3: [0, 0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.24512959986652616\n",
      "Transitions 1-3: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 1-3: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: 0.03529556234399722\n",
      "Transitions 2-3: [array([0, 5]), array([0, 6])]\n",
      "Rewards 2-3: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.13564671971305142\n",
      "Transitions 3-3: [array([0, 6])]\n",
      "Rewards 3-3: [1]\n",
      "err_sum: 0.13564671971305142\n",
      "err_sum: 0.13564671971305142 | State Value [0 3]: 0.768435072104779\n",
      "Transitions 1-3: [array([0, 4]), array([0, 5]), array([0, 6])]\n",
      "Rewards 1-3: [0, 0, 1]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 1\n",
      "err_sum: -0.20983403752252894\n",
      "Transitions 2-3: [array([0, 5]), array([0, 6])]\n",
      "Rewards 2-3: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: -0.10948288015347474\n",
      "Transitions 3-3: [array([0, 6])]\n",
      "Rewards 3-3: [1]\n",
      "err_sum: -0.10948288015347474\n",
      "err_sum: -0.10948288015347474 | State Value [0 4]: 1.1988857495071814\n",
      "Transitions 2-3: [array([0, 5]), array([0, 6])]\n",
      "Rewards 2-3: [0, 1]\n",
      "n_step_reward: 1\n",
      "err_sum: 0.1003511573690542\n",
      "Transitions 3-3: [array([0, 6])]\n",
      "Rewards 3-3: [1]\n",
      "err_sum: 0.1003511573690542\n",
      "err_sum: 0.1003511573690542 | State Value [0 5]: 0.9096839583678512\n",
      "Transitions 3-3: [array([0, 6])]\n",
      "Rewards 3-3: [1]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 6]: 0.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "State_Values: [[0.         0.22077433 0.31143205 0.76843507 1.19888575 0.90968396\n",
      "  0.        ]]\n",
      "State_Values: [0.22077433 0.31143205 0.76843507 1.19888575 0.90968396]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]), array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.7548704 , 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.76843507, 1.19888575, 0.90968396])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 5\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 6\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 7\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 8\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 9\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 10\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 11\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 12\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 13\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 14\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 1-5: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 2-6: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 3-7: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.8874536974499251\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.5763633208870131\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.4638170183369383\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.4638170183369383\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.5763633208870131\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.887453697449925\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.31143205205725644\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0798671241620355\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.3912991762192917\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6120735111500548\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -1.6120735111500548\n",
      "err_sum: -1.6120735111500548 | State Value [0 3]: 0.6072277209897735\n",
      "Transitions 1-5: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 2-6: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 3-7: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.8874536974499251\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.5763633208870131\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.4638170183369383\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.4638170183369383\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.5763633208870131\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.887453697449925\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.31143205205725644\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.91865977304703\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.2300918251042863\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4508661600350494\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -1.4508661600350494\n",
      "err_sum: -1.4508661600350494 | State Value [0 2]: 0.16634543605375138\n",
      "Transitions 2-6: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 2-6: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 3-7: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.0325403134534301\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.7214499368905183\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.753990250343948\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.753990250343948\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.721449936890518\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.03254031345343\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.16634543605375152\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.773573157043525\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9399185930972764\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1606929280280396\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -1.1606929280280396\n",
      "err_sum: -1.1606929280280396 | State Value [0 1]: 0.10470504212795913\n",
      "Transitions 3-7: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2])]\n",
      "Rewards 3-7: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.0325403134534301\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.837519229693322\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.870059543146752\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.870059543146752\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.8375192296933218\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.03254031345343\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.16634543605375152\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.773573157043525\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9399185930972764\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.0446236352252356\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -1.0446236352252356\n",
      "err_sum: -1.0446236352252356 | State Value [0 2]: 0.06188307253122781\n",
      "Transitions 4-8: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3])]\n",
      "Rewards 4-8: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 5-9: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1370026769759536\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.9419815932158455\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 3.078984270191799\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 3.078984270191799\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.9419815932158453\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1370026769759534\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.061883072531228045\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6691107935210016\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7309938660522294\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8356989081801885\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -0.8356989081801885\n",
      "err_sum: -0.8356989081801885 | State Value [0 3]: 0.5236578301717547\n",
      "Transitions 5-9: [array([0, 2]), array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4])]\n",
      "Rewards 5-9: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1370026769759536\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.9419815932158455\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 3.078984270191799\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 3.078984270191799\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.9419815932158453\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1370026769759534\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.061883072531228045\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.5855409027029828\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6474239752342106\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7521290173621697\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -0.7521290173621697\n",
      "err_sum: -0.7521290173621697 | State Value [0 2]: -0.013329829204989166\n",
      "Transitions 6-10: [array([0, 1]), array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5])]\n",
      "Rewards 6-10: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.804978916239892\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.017194494952063\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 2.017194494952063\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.8049789162398922\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.1102230246251565e-16\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.1988857495071814\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.7225435796789361\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.7092137504739469\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.813918792601906\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -1.813918792601906\n",
      "err_sum: -1.813918792601906 | State Value [0 1]: -0.0766868371322315\n",
      "Transitions 7-11: [array([0, 2]), array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4])]\n",
      "Rewards 7-11: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.2122155787121707\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 1.2122155787121707\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9863707955000827\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.185256545007264\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.7089143751790186\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.6955845459740293\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -2.6188977088417977\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -2.6188977088417977\n",
      "err_sum: -2.6188977088417977 | State Value [0 2]: -0.27521960008916896\n",
      "Transitions 8-12: [array([0, 3]), array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3])]\n",
      "Rewards 8-12: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4741053495963503\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.460476145096433\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -3.6593618946036144\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -4.183019724775369\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -3.9078001246862004\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -3.831113287553969\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -3.831113287553969\n",
      "err_sum: -3.831113287553969 | State Value [0 3]: 0.14054650141635783\n",
      "Transitions 9-13: [array([0, 4]), array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2])]\n",
      "Rewards 9-13: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.4741053495963503\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -2.460476145096433\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -3.6593618946036144\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -3.799908396019972\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -3.5246887959308033\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -3.4480019587985717\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -3.4480019587985717\n",
      "err_sum: -3.4480019587985717 | State Value [0 4]: 0.8540855536273242\n",
      "Transitions 10-14: [array([0, 5]), array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 10-14: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.9863707955000827\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.8404563491274069\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.9810028505437647\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -1.7057832504545958\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -1.6290964133223642\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -1.6290964133223642\n",
      "err_sum: -1.6290964133223642 | State Value [0 5]: 0.7467743170356148\n",
      "Transitions 11-15: [array([0, 4]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 11-15: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.8540855536273242\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.994632055043682\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.7194124549545131\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.6427256178222817\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: -0.6427256178222817\n",
      "err_sum: -0.6427256178222817 | State Value [0 4]: 0.789812991845096\n",
      "Transitions 12-15: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 12-15: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.14054650141635783\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.13467309867281113\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.21135993580504264\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: 0.21135993580504264\n",
      "err_sum: 0.21135993580504264 | State Value [0 3]: 0.1616824949968621\n",
      "Transitions 13-15: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 13-15: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.27521960008916896\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.35190643722140047\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: 0.35190643722140047\n",
      "err_sum: 0.35190643722140047 | State Value [0 2]: -0.24002895636702892\n",
      "Transitions 14-15: [array([0, 1]), array([0, 0])]\n",
      "Rewards 14-15: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.0766868371322315\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: 0.0766868371322315\n",
      "err_sum: 0.0766868371322315 | State Value [0 1]: -0.06901815341900835\n",
      "Transitions 15-15: [array([0, 0])]\n",
      "Rewards 15-15: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "State_Values: [[ 0.         -0.06901815 -0.24002896  0.16168249  0.78981299  0.74677432\n",
      "   0.        ]]\n",
      "State_Values: [-0.06901815 -0.24002896  0.16168249  0.78981299  0.74677432]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]), array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.7548704 , 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.76843507, 1.19888575, 0.90968396]), array([-0.06901815, -0.24002896,  0.16168249,  0.78981299,  0.74677432])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.23070064841587046\n",
      "Transitions 1-5: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.009328307951158465\n",
      "Transitions 2-5: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.15235418704570364\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.08767476932132529\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.15669292274033364\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.15669292274033364\n",
      "err_sum: 0.15669292274033364 | State Value [0 3]: 0.17735178727089546\n",
      "Transitions 1-5: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.24002895636702892\n",
      "Transitions 2-5: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.06267716909613347\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.3027061254631624\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.37172427888217074\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.37172427888217074\n",
      "err_sum: 0.37172427888217074 | State Value [0 2]: -0.20285652847881186\n",
      "Transitions 2-5: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.17735178727089546\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.025504741207916404\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.09452289462692476\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.09452289462692476\n",
      "err_sum: 0.09452289462692476 | State Value [0 3]: 0.18680407673358793\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.20285652847881186\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2718746818978202\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.2718746818978202\n",
      "err_sum: 0.2718746818978202 | State Value [0 2]: -0.17566906028902984\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.06901815341900835\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.06901815341900835\n",
      "err_sum: 0.06901815341900835 | State Value [0 1]: -0.06211633807710752\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "State_Values: [[ 0.         -0.06211634 -0.17566906  0.18680408  0.78981299  0.74677432\n",
      "   0.        ]]\n",
      "State_Values: [-0.06211634 -0.17566906  0.18680408  0.78981299  0.74677432]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]), array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.7548704 , 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.76843507, 1.19888575, 0.90968396]), array([-0.06901815, -0.24002896,  0.16168249,  0.78981299,  0.74677432]), array([-0.06211634, -0.17566906,  0.18680408,  0.78981299,  0.74677432])]\n",
      "---------------------------\n",
      "Step: 0\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0]\n",
      "---------------------------\n",
      "Step: 1\n",
      "Action: 0\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3])]\n",
      "Rewards: [0, 0, 0]\n",
      "---------------------------\n",
      "Step: 2\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2])]\n",
      "Rewards: [0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 3\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards: [0, 0, 0, 0, 0]\n",
      "---------------------------\n",
      "Step: 4\n",
      "Action: 1\n",
      "Transitions: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards: [0, 0, 0, 0, 0, 0]\n",
      "Transitions 0-4: [array([0, 3]), array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1])]\n",
      "Rewards 0-4: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.24892041481069543\n",
      "Transitions 1-5: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.07325135452166559\n",
      "Transitions 2-5: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.26005543125525354\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.0843863709662237\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: -0.02227003288911618\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: -0.02227003288911618\n",
      "err_sum: -0.02227003288911618 | State Value [0 3]: 0.1845770734446763\n",
      "Transitions 1-5: [array([0, 2]), array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 1-5: [0, 0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.17566906028902984\n",
      "Transitions 2-5: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.00890801315564646\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.16676104713338338\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2288773852104909\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.2288773852104909\n",
      "err_sum: 0.2288773852104909 | State Value [0 2]: -0.15278132176798076\n",
      "Transitions 2-5: [array([0, 3]), array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 2-5: [0, 0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.1845770734446763\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: -0.031795751676695544\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.030320586400411978\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.030320586400411978\n",
      "err_sum: 0.030320586400411978 | State Value [0 3]: 0.1876091320847175\n",
      "Transitions 3-5: [array([0, 2]), array([0, 1]), array([0, 0])]\n",
      "Rewards 3-5: [0, 0, 0]\n",
      "n_step_reward: 0\n",
      "n_step_reward: 0\n",
      "err_sum: 0.15278132176798076\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.2148976598450883\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.2148976598450883\n",
      "err_sum: 0.2148976598450883 | State Value [0 2]: -0.13129155578347193\n",
      "Transitions 4-5: [array([0, 1]), array([0, 0])]\n",
      "Rewards 4-5: [0, 0]\n",
      "n_step_reward: 0\n",
      "err_sum: 0.06211633807710752\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.06211633807710752\n",
      "err_sum: 0.06211633807710752 | State Value [0 1]: -0.05590470426939677\n",
      "Transitions 5-5: [array([0, 0])]\n",
      "Rewards 5-5: [0]\n",
      "err_sum: 0.0\n",
      "err_sum: 0.0 | State Value [0 0]: 0.0\n",
      "Episode: 10 Finished | Average Steps: 5.0\n",
      "State_Values: [[ 0.         -0.0559047  -0.13129156  0.18760913  0.78981299  0.74677432\n",
      "   0.        ]]\n",
      "State_Values: [-0.0559047  -0.13129156  0.18760913  0.78981299  0.74677432]\n",
      "History: [array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]), array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]), array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]), array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]), array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.7548704 , 1.20983404, 0.89964884]), array([0.22077433, 0.31143205, 0.76843507, 1.19888575, 0.90968396]), array([-0.06901815, -0.24002896,  0.16168249,  0.78981299,  0.74677432]), array([-0.06211634, -0.17566906,  0.18680408,  0.78981299,  0.74677432]), array([-0.0559047 , -0.13129156,  0.18760913,  0.78981299,  0.74677432])]\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 84\n",
      "Total Average of Steps Per Episode: 8.4\n"
     ]
    }
   ],
   "source": [
    "td_err_history = agent.sum_td_errors_estimating(env, state_values, episodes=10, n=n, alpha=0.1, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd3b9d88-ce0a-43bf-86df-073bf90121c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.34596, 0.10196, 0.156  , 0.5    , 0.5    ]),\n",
       " array([ 0.19018395, -0.1060629 , -0.02869925,  0.3987476 ,  0.5       ]),\n",
       " array([ 0.17116555, -0.11447501, -0.03424143,  0.3987476 ,  0.5       ]),\n",
       " array([0.35329248, 0.55493775, 1.08293513, 1.2637129 , 0.88849871]),\n",
       " array([0.35329248, 0.55493775, 1.00131911, 1.20983404, 0.89964884]),\n",
       " array([0.22077433, 0.31143205, 0.7548704 , 1.20983404, 0.89964884]),\n",
       " array([0.22077433, 0.31143205, 0.76843507, 1.19888575, 0.90968396]),\n",
       " array([-0.06901815, -0.24002896,  0.16168249,  0.78981299,  0.74677432]),\n",
       " array([-0.06211634, -0.17566906,  0.18680408,  0.78981299,  0.74677432]),\n",
       " array([-0.0559047 , -0.13129156,  0.18760913,  0.78981299,  0.74677432])]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td_err_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a1499315-fab8-4094-8a07-3a0a012d51fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_star = np.arange(1, size - 2 + 1) / (size - 2 + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0acb3e3b-a3ce-4969-8f3f-fb3c8ba01a1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16666667, 0.33333333, 0.5       , 0.66666667, 0.83333333])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d48b0e54-bd59-4e4e-ab39-4de7bdd10a9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "plt.title(f\"Learning Curves (n={n})\")\n",
    "plt.xlabel(\"Episodes\")\n",
    "plt.ylabel(\"RMS Error\")\n",
    "rms0 = np.sqrt((np.mean(n_step_td_history - v_star, axis=1) ** 2))      \n",
    "rms1 = np.sqrt((np.mean(td_err_history - v_star, axis=1) ** 2))\n",
    "plt.plot(rms0, label='Online')\n",
    "plt.plot(rms1, label='TD Error Sum')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"Value Function (n={n})\")\n",
    "plt.xlabel(\"State\")\n",
    "plt.ylabel(\"Value\")\n",
    "plt.xticks(range(size + 1), [chr(ord('A') + i) for i in range(size + 1)])\n",
    "plt.plot(n_step_td_history[-1], 'o-', label='Online')\n",
    "plt.plot(td_err_history[-1], 'x-', label='TD Error Sum')\n",
    "plt.plot(v_star, 'o--', color='gray', label='Theoretical')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "327a2297-993a-4b4f-9cc6-e788c8a5f478",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.5        0.5        0.5        0.51315789] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.51315789] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.51315789] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.5        0.51315789] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.50034626 0.51315789] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.50034626 0.51282075] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.5        0.50033715 0.51282075] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.50000887 0.50033715 0.51282075] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.5        0.50000887 0.50066566 0.51282075] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.50000887 0.50066566 0.51250088] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.5        0.50000887 0.50064838 0.51250088] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.5000257  0.50064838 0.51250088] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.5        0.5000257  0.50096029 0.51250088] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.5        0.5000257  0.50096029 0.51219718] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.5        0.5000257  0.501256   0.51219718] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.5        0.5000257  0.501256   0.52503409] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.5        0.50002503 0.501256   0.52503409] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48684211 0.49965374 0.50002503 0.501256   0.52503409] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.48717925 0.49965374 0.50002503 0.501256   0.52503409] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48717925 0.49966351 0.50002503 0.501256   0.52503409] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48717925 0.49966351 0.50001551 0.501256   0.52503409] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48717925 0.49933498 0.50001551 0.501256   0.52503409] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.48749914 0.49933498 0.50001551 0.501256   0.52503409] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48749914 0.49902351 0.50001551 0.501256   0.52503409] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47467022 0.49902351 0.50001551 0.501256   0.52503409] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47467022 0.49902351 0.50004816 0.501256   0.52503409] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47467022 0.49902351 0.50004816 0.50188173 0.52503409] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47467022 0.49902351 0.50004816 0.50188173 0.5375332 ] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47467022 0.49902351 0.50002119 0.50188173 0.5375332 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47467022 0.49904976 0.50002119 0.50188173 0.5375332 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47467022 0.49904976 0.50007015 0.50188173 0.5375332 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47467022 0.49904976 0.50007015 0.50281993 0.5375332 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47467022 0.49904976 0.50007015 0.50281993 0.54970337] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47467022 0.49904976 0.5000433  0.50281993 0.54970337] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47467022 0.4984082  0.5000433  0.50281993 0.54970337] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46217889 0.4984082  0.5000433  0.50281993 0.54970337] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46217889 0.4984082  0.50000027 0.50281993 0.54970337] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46217889 0.49845009 0.50000027 0.50281993 0.54970337] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46217889 0.49845009 0.49995948 0.50281993 0.54970337] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46217889 0.49848981 0.49995948 0.50281993 0.54970337] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46217889 0.49848981 0.4999208  0.50281993 0.54970337] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46217889 0.49852747 0.4999208  0.50281993 0.54970337] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46217889 0.49852747 0.49999709 0.50281993 0.54970337] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46217889 0.49852747 0.49999709 0.50405371 0.54970337] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46217889 0.49852747 0.49999709 0.50405371 0.54850207] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46217889 0.49852747 0.49999709 0.50394695 0.54850207] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46217889 0.49852747 0.50010104 0.50394695 0.54850207] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46217889 0.49852747 0.50010104 0.50511946 0.54850207] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46217889 0.49852747 0.50010104 0.50511946 0.56038359] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46217889 0.49852747 0.50005963 0.50511946 0.56038359] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46217889 0.49757093 0.50005963 0.50511946 0.56038359] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46311026 0.49757093 0.50005963 0.50511946 0.56038359] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46311026 0.49666407 0.50005963 0.50511946 0.56038359] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.45092315 0.49666407 0.50005963 0.50511946 0.56038359] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.45092315 0.49666407 0.50019278 0.50511946 0.56038359] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.45092315 0.49666407 0.50019278 0.50498981 0.56038359] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45092315 0.49666407 0.50009992 0.50498981 0.56038359] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45092315 0.49546036 0.50009992 0.50498981 0.56038359] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.45209518 0.49546036 0.50009992 0.50498981 0.56038359] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45209518 0.49431917 0.50009992 0.50498981 0.56038359] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.45320634 0.49431917 0.50009992 0.50498981 0.56038359] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45320634 0.49323726 0.50009992 0.50498981 0.56038359] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.45425979 0.49323726 0.50009992 0.50498981 0.56038359] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45425979 0.49221153 0.50009992 0.50498981 0.56038359] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44230558 0.49221153 0.50009992 0.50498981 0.56038359] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.02631578947368421\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.5        0.5        0.5        0.52631579] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.52631579] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.52631579] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.5        0.52631579] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.50138504 0.52631579] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.50138504 0.52500364] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.5        0.50131214 0.52500364] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.50006906 0.50131214 0.52500364] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.5        0.50006906 0.50255907 0.52500364] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.50006906 0.50255907 0.52382235] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.5        0.50006906 0.50242801 0.52382235] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.50019322 0.50242801 0.52382235] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.5        0.50019322 0.50355403 0.52382235] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.5        0.50019322 0.50355403 0.5227556 ] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.5        0.50019322 0.50456464 0.5227556 ] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.5        0.50019322 0.50456464 0.54787372] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.5        0.50018305 0.50456464 0.54787372] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47368421 0.49861496 0.50018305 0.50456464 0.54787372] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.47499636 0.49861496 0.50018305 0.50456464 0.54787372] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47499636 0.49869749 0.50018305 0.50456464 0.54787372] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47499636 0.49869749 0.50010486 0.50456464 0.54787372] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47499636 0.49745006 0.50010486 0.50456464 0.54787372] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.47617813 0.49745006 0.50010486 0.50456464 0.54787372] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47617813 0.49633049 0.50010486 0.50456464 0.54787372] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.45111612 0.49633049 0.50010486 0.50456464 0.54787372] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.45111612 0.49633049 0.50033958 0.50456464 0.54787372] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.45111612 0.49633049 0.50033958 0.50684406 0.54787372] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.45111612 0.49633049 0.50033958 0.50684406 0.57166984] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45111612 0.49633049 0.50012858 0.50684406 0.57166984] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.45111612 0.49653039 0.50012858 0.50684406 0.57166984] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.45111612 0.49653039 0.50048203 0.50684406 0.57166984] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.45111612 0.49653039 0.50048203 0.51025595 0.57166984] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.45111612 0.49653039 0.50048203 0.51025595 0.59421354] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45111612 0.49653039 0.50027404 0.51025595 0.59421354] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45111612 0.49414016 0.50027404 0.51025595 0.59421354] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42737317 0.49414016 0.50027404 0.51025595 0.59421354] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42737317 0.49414016 0.49995121 0.51025595 0.59421354] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42737317 0.49444601 0.49995121 0.51025595 0.59421354] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42737317 0.49444601 0.49966146 0.51025595 0.59421354] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42737317 0.4947205  0.49966146 0.51025595 0.59421354] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42737317 0.4947205  0.49940141 0.51025595 0.59421354] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42737317 0.49496687 0.49940141 0.51025595 0.59421354] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42737317 0.49496687 0.4999727  0.51025595 0.59421354] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42737317 0.49496687 0.4999727  0.51467477 0.59421354] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42737317 0.49496687 0.4999727  0.51467477 0.59002729] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42737317 0.49496687 0.4999727  0.51390098 0.59002729] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42737317 0.49496687 0.50070577 0.51390098 0.59002729] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42737317 0.49496687 0.50070577 0.51790762 0.59002729] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42737317 0.49496687 0.50070577 0.51790762 0.6116048 ] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42737317 0.49496687 0.50040372 0.51790762 0.6116048 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42737317 0.4914093  0.50040372 0.51790762 0.6116048 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43074349 0.4914093  0.50040372 0.51790762 0.6116048 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43074349 0.48821637 0.50040372 0.51790762 0.6116048 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40807278 0.48821637 0.50040372 0.51790762 0.6116048 ] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40807278 0.48821637 0.50132498 0.51790762 0.6116048 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40807278 0.48821637 0.50132498 0.51703485 0.6116048 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40807278 0.48821637 0.50063505 0.51703485 0.6116048 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40807278 0.48399828 0.50063505 0.51703485 0.6116048 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41206886 0.48399828 0.50063505 0.51703485 0.6116048 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41206886 0.48021252 0.50063505 0.51703485 0.6116048 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41565537 0.48021252 0.50063505 0.51703485 0.6116048 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41565537 0.47681478 0.50063505 0.51703485 0.6116048 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41887429 0.47681478 0.50063505 0.51703485 0.6116048 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41887429 0.47376528 0.50063505 0.51703485 0.6116048 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39682827 0.47376528 0.50063505 0.51703485 0.6116048 ] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.05263157894736842\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.5        0.5        0.5        0.53947368] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.53947368] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.53947368] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.5        0.53947368] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.50311634 0.53947368] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.50311634 0.53660337] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5        0.50287032 0.53660337] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.5002266  0.50287032 0.53660337] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.5        0.5002266  0.50553345 0.53660337] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.5002266  0.50553345 0.53415048] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.5        0.5002266  0.50511449 0.53415048] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.50061249 0.50511449 0.53415048] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.5        0.50061249 0.50740681 0.53415048] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.5        0.50061249 0.50740681 0.53203914] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.5        0.50061249 0.50935146 0.53203914] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.5        0.50061249 0.50935146 0.56898342] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.5        0.50056414 0.50935146 0.56898342] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46052632 0.49688366 0.50056414 0.50935146 0.56898342] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46339663 0.49688366 0.50056414 0.50935146 0.56898342] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46339663 0.49717422 0.50056414 0.50935146 0.56898342] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46339663 0.49717422 0.50029651 0.50935146 0.56898342] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46339663 0.49450757 0.50029651 0.50935146 0.56898342] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46585276 0.49450757 0.50029651 0.50935146 0.56898342] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46585276 0.49224535 0.50029651 0.50935146 0.56898342] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42907491 0.49224535 0.50029651 0.50935146 0.56898342] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42907491 0.49224535 0.50101138 0.50935146 0.56898342] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42907491 0.49224535 0.50101138 0.51405925 0.56898342] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42907491 0.49224535 0.50101138 0.51405925 0.60301104] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42907491 0.49224535 0.50031932 0.51405925 0.60301104] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42907491 0.49288277 0.50031932 0.51405925 0.60301104] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42907491 0.49288277 0.50140405 0.51405925 0.60301104] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42907491 0.49288277 0.50140405 0.52108176 0.60301104] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42907491 0.49288277 0.50140405 0.52108176 0.63435227] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42907491 0.49288277 0.50073132 0.52108176 0.63435227] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42907491 0.4878453  0.50073132 0.52108176 0.63435227] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39520057 0.4878453  0.50073132 0.52108176 0.63435227] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39520057 0.4878453  0.499714   0.52108176 0.63435227] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39520057 0.48878231 0.499714   0.52108176 0.63435227] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39520057 0.48878231 0.49885097 0.52108176 0.63435227] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39520057 0.4895772  0.49885097 0.52108176 0.63435227] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39520057 0.4895772  0.49811883 0.52108176 0.63435227] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39520057 0.49025154 0.49811883 0.52108176 0.63435227] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39520057 0.49025154 0.4999317  0.52108176 0.63435227] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39520057 0.49025154 0.4999317  0.53002417 0.63435227] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39520057 0.49025154 0.4999317  0.53002417 0.62611584] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39520057 0.49025154 0.4999317  0.52764845 0.62611584] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39520057 0.49025154 0.50211986 0.52764845 0.62611584] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39520057 0.49025154 0.50211986 0.53542219 0.62611584] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39520057 0.49025154 0.50211986 0.53542219 0.65563302] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39520057 0.49025154 0.50118289 0.53542219 0.65563302] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39520057 0.48274752 0.50118289 0.53542219 0.65563302] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40211218 0.48274752 0.50118289 0.53542219 0.65563302] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40211218 0.47638157 0.50118289 0.53542219 0.65563302] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.37036648 0.47638157 0.50118289 0.53542219 0.65563302] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.37036648 0.47638157 0.50388599 0.53542219 0.65563302] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.37036648 0.47638157 0.50388599 0.53293249 0.65563302] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.37036648 0.47638157 0.50171459 0.53293249 0.65563302] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37036648 0.46801196 0.50171459 0.53293249 0.65563302] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.37807533 0.46801196 0.50171459 0.53293249 0.65563302] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37807533 0.4609117  0.50171459 0.53293249 0.65563302] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38461504 0.4609117  0.50171459 0.53293249 0.65563302] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38461504 0.45488828 0.50171459 0.53293249 0.65563302] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39016293 0.45488828 0.50171459 0.53293249 0.65563302] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39016293 0.44977838 0.50171459 0.53293249 0.65563302] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35936059 0.44977838 0.50171459 0.53293249 0.65563302] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.07894736842105263\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.5        0.5        0.5        0.55263158] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.55263158] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.55263158] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.5        0.55263158] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.50554017 0.55263158] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.50554017 0.54767459] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.5        0.50495699 0.54767459] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.50052179 0.50495699 0.54767459] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.5        0.50052179 0.50945358 0.54767459] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.50052179 0.50945358 0.54365132] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.5        0.50052179 0.50851339 0.54365132] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.50136301 0.50851339 0.54365132] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.5        0.50136301 0.51221212 0.54365132] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.5        0.50136301 0.51221212 0.54034193] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.5        0.50136301 0.51517315 0.54034193] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.5        0.50136301 0.51517315 0.58872699] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.5        0.50121954 0.51517315 0.58872699] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44736842 0.49445983 0.50121954 0.51517315 0.58872699] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.45232541 0.49445983 0.50121954 0.51517315 0.58872699] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.45232541 0.49517138 0.50121954 0.51517315 0.58872699] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45232541 0.49517138 0.50058289 0.51517315 0.58872699] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45232541 0.49066128 0.50058289 0.51517315 0.58872699] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.45636077 0.49066128 0.50058289 0.51517315 0.58872699] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45636077 0.4870507  0.50058289 0.51517315 0.58872699] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40832279 0.4870507  0.50058289 0.51517315 0.58872699] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40832279 0.4870507  0.5021187  0.51517315 0.58872699] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40832279 0.4870507  0.5021187  0.52291566 0.58872699] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40832279 0.4870507  0.5021187  0.52291566 0.63201889] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40832279 0.4870507  0.5005326  0.52291566 0.63201889] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40832279 0.48846985 0.5005326  0.52291566 0.63201889] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40832279 0.48846985 0.50288871 0.52291566 0.63201889] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40832279 0.48846985 0.50288871 0.53440021 0.63201889] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40832279 0.48846985 0.50288871 0.53440021 0.67075374] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40832279 0.48846985 0.50137094 0.53440021 0.67075374] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40832279 0.48003331 0.50137094 0.53440021 0.67075374] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36534144 0.48003331 0.50137094 0.53440021 0.67075374] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36534144 0.48003331 0.49912487 0.53440021 0.67075374] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36534144 0.48204295 0.49912487 0.53440021 0.67075374] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36534144 0.48204295 0.49732677 0.53440021 0.67075374] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36534144 0.48365178 0.49732677 0.53440021 0.67075374] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36534144 0.48365178 0.4958873  0.53440021 0.67075374] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36534144 0.48493973 0.4958873  0.53440021 0.67075374] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36534144 0.48493973 0.49994129 0.53440021 0.67075374] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36534144 0.48493973 0.49994129 0.54875322 0.67075374] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36534144 0.48493973 0.49994129 0.54875322 0.65791158] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36534144 0.48493973 0.49994129 0.54361512 0.65791158] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36534144 0.48493973 0.50453854 0.54361512 0.65791158] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36534144 0.48493973 0.50453854 0.55564633 0.65791158] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36534144 0.48493973 0.50453854 0.55564633 0.69392089] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36534144 0.48493973 0.5024755  0.55564633 0.69392089] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36534144 0.47235043 0.5024755  0.55564633 0.69392089] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.37660555 0.47235043 0.5024755  0.55564633 0.69392089] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37660555 0.46227202 0.5024755  0.55564633 0.69392089] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33696286 0.46227202 0.5024755  0.55564633 0.69392089] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33696286 0.46227202 0.50807243 0.55564633 0.69392089] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.33696286 0.46227202 0.50807243 0.55063855 0.69392089] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33696286 0.46227202 0.50325134 0.55063855 0.69392089] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33696286 0.44908159 0.50325134 0.55063855 0.69392089] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34876483 0.44908159 0.50325134 0.55063855 0.69392089] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34876483 0.43852193 0.50325134 0.55063855 0.69392089] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35821295 0.43852193 0.50325134 0.55063855 0.69392089] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35821295 0.43006835 0.50325134 0.55063855 0.69392089] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36577667 0.43006835 0.50325134 0.55063855 0.69392089] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36577667 0.4233008  0.50325134 0.55063855 0.69392089] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32727386 0.4233008  0.50325134 0.55063855 0.69392089] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.10526315789473684\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.5        0.5        0.5        0.56578947] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.56578947] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.56578947] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5        0.56578947] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.50865651 0.56578947] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.50865651 0.55827198] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.5        0.5075175  0.55827198] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.50098914 0.5075175  0.55827198] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.5        0.50098914 0.51419572 0.55827198] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.50098914 0.51419572 0.55247247] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.5        0.50098914 0.51245801 0.55247247] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.50249821 0.51245801 0.55247247] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.5        0.50249821 0.51772307 0.55247247] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.5        0.50249821 0.51772307 0.54790018] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.5        0.50249821 0.52169374 0.54790018] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.5        0.50249821 0.52169374 0.607387  ] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.5        0.50216949 0.52169374 0.607387  ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43421053 0.49134349 0.50216949 0.52169374 0.607387  ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44172802 0.49134349 0.50216949 0.52169374 0.607387  ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44172802 0.49276796 0.50216949 0.52169374 0.607387  ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44172802 0.49276796 0.50093245 0.52169374 0.607387  ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44172802 0.48605218 0.50093245 0.52169374 0.607387  ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44756015 0.48605218 0.50093245 0.52169374 0.607387  ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44756015 0.48098744 0.50093245 0.52169374 0.607387  ] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38867065 0.48098744 0.50093245 0.52169374 0.607387  ] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38867065 0.48098744 0.5036642  0.52169374 0.607387  ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38867065 0.48098744 0.5036642  0.53296917 0.607387  ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38867065 0.48098744 0.5036642  0.53296917 0.6590466 ] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38867065 0.48098744 0.50068042 0.53296917 0.6590466 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38867065 0.48357862 0.50068042 0.53296917 0.6590466 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38867065 0.48357862 0.50492894 0.53296917 0.6590466 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38867065 0.48357862 0.50492894 0.54955831 0.6590466 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38867065 0.48357862 0.50492894 0.54955831 0.70390889] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38867065 0.48357862 0.50211968 0.54955831 0.70390889] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38867065 0.47109073 0.50211968 0.54955831 0.70390889] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33752978 0.47109073 0.50211968 0.54955831 0.70390889] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33752978 0.47109073 0.49803693 0.54955831 0.70390889] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33752978 0.47463628 0.49803693 0.54955831 0.70390889] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33752978 0.47463628 0.4949579  0.54955831 0.70390889] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33752978 0.47731018 0.4949579  0.54955831 0.70390889] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33752978 0.47731018 0.49263583 0.54955831 0.70390889] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33752978 0.47932671 0.49263583 0.54955831 0.70390889] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50012563 0.54955831 0.70390889] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50012563 0.56986759 0.70390889] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50012563 0.56986759 0.68627188] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50012563 0.56069102 0.68627188] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50809476 0.56069102 0.68627188] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50809476 0.57721482 0.68627188] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33752978 0.47932671 0.50809476 0.57721482 0.7275519 ] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33752978 0.47932671 0.50430949 0.57721482 0.7275519 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33752978 0.46066922 0.50430949 0.57721482 0.7275519 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35373234 0.46066922 0.50430949 0.57721482 0.7275519 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35373234 0.44659858 0.50430949 0.57721482 0.7275519 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30718861 0.44659858 0.50430949 0.57721482 0.7275519 ] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30718861 0.44659858 0.5139023  0.57721482 0.7275519 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30718861 0.44659858 0.5139023  0.56888422 0.7275519 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30718861 0.44659858 0.50504654 0.56888422 0.7275519 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30718861 0.42825516 0.50504654 0.56888422 0.7275519 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32311842 0.42825516 0.50504654 0.56888422 0.7275519 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32311842 0.41442138 0.50504654 0.56888422 0.7275519 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.33513197 0.41442138 0.50504654 0.56888422 0.7275519 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33513197 0.40398856 0.50504654 0.56888422 0.7275519 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34419204 0.40398856 0.50504654 0.56888422 0.7275519 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34419204 0.3961206  0.50504654 0.56888422 0.7275519 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29890362 0.3961206  0.50504654 0.56888422 0.7275519 ] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.13157894736842105\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.5        0.5        0.5        0.57894737] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.57894737] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.57894737] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.5        0.57894737] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.51246537 0.57894737] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.51246537 0.56845021] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.5        0.51049716 0.56845021] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.50165745 0.51049716 0.56845021] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.5        0.50165745 0.51964764 0.56845021] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.50165745 0.51964764 0.56074454] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.5        0.50165745 0.51680708 0.56074454] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.50404949 0.51680708 0.56074454] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.5        0.50404949 0.52374458 0.56074454] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.5        0.50404949 0.52374458 0.55490244] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.5        0.50404949 0.52866424 0.55490244] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.5        0.50404949 0.52866424 0.625181  ] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.5        0.5034101  0.52866424 0.625181  ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42105263 0.48753463 0.5034101  0.52866424 0.625181  ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43154979 0.48753463 0.5034101  0.52866424 0.625181  ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43154979 0.49004128 0.5034101  0.52866424 0.625181  ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43154979 0.49004128 0.50129923 0.52866424 0.625181  ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43154979 0.48080578 0.50129923 0.52866424 0.625181  ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43932705 0.48080578 0.50129923 0.52866424 0.625181  ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43932705 0.47425651 0.50129923 0.52866424 0.625181  ] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36995962 0.47425651 0.50129923 0.52866424 0.625181  ] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36995962 0.47425651 0.50562002 0.52866424 0.625181  ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36995962 0.47425651 0.50562002 0.54390373 0.625181  ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36995962 0.47425651 0.50562002 0.54390373 0.68436295] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36995962 0.47425651 0.50066789 0.54390373 0.68436295] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36995962 0.47842673 0.50066789 0.54390373 0.68436295] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36995962 0.47842673 0.5074946  0.54390373 0.68436295] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36995962 0.47842673 0.5074946  0.5660815  0.68436295] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36995962 0.47842673 0.5074946  0.5660815  0.73420038] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36995962 0.47842673 0.50290494 0.5660815  0.73420038] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36995962 0.46130034 0.50290494 0.5660815  0.73420038] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.31154494 0.46130034 0.50290494 0.5660815  0.73420038] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31154494 0.46130034 0.49633579 0.5660815  0.73420038] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31154494 0.46683225 0.49633579 0.5660815  0.73420038] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31154494 0.46683225 0.49167734 0.5660815  0.73420038] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31154494 0.47075516 0.49167734 0.5660815  0.73420038] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31154494 0.47075516 0.48837384 0.5660815  0.73420038] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31154494 0.47353706 0.48837384 0.5660815  0.73420038] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31154494 0.47353706 0.50064347 0.5660815  0.73420038] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31154494 0.47353706 0.50064347 0.59262659 0.73420038] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31154494 0.47353706 0.50064347 0.59262659 0.71184662] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31154494 0.47353706 0.50064347 0.57810294 0.71184662] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31154494 0.47353706 0.51287391 0.57810294 0.71184662] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31154494 0.47353706 0.51287391 0.59922036 0.71184662] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31154494 0.47353706 0.51287391 0.59922036 0.75734452] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31154494 0.47353706 0.50666283 0.59922036 0.75734452] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31154494 0.44795936 0.50666283 0.59922036 0.75734452] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.33308406 0.44795936 0.50666283 0.59922036 0.75734452] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33308406 0.42982115 0.50666283 0.59922036 0.75734452] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28049184 0.42982115 0.50666283 0.59922036 0.75734452] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28049184 0.42982115 0.52127717 0.59922036 0.75734452] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28049184 0.42982115 0.52127717 0.58691354 0.75734452] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28049184 0.42982115 0.50683675 0.58691354 0.75734452] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28049184 0.40624284 0.50683675 0.58691354 0.75734452] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.30034726 0.40624284 0.50683675 0.58691354 0.75734452] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30034726 0.38952249 0.50683675 0.58691354 0.75734452] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.31442756 0.38952249 0.50683675 0.58691354 0.75734452] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31442756 0.37766539 0.50683675 0.58691354 0.75734452] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32441248 0.37766539 0.50683675 0.58691354 0.75734452] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32441248 0.36925704 0.50683675 0.58691354 0.75734452] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27318946 0.36925704 0.50683675 0.58691354 0.75734452] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.15789473684210525\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.5        0.5        0.5        0.59210526] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.59210526] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.59210526] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5        0.59210526] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.51696676 0.59210526] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.51696676 0.57826396] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.5        0.5138413  0.57826396] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.50254971 0.5138413  0.57826396] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.5        0.50254971 0.52570863 0.57826396] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.50254971 0.52570863 0.56858272] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.5        0.50254971 0.52144252 0.56858272] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.50602997 0.52144252 0.56858272] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.5        0.50602997 0.53012624 0.56858272] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.5        0.50602997 0.53012624 0.56149863] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.5        0.50602997 0.53590536 0.56149863] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.5        0.50602997 0.53590536 0.6422752 ] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.5        0.50491918 0.53590536 0.6422752 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40789474 0.48303324 0.50491918 0.53590536 0.6422752 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42173604 0.48303324 0.50491918 0.53590536 0.6422752 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42173604 0.48706486 0.50491918 0.53590536 0.6422752 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42173604 0.48706486 0.50163023 0.53590536 0.6422752 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42173604 0.47503061 0.50163023 0.53590536 0.6422752 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43155346 0.47503061 0.50163023 0.53590536 0.6422752 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43155346 0.46702166 0.50163023 0.53590536 0.6422752 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35205677 0.46702166 0.50163023 0.53590536 0.6422752 ] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35205677 0.46702166 0.50794407 0.53590536 0.6422752 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35205677 0.46702166 0.50794407 0.55549981 0.6422752 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35205677 0.46702166 0.50794407 0.55549981 0.70817187] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35205677 0.46702166 0.50040573 0.55549981 0.70817187] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35205677 0.47317136 0.50040573 0.55549981 0.70817187] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35205677 0.47317136 0.51055464 0.55549981 0.70817187] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35205677 0.47317136 0.51055464 0.58362361 0.70817187] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35205677 0.47317136 0.51055464 0.58362361 0.76192968] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35205677 0.47317136 0.50366824 0.58362361 0.76192968] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35205677 0.45086077 0.50366824 0.58362361 0.76192968] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28720421 0.45086077 0.50366824 0.58362361 0.76192968] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28720421 0.45086077 0.49394055 0.58362361 0.76192968] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28720421 0.45879652 0.49394055 0.58362361 0.76192968] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28720421 0.45879652 0.48746665 0.58362361 0.76192968] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28720421 0.46407786 0.48746665 0.58362361 0.76192968] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28720421 0.46407786 0.48315819 0.58362361 0.76192968] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28720421 0.46759266 0.48315819 0.58362361 0.76192968] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28720421 0.46759266 0.50166498 0.58362361 0.76192968] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28720421 0.46759266 0.50166498 0.61646946 0.76192968] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28720421 0.46759266 0.50166498 0.61646946 0.73513438] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28720421 0.46759266 0.50166498 0.59532127 0.73513438] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28720421 0.46759266 0.51891745 0.59532127 0.73513438] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28720421 0.46759266 0.51891745 0.62107632 0.73513438] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28720421 0.46759266 0.51891745 0.62107632 0.78392542] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28720421 0.46759266 0.50946289 0.62107632 0.78392542] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28720421 0.43436321 0.50946289 0.62107632 0.78392542] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.31431244 0.43436321 0.50946289 0.62107632 0.78392542] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31431244 0.41224859 0.50946289 0.62107632 0.78392542] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25641278 0.41224859 0.50946289 0.62107632 0.78392542] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25641278 0.41224859 0.53002325 0.62107632 0.78392542] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25641278 0.41224859 0.53002325 0.60430338 0.78392542] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25641278 0.41224859 0.50832792 0.60430338 0.78392542] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25641278 0.383542   0.50832792 0.60430338 0.78392542] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.27983132 0.383542   0.50832792 0.60430338 0.78392542] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27983132 0.3644374  0.50832792 0.60430338 0.78392542] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.29541665 0.3644374  0.50832792 0.60430338 0.78392542] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29541665 0.35172305 0.50832792 0.60430338 0.78392542] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.30578888 0.35172305 0.50832792 0.60430338 0.78392542] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30578888 0.34326149 0.50832792 0.60430338 0.78392542] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24945935 0.34326149 0.50832792 0.60430338 0.78392542] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.18421052631578946\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.5        0.5        0.5        0.60526316] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.60526316] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.60526316] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.5        0.60526316] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.52216066 0.60526316] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.52216066 0.5877679 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.5        0.51749526 0.5877679 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.50368321 0.51749526 0.5877679 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.5        0.50368321 0.5322895  0.5877679 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.50368321 0.5322895  0.57608823] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.5        0.50368321 0.52626712 0.57608823] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.50843772 0.52626712 0.57608823] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.5        0.50843772 0.53675578 0.57608823] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.5        0.50843772 0.53675578 0.56780772] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.5        0.50843772 0.54329303 0.56780772] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.5        0.50843772 0.54329303 0.65879557] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.5        0.50666136 0.54329303 0.65879557] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39473684 0.47783934 0.50666136 0.54329303 0.65879557] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.4122321  0.47783934 0.50666136 0.54329303 0.65879557] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.4122321  0.48390713 0.50666136 0.54329303 0.65879557] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.4122321  0.48390713 0.50187099 0.54329303 0.65879557] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.4122321  0.46881765 0.50187099 0.54329303 0.65879557] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42414485 0.46881765 0.50187099 0.54329303 0.65879557] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42414485 0.45941285 0.50187099 0.54329303 0.65879557] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3348512  0.45941285 0.50187099 0.54329303 0.65879557] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3348512  0.45941285 0.51059142 0.54329303 0.65879557] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3348512  0.45941285 0.51059142 0.56760935 0.65879557] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3348512  0.45941285 0.51059142 0.56760935 0.73062808] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3348512  0.45941285 0.49981699 0.56760935 0.73062808] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3348512  0.46791898 0.49981699 0.56760935 0.73062808] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3348512  0.46791898 0.51408906 0.56760935 0.73062808] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3348512  0.46791898 0.51408906 0.60192908 0.73062808] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3348512  0.46791898 0.51408906 0.60192908 0.78733796] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3348512  0.46791898 0.50436905 0.60192908 0.78733796] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3348512  0.43990471 0.50436905 0.60192908 0.78733796] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26435621 0.43990471 0.50436905 0.60192908 0.78733796] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26435621 0.43990471 0.49079761 0.60192908 0.78733796] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26435621 0.45061901 0.49079761 0.60192908 0.78733796] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26435621 0.45061901 0.48233896 0.60192908 0.78733796] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26435621 0.45729689 0.48233896 0.60192908 0.78733796] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26435621 0.45729689 0.47706694 0.60192908 0.78733796] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26435621 0.46145901 0.47706694 0.60192908 0.78733796] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26435621 0.46145901 0.50335371 0.60192908 0.78733796] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26435621 0.46145901 0.50335371 0.64096253 0.78733796] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26435621 0.46145901 0.50335371 0.64096253 0.75652208] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26435621 0.46145901 0.50335371 0.61199225 0.75652208] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26435621 0.46145901 0.52622498 0.61199225 0.75652208] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26435621 0.46145901 0.52622498 0.64241958 0.75652208] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26435621 0.46145901 0.52622498 0.64241958 0.80778059] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26435621 0.46145901 0.51259004 0.64241958 0.80778059] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26435621 0.41996368 0.51259004 0.64241958 0.80778059] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.29711568 0.41996368 0.51259004 0.64241958 0.80778059] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29711568 0.39410094 0.51259004 0.64241958 0.80778059] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23456501 0.39410094 0.51259004 0.64241958 0.80778059] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.23456501 0.39410094 0.53992258 0.64241958 0.80778059] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.23456501 0.39410094 0.53992258 0.62084127 0.80778059] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.23456501 0.39410094 0.50922328 0.62084127 0.80778059] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23456501 0.36051443 0.50922328 0.62084127 0.80778059] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.26108068 0.36051443 0.50922328 0.62084127 0.80778059] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26108068 0.33958101 0.50922328 0.62084127 0.80778059] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.27760706 0.33958101 0.50922328 0.62084127 0.80778059] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27760706 0.32653386 0.50922328 0.62084127 0.80778059] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.28790744 0.32653386 0.50922328 0.62084127 0.80778059] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28790744 0.31840198 0.50922328 0.62084127 0.80778059] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22729535 0.31840198 0.50922328 0.62084127 0.80778059] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.21052631578947367\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.5        0.5        0.5        0.61842105] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.61842105] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.61842105] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.5        0.61842105] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.52804709 0.61842105] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.52804709 0.59701669] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.5        0.52140436 0.59701669] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.50506945 0.52140436 0.59701669] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.5        0.50506945 0.53931254 0.59701669] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.50506945 0.53931254 0.58334992] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.5        0.50506945 0.53120234 0.58334992] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.51125882 0.53120234 0.58334992] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.5        0.51125882 0.54355308 0.58334992] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.5        0.51125882 0.54355308 0.57392435] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.5        0.51125882 0.55074628 0.57392435] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.5        0.51125882 0.55074628 0.67483701] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.5        0.50859226 0.55074628 0.67483701] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38157895 0.47195291 0.50859226 0.55074628 0.67483701] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40298331 0.47195291 0.50859226 0.55074628 0.67483701] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40298331 0.48063065 0.50859226 0.55074628 0.67483701] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40298331 0.48063065 0.50196977 0.55074628 0.67483701] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40298331 0.46224049 0.50196977 0.55074628 0.67483701] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.4170179  0.46224049 0.50196977 0.55074628 0.67483701] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.4170179  0.45152988 0.50196977 0.55074628 0.67483701] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3182505  0.45152988 0.50196977 0.55074628 0.67483701] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3182505  0.45152988 0.5135221  0.55074628 0.67483701] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3182505  0.45152988 0.5135221  0.58013619 0.67483701] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3182505  0.45152988 0.5135221  0.58013619 0.75184929] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3182505  0.45152988 0.49883973 0.58013619 0.75184929] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3182505  0.46273484 0.49883973 0.58013619 0.75184929] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3182505  0.46273484 0.51809416 0.58013619 0.75184929] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3182505  0.46273484 0.51809416 0.62080508 0.75184929] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3182505  0.46273484 0.51809416 0.62080508 0.81062183] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3182505  0.46273484 0.50498274 0.62080508 0.81062183] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3182505  0.42851487 0.50498274 0.62080508 0.81062183] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24287539 0.42851487 0.50498274 0.62080508 0.81062183] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24287539 0.42851487 0.48687193 0.62080508 0.81062183] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24287539 0.44233628 0.48687193 0.62080508 0.81062183] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24287539 0.44233628 0.47632401 0.62080508 0.81062183] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24287539 0.450386   0.47632401 0.62080508 0.81062183] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24287539 0.450386   0.4701808  0.62080508 0.81062183] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24287539 0.45507424 0.4701808  0.62080508 0.81062183] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24287539 0.45507424 0.50585497 0.62080508 0.81062183] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24287539 0.45507424 0.50585497 0.66576168 0.81062183] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.24287539 0.45507424 0.50585497 0.66576168 0.77631285] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.24287539 0.45507424 0.50585497 0.62788904 0.77631285] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24287539 0.45507424 0.53475778 0.62788904 0.77631285] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24287539 0.45507424 0.53475778 0.66304205 0.77631285] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24287539 0.45507424 0.53475778 0.66304205 0.82929138] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24287539 0.45507424 0.51588536 0.66304205 0.82929138] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24287539 0.40481662 0.51588536 0.66304205 0.82929138] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.28122989 0.40481662 0.51588536 0.66304205 0.82929138] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28122989 0.37554608 0.51588536 0.66304205 0.82929138] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21462281 0.37554608 0.51588536 0.66304205 0.82929138] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.21462281 0.37554608 0.55073826 0.66304205 0.82929138] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.21462281 0.37554608 0.55073826 0.63644378 0.82929138] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.21462281 0.37554608 0.50924537 0.63644378 0.82929138] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21462281 0.33743267 0.50924537 0.63644378 0.82929138] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.24370936 0.33743267 0.50924537 0.63644378 0.82929138] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24370936 0.31523504 0.50924537 0.63644378 0.82929138] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.26064965 0.31523504 0.50924537 0.63644378 0.82929138] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26064965 0.30230692 0.50924537 0.63644378 0.82929138] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.27051585 0.30230692 0.50924537 0.63644378 0.82929138] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27051585 0.29477746 0.50924537 0.63644378 0.82929138] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2064463  0.29477746 0.50924537 0.63644378 0.82929138] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.23684210526315788\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.5        0.5        0.5        0.63157895] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.63157895] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.63157895] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.5        0.63157895] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.53462604 0.63157895] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.53462604 0.60606502] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.5        0.52551392 0.60606502] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.50671419 0.52551392 0.60606502] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.5        0.50671419 0.54671158 0.60606502] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.50671419 0.54671158 0.5904457 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.5        0.50671419 0.53618595 0.5904457 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.51446992 0.53618595 0.5904457 ] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.5        0.51446992 0.55046483 0.5904457 ] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.5        0.51446992 0.55046483 0.57992442] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.5        0.51446992 0.55821735 0.57992442] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.5        0.51446992 0.55821735 0.69047062] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.5        0.51066204 0.55821735 0.69047062] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36842105 0.46537396 0.51066204 0.55821735 0.69047062] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39393498 0.46537396 0.51066204 0.55821735 0.69047062] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39393498 0.47729188 0.51066204 0.55821735 0.69047062] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39393498 0.47729188 0.50188042 0.55821735 0.69047062] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39393498 0.45535585 0.50188042 0.55821735 0.69047062] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41009836 0.45535585 0.50188042 0.55821735 0.69047062] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41009836 0.44344599 0.50188042 0.55821735 0.69047062] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30217774 0.44344599 0.50188042 0.55821735 0.69047062] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30217774 0.44344599 0.51670593 0.55821735 0.69047062] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30217774 0.44344599 0.51670593 0.59302085 0.69047062] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30217774 0.44344599 0.51670593 0.59302085 0.77192572] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30217774 0.44344599 0.497427   0.59302085 0.77192572] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30217774 0.45765152 0.497427   0.59302085 0.77192572] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30217774 0.45765152 0.52258327 0.59302085 0.77192572] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30217774 0.45765152 0.52258327 0.64010108 0.77192572] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30217774 0.45765152 0.52258327 0.64010108 0.83194527] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30217774 0.45765152 0.50549597 0.64010108 0.83194527] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30217774 0.41673736 0.50549597 0.64010108 0.83194527] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22265728 0.41673736 0.50549597 0.64010108 0.83194527] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22265728 0.41673736 0.48213844 0.64010108 0.83194527] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22265728 0.43394817 0.48213844 0.64010108 0.83194527] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22265728 0.43394817 0.46945679 0.64010108 0.83194527] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22265728 0.44329255 0.46945679 0.64010108 0.83194527] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22265728 0.44329255 0.46257146 0.64010108 0.83194527] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22265728 0.44836595 0.46257146 0.64010108 0.83194527] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22265728 0.44836595 0.50928978 0.64010108 0.83194527] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22265728 0.44836595 0.50928978 0.69058639 0.83194527] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.22265728 0.44836595 0.50928978 0.69058639 0.79474556] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.22265728 0.44836595 0.50928978 0.64287676 0.79474556] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22265728 0.44836595 0.54444425 0.64287676 0.79474556] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22265728 0.44836595 0.54444425 0.68284223 0.79474556] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22265728 0.44836595 0.54444425 0.68284223 0.84875989] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22265728 0.44836595 0.51916049 0.68284223 0.84875989] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22265728 0.38896893 0.51916049 0.68284223 0.84875989] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.26642351 0.38896893 0.51916049 0.68284223 0.84875989] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26642351 0.35672013 0.51916049 0.68284223 0.84875989] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.19631206 0.35672013 0.51916049 0.68284223 0.84875989] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.19631206 0.35672013 0.56223463 0.68284223 0.84875989] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.19631206 0.35672013 0.56223463 0.65110339 0.84875989] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.19631206 0.35672013 0.50815187 0.65110339 0.84875989] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.19631206 0.31450748 0.50815187 0.65110339 0.84875989] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22741612 0.31450748 0.50815187 0.65110339 0.84875989] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22741612 0.2915887  0.50815187 0.65110339 0.84875989] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.24430364 0.2915887  0.50815187 0.65110339 0.84875989] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24430364 0.27914526 0.50815187 0.65110339 0.84875989] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25347249 0.27914526 0.50815187 0.65110339 0.84875989] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25347249 0.27238927 0.50815187 0.65110339 0.84875989] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1867692  0.27238927 0.50815187 0.65110339 0.84875989] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.2631578947368421\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.5        0.5        0.5        0.64473684] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.64473684] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.64473684] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.5        0.64473684] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.54189751 0.64473684] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.54189751 0.61496756] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.5        0.52976928 0.61496756] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.50861742 0.52976928 0.61496756] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.5        0.50861742 0.55443194 0.61496756] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.50861742 0.55443194 0.59744409] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.5        0.50861742 0.54116984 0.59744409] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.51804049 0.54116984 0.59744409] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.5        0.51804049 0.55745976 0.59744409] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.5        0.51804049 0.55745976 0.58586968] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.5        0.51804049 0.56568368 0.58586968] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.5        0.51804049 0.56568368 0.70574951] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.5        0.51281824 0.56568368 0.70574951] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35526316 0.45810249 0.51281824 0.56568368 0.70574951] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38503244 0.45810249 0.51281824 0.56568368 0.70574951] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38503244 0.47394126 0.51281824 0.56568368 0.70574951] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38503244 0.47394126 0.50156438 0.56568368 0.70574951] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38503244 0.4482045  0.50156438 0.56568368 0.70574951] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40331909 0.4482045  0.50156438 0.56568368 0.70574951] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40331909 0.43521135 0.50156438 0.56568368 0.70574951] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28656883 0.43521135 0.50156438 0.56568368 0.70574951] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28656883 0.43521135 0.52012523 0.56568368 0.70574951] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28656883 0.43521135 0.52012523 0.60622905 0.70574951] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28656883 0.43521135 0.52012523 0.60622905 0.79092728] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28656883 0.43521135 0.4955449  0.60622905 0.79092728] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28656883 0.45267633 0.4955449  0.60622905 0.79092728] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28656883 0.45267633 0.52758505 0.60622905 0.79092728] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28656883 0.45267633 0.52758505 0.65969433 0.79092728] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28656883 0.45267633 0.52758505 0.65969433 0.85144833] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28656883 0.45267633 0.50590095 0.65969433 0.85144833] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28656883 0.40459258 0.50590095 0.65969433 0.85144833] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20361469 0.40459258 0.50590095 0.65969433 0.85144833] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20361469 0.40459258 0.47657484 0.65969433 0.85144833] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20361469 0.42542955 0.47657484 0.65969433 0.85144833] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20361469 0.42542955 0.46176962 0.65969433 0.85144833] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20361469 0.43594904 0.46176962 0.65969433 0.85144833] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20361469 0.43594904 0.45429524 0.65969433 0.85144833] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20361469 0.44125979 0.45429524 0.65969433 0.85144833] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20361469 0.44125979 0.51375287 0.65969433 0.85144833] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20361469 0.44125979 0.51375287 0.71520207 0.85144833] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.20361469 0.44125979 0.51375287 0.71520207 0.81200862] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.20361469 0.44125979 0.51375287 0.65688783 0.81200862] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20361469 0.44125979 0.55518668 0.65688783 0.81200862] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20361469 0.44125979 0.55518668 0.70179122 0.81200862] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20361469 0.44125979 0.55518668 0.70179122 0.86642718] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20361469 0.44125979 0.52220784 0.70179122 0.86642718] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20361469 0.37246778 0.52220784 0.70179122 0.86642718] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25249322 0.37246778 0.52220784 0.70179122 0.86642718] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25249322 0.3377383  0.52220784 0.70179122 0.86642718] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17940308 0.3377383  0.52220784 0.70179122 0.86642718] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17940308 0.3377383  0.5741925  0.70179122 0.86642718] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.17940308 0.3377383  0.5741925  0.66485475 0.86642718] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17940308 0.3377383  0.50574523 0.66485475 0.86642718] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17940308 0.29190442 0.50574523 0.66485475 0.86642718] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.21196926 0.29190442 0.50574523 0.66485475 0.86642718] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21196926 0.2687653  0.50574523 0.66485475 0.86642718] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22841021 0.2687653  0.50574523 0.66485475 0.86642718] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22841021 0.25708356 0.50574523 0.66485475 0.86642718] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.23671039 0.25708356 0.50574523 0.66485475 0.86642718] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23671039 0.25118607 0.50574523 0.66485475 0.86642718] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16818896 0.25118607 0.50574523 0.66485475 0.86642718] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.2894736842105263\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.5        0.5        0.5        0.65789474] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.65789474] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.65789474] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5        0.65789474] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5498615  0.65789474] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.5498615  0.62377898] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5        0.53411576 0.62377898] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.5107734  0.53411576 0.62377898] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.5        0.5107734  0.56243046 0.62377898] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.5107734  0.56243046 0.60440576] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.5        0.5107734  0.5461177  0.60440576] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.52193476 0.5461177  0.60440576] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.5        0.52193476 0.56452446 0.60440576] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.5        0.52193476 0.56452446 0.59181167] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.5        0.52193476 0.57314147 0.59181167] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.5        0.52193476 0.57314147 0.72071324] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.5        0.51500799 0.57314147 0.72071324] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34210526 0.4501385  0.51500799 0.57314147 0.72071324] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.37622102 0.4501385  0.51500799 0.57314147 0.72071324] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.37622102 0.47062361 0.51500799 0.57314147 0.72071324] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.37622102 0.47062361 0.50099187 0.57314147 0.72071324] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37622102 0.44081226 0.50099187 0.57314147 0.72071324] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39661826 0.44081226 0.50099187 0.57314147 0.72071324] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39661826 0.42685626 0.50099187 0.57314147 0.72071324] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27137039 0.42685626 0.50099187 0.57314147 0.72071324] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27137039 0.42685626 0.52377595 0.57314147 0.72071324] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27137039 0.42685626 0.52377595 0.61974308 0.72071324] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27137039 0.42685626 0.52377595 0.61974308 0.80890906] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27137039 0.42685626 0.49316974 0.61974308 0.80890906] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27137039 0.44779736 0.49316974 0.61974308 0.80890906] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27137039 0.44779736 0.53314027 0.61974308 0.80890906] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27137039 0.44779736 0.53314027 0.67947971 0.80890906] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27137039 0.44779736 0.53314027 0.67947971 0.86925357] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27137039 0.44779736 0.50618987 0.67947971 0.86925357] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27137039 0.39208358 0.50618987 0.67947971 0.86925357] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18567448 0.39208358 0.50618987 0.67947971 0.86925357] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18567448 0.39208358 0.47015631 0.67947971 0.86925357] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18567448 0.41673812 0.47015631 0.67947971 0.86925357] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18567448 0.41673812 0.45328741 0.67947971 0.86925357] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18567448 0.42828    0.45328741 0.67947971 0.86925357] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18567448 0.42828    0.44539033 0.67947971 0.86925357] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18567448 0.43368327 0.44539033 0.67947971 0.86925357] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18567448 0.43368327 0.51931329 0.67947971 0.86925357] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18567448 0.43368327 0.51931329 0.7394083  0.86925357] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.18567448 0.43368327 0.51931329 0.7394083  0.8282498 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.18567448 0.43368327 0.51931329 0.66990461 0.8282498 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18567448 0.43368327 0.56686845 0.66990461 0.8282498 ] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18567448 0.43368327 0.56686845 0.71990835 0.8282498 ] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18567448 0.43368327 0.56686845 0.71990835 0.8824867 ] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18567448 0.43368327 0.52480997 0.71990835 0.8824867 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18567448 0.3553647  0.52480997 0.71990835 0.8824867 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.23926086 0.3553647  0.52480997 0.71990835 0.8824867 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23926086 0.31870033 0.52480997 0.71990835 0.8824867 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1637048  0.31870033 0.52480997 0.71990835 0.8824867 ] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.1637048  0.31870033 0.58641998 0.71990835 0.8824867 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.1637048  0.31870033 0.58641998 0.67775413 0.8824867 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.1637048  0.31870033 0.50187694 0.67775413 0.8824867 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1637048  0.26975437 0.50187694 0.67775413 0.8824867 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.19719414 0.26975437 0.50187694 0.67775413 0.8824867 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.19719414 0.24684061 0.50187694 0.67775413 0.8824867 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.21287197 0.24684061 0.50187694 0.67775413 0.8824867 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21287197 0.23611368 0.50187694 0.67775413 0.8824867 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22021146 0.23611368 0.50187694 0.67775413 0.8824867 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22021146 0.23109192 0.50187694 0.67775413 0.8824867 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.150671   0.23109192 0.50187694 0.67775413 0.8824867 ] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.3157894736842105\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.5        0.5        0.5        0.67105263] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.67105263] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.67105263] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.5        0.67105263] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.55851801 0.67105263] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.55851801 0.63255394] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5        0.53849869 0.63255394] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.5131706  0.53849869 0.63255394] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.5        0.5131706  0.57067549 0.63255394] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.5131706  0.57067549 0.611385  ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.5        0.5131706  0.55100276 0.611385  ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.52611318 0.55100276 0.611385  ] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.5        0.52611318 0.57165984 0.611385  ] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.5        0.52611318 0.57165984 0.59779481] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.5        0.52611318 0.58060075 0.59779481] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.5        0.52611318 0.58060075 0.73539132] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.5        0.51717973 0.58060075 0.73539132] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32894737 0.44148199 0.51717973 0.58060075 0.73539132] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36744606 0.44148199 0.51717973 0.58060075 0.73539132] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36744606 0.46737859 0.51717973 0.58060075 0.73539132] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36744606 0.46737859 0.50014249 0.58060075 0.73539132] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36744606 0.43319114 0.50014249 0.58060075 0.73539132] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.3899378  0.43319114 0.50014249 0.58060075 0.73539132] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3899378  0.41839394 0.50014249 0.58060075 0.73539132] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25653802 0.41839394 0.50014249 0.58060075 0.73539132] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25653802 0.41839394 0.52766769 0.58060075 0.73539132] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25653802 0.41839394 0.52766769 0.63355542 0.73539132] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25653802 0.41839394 0.52766769 0.63355542 0.82591535] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25653802 0.41839394 0.49028457 0.63355542 0.82591535] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25653802 0.4429881  0.49028457 0.63355542 0.82591535] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25653802 0.4429881  0.53929828 0.63355542 0.82591535] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25653802 0.4429881  0.53929828 0.69936276 0.82591535] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25653802 0.4429881  0.53929828 0.69936276 0.88547062] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25653802 0.4429881  0.50635006 0.69936276 0.88547062] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25653802 0.37920255 0.50635006 0.69936276 0.88547062] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16877502 0.37920255 0.50635006 0.69936276 0.88547062] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16877502 0.37920255 0.46285223 0.69936276 0.88547062] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16877502 0.40781955 0.46285223 0.69936276 0.88547062] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16877502 0.40781955 0.44402526 0.69936276 0.88547062] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16877502 0.42020571 0.44402526 0.69936276 0.88547062] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16877502 0.42020571 0.43587647 0.69936276 0.88547062] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16877502 0.42556676 0.43587647 0.69936276 0.88547062] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16877502 0.42556676 0.52601652 0.69936276 0.88547062] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.16877502 0.42556676 0.52601652 0.76303124 0.88547062] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.16877502 0.42556676 0.52601652 0.76303124 0.84358347] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.16877502 0.42556676 0.52601652 0.68194726 0.84358347] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16877502 0.42556676 0.57936124 0.68194726 0.84358347] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.16877502 0.42556676 0.57936124 0.73724385 0.84358347] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.16877502 0.42556676 0.57936124 0.73724385 0.89709439] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16877502 0.42556676 0.52674734 0.73724385 0.89709439] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16877502 0.33771695 0.52674734 0.73724385 0.89709439] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22657094 0.33771695 0.52674734 0.73724385 0.89709439] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22657094 0.29969332 0.52674734 0.73724385 0.89709439] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.14905983 0.29969332 0.52674734 0.73724385 0.89709439] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.14905983 0.29969332 0.59875931 0.73724385 0.89709439] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.14905983 0.29969332 0.59875931 0.68986756 0.89709439] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.14905983 0.29969332 0.49644726 0.68986756 0.89709439] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14905983 0.24816081 0.49644726 0.68986756 0.89709439] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.1829628  0.24816081 0.49644726 0.68986756 0.89709439] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1829628  0.22585622 0.49644726 0.68986756 0.89709439] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.19763686 0.22585622 0.49644726 0.68986756 0.89709439] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.19763686 0.21620223 0.49644726 0.68986756 0.89709439] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.20398817 0.21620223 0.49644726 0.68986756 0.89709439] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20398817 0.21202374 0.49644726 0.68986756 0.89709439] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13420275 0.21202374 0.49644726 0.68986756 0.89709439] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.3421052631578947\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.5        0.5        0.5        0.68421053] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.68421053] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.68421053] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.5        0.68421053] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.56786704 0.68421053] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.56786704 0.64134714] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.5        0.54286339 0.64134714] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.51579178 0.54286339 0.64134714] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.5        0.51579178 0.57914688 0.64134714] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.51579178 0.57914688 0.61843125] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.5        0.51579178 0.55580552 0.61843125] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.53053368 0.55580552 0.61843125] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.5        0.53053368 0.57887816 0.61843125] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.5        0.53053368 0.57887816 0.60385906] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.5        0.53053368 0.58808165 0.60385906] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.5        0.53053368 0.58808165 0.74980572] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.5        0.51928443 0.58808165 0.74980572] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31578947 0.43213296 0.51928443 0.58808165 0.74980572] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35865286 0.43213296 0.51928443 0.58808165 0.74980572] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35865286 0.4642414  0.51928443 0.58808165 0.74980572] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35865286 0.4642414  0.49900542 0.58808165 0.74980572] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35865286 0.42534036 0.49900542 0.58808165 0.74980572] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38322194 0.42534036 0.49900542 0.58808165 0.74980572] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38322194 0.40982305 0.49900542 0.58808165 0.74980572] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24203491 0.40982305 0.49900542 0.58808165 0.74980572] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24203491 0.40982305 0.53182298 0.58808165 0.74980572] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24203491 0.40982305 0.53182298 0.6476642  0.74980572] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24203491 0.40982305 0.53182298 0.6476642  0.84198256] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24203491 0.40982305 0.48687564 0.6476642  0.84198256] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24203491 0.43821084 0.48687564 0.6476642  0.84198256] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24203491 0.43821084 0.54611353 0.6476642  0.84198256] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24203491 0.43821084 0.54611353 0.71925518 0.84198256] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24203491 0.43821084 0.54611353 0.71925518 0.90019951] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24203491 0.43821084 0.50635991 0.71925518 0.90019951] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24203491 0.3659355  0.50635991 0.71925518 0.90019951] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15286415 0.3659355  0.50635991 0.71925518 0.90019951] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15286415 0.3659355  0.4546246  0.71925518 0.90019951] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15286415 0.39861043 0.4546246  0.71925518 0.90019951] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15286415 0.39861043 0.4339878  0.71925518 0.90019951] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15286415 0.4116442  0.4339878  0.71925518 0.90019951] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15286415 0.4116442  0.42575595 0.71925518 0.90019951] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15286415 0.41684326 0.42575595 0.71925518 0.90019951] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15286415 0.41684326 0.53388724 0.71925518 0.90019951] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.15286415 0.41684326 0.53388724 0.78591888 0.90019951] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.15286415 0.41684326 0.53388724 0.78591888 0.85809612] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.15286415 0.41684326 0.53388724 0.69306512 0.85809612] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15286415 0.41684326 0.59253172 0.69306512 0.85809612] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.15286415 0.41684326 0.59253172 0.75386601 0.85809612] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15286415 0.41684326 0.59253172 0.75386601 0.9103765 ] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15286415 0.41684326 0.5278044  0.75386601 0.9103765 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15286415 0.3195878  0.5278044  0.75386601 0.9103765 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.21428866 0.3195878  0.5278044  0.75386601 0.9103765 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21428866 0.28079338 0.5278044  0.75386601 0.9103765 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1353402  0.28079338 0.5278044  0.75386601 0.9103765 ] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.1353402  0.28079338 0.61109026 0.75386601 0.9103765 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.1353402  0.28079338 0.61109026 0.70126442 0.9103765 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.1353402  0.28079338 0.48940193 0.70126442 0.9103765 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1353402  0.22720537 0.48940193 0.70126442 0.9103765 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16918526 0.22720537 0.48940193 0.70126442 0.9103765 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16918526 0.20582954 0.48940193 0.70126442 0.9103765 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18268579 0.20582954 0.48940193 0.70126442 0.9103765 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18268579 0.19730289 0.48940193 0.70126442 0.9103765 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18807104 0.19730289 0.48940193 0.70126442 0.9103765 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18807104 0.19390168 0.48940193 0.70126442 0.9103765 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11878171 0.19390168 0.48940193 0.70126442 0.9103765 ] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.3684210526315789\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.5        0.5        0.5        0.69736842] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.69736842] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.69736842] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5        0.69736842] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.57790859 0.69736842] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.57790859 0.65021322] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.5        0.5471552  0.65021322] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.51861389 0.5471552  0.65021322] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.5        0.51861389 0.587836   0.65021322] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.51861389 0.587836   0.62559063] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.5        0.51861389 0.56051148 0.62559063] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.53515242 0.56051148 0.62559063] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.5        0.53515242 0.58620062 0.62559063] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.5        0.53515242 0.58620062 0.61004194] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.5        0.53515242 0.59561167 0.61004194] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.5        0.53515242 0.59561167 0.76397276] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.5        0.52127646 0.59561167 0.76397276] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30263158 0.42209141 0.52127646 0.59561167 0.76397276] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34978678 0.42209141 0.52127646 0.59561167 0.76397276] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34978678 0.46124341 0.52127646 0.59561167 0.76397276] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34978678 0.46124341 0.4975792  0.59561167 0.76397276] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34978678 0.41724737 0.4975792  0.59561167 0.76397276] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.37641596 0.41724737 0.4975792  0.59561167 0.76397276] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37641596 0.40112971 0.4975792  0.59561167 0.76397276] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22783071 0.40112971 0.4975792  0.59561167 0.76397276] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22783071 0.40112971 0.53627623 0.59561167 0.76397276] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22783071 0.40112971 0.53627623 0.66206999 0.76397276] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22783071 0.40112971 0.53627623 0.66206999 0.85714141] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22783071 0.40112971 0.48292892 0.66206999 0.85714141] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22783071 0.43341887 0.48292892 0.66206999 0.85714141] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22783071 0.43341887 0.5536425  0.66206999 0.85714141] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22783071 0.43341887 0.5536425  0.73907187 0.85714141] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22783071 0.43341887 0.5536425  0.73907187 0.91353296] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22783071 0.43341887 0.5061858  0.73907187 0.91353296] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22783071 0.35226565 0.5061858  0.73907187 0.91353296] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13789754 0.35226565 0.5061858  0.73907187 0.91353296] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13789754 0.35226565 0.44542785 0.73907187 0.91353296] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13789754 0.3890402  0.44542785 0.73907187 0.91353296] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13789754 0.3890402  0.42316957 0.73907187 0.91353296] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13789754 0.40251232 0.42316957 0.73907187 0.91353296] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13789754 0.40251232 0.41501539 0.73907187 0.91353296] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13789754 0.40744774 0.41501539 0.73907187 0.91353296] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.13789754 0.40744774 0.54293242 0.73907187 0.91353296] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.13789754 0.40744774 0.54293242 0.80793809 0.91353296] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.13789754 0.40744774 0.54293242 0.80793809 0.87185077] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.13789754 0.40744774 0.54293242 0.70333059 0.87185077] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.13789754 0.40744774 0.60624749 0.70333059 0.87185077] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.13789754 0.40744774 0.60624749 0.76985171 0.87185077] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13789754 0.40744774 0.60624749 0.76985171 0.92243599] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13789754 0.40744774 0.5277739  0.76985171 0.92243599] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13789754 0.30104634 0.5277739  0.76985171 0.92243599] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.20229838 0.30104634 0.5277739  0.76985171 0.92243599] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20229838 0.26206689 0.5277739  0.76985171 0.92243599] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12244376 0.26206689 0.5277739  0.76985171 0.92243599] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12244376 0.26206689 0.62333093 0.76985171 0.92243599] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.12244376 0.26206689 0.62333093 0.71201456 0.92243599] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12244376 0.26206689 0.4807267  0.71201456 0.92243599] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12244376 0.20695249 0.4807267  0.71201456 0.92243599] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.15580247 0.20695249 0.4807267  0.71201456 0.92243599] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15580247 0.18676169 0.4807267  0.71201456 0.92243599] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16802322 0.18676169 0.4807267  0.71201456 0.92243599] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16802322 0.17936493 0.4807267  0.71201456 0.92243599] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.17250021 0.17936493 0.4807267  0.71201456 0.92243599] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17250021 0.17665517 0.4807267  0.71201456 0.92243599] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10440802 0.17665517 0.4807267  0.71201456 0.92243599] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.39473684210526316\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.5        0.5        0.5        0.71052632] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.71052632] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.71052632] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.5        0.71052632] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.58864266 0.71052632] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.58864266 0.65920688] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.5        0.55131943 0.65920688] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.52160818 0.55131943 0.65920688] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.5        0.52160818 0.59674573 0.65920688] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.52160818 0.59674573 0.63290745] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.5        0.52160818 0.56510887 0.63290745] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.53992426 0.56510887 0.63290745] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.5        0.53992426 0.59365564 0.63290745] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.5        0.53992426 0.59365564 0.61638037] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.5        0.53992426 0.60322395 0.61638037] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.5        0.53992426 0.60322395 0.77790442] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.5        0.52311405 0.60322395 0.77790442] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28947368 0.41135734 0.52311405 0.60322395 0.77790442] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34079312 0.41135734 0.52311405 0.60322395 0.77790442] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34079312 0.4584128  0.52311405 0.60322395 0.77790442] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34079312 0.4584128  0.49587141 0.60322395 0.77790442] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34079312 0.40888872 0.49587141 0.60322395 0.77790442] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36946495 0.40888872 0.49587141 0.60322395 0.77790442] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36946495 0.39228924 0.49587141 0.60322395 0.77790442] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21390076 0.39228924 0.49587141 0.60322395 0.77790442] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.21390076 0.39228924 0.54107248 0.60322395 0.77790442] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.21390076 0.39228924 0.54107248 0.67677362 0.77790442] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.21390076 0.39228924 0.54107248 0.67677362 0.87141835] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.21390076 0.39228924 0.4784269  0.67677362 0.87141835] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.21390076 0.42855773 0.4784269  0.67677362 0.87141835] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.21390076 0.42855773 0.56194131 0.67677362 0.87141835] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.21390076 0.42855773 0.56194131 0.7587293  0.87141835] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.21390076 0.42855773 0.56194131 0.7587293  0.92555799] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.21390076 0.42855773 0.5057798  0.7587293  0.92555799] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21390076 0.33817585 0.5057798  0.7587293  0.92555799] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12383728 0.33817585 0.5057798  0.7587293  0.92555799] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12383728 0.33817585 0.43520972 0.7587293  0.92555799] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12383728 0.37903221 0.43520972 0.7587293  0.92555799] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12383728 0.37903221 0.41155603 0.7587293  0.92555799] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12383728 0.39272645 0.41155603 0.7587293  0.92555799] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12383728 0.39272645 0.40362779 0.7587293  0.92555799] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12383728 0.39731649 0.40362779 0.7587293  0.92555799] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12383728 0.39731649 0.55314421 0.7587293  0.92555799] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12383728 0.39731649 0.55314421 0.82897296 0.92555799] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.12383728 0.39731649 0.55314421 0.82897296 0.88489061] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.12383728 0.39731649 0.55314421 0.71283454 0.88489061] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12383728 0.39731649 0.62038225 0.71283454 0.88489061] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12383728 0.39731649 0.62038225 0.7852792  0.88489061] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12383728 0.39731649 0.62038225 0.7852792  0.93335772] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12383728 0.39731649 0.52645982 0.7852792  0.93335772] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12383728 0.28216735 0.52645982 0.7852792  0.93335772] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.19050257 0.28216735 0.52645982 0.7852792  0.93335772] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.19050257 0.24357165 0.52645982 0.7852792  0.93335772] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11029096 0.24357165 0.52645982 0.7852792  0.93335772] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11029096 0.24357165 0.6354364  0.7852792  0.93335772] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.11029096 0.24357165 0.6354364  0.7221875  0.93335772] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11029096 0.24357165 0.47044072 0.7221875  0.93335772] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11029096 0.18745347 0.47044072 0.7221875  0.93335772] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14278044 0.18745347 0.47044072 0.7221875  0.93335772] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14278044 0.16864377 0.47044072 0.7221875  0.93335772] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.15367026 0.16864377 0.47044072 0.7221875  0.93335772] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15367026 0.16233914 0.47044072 0.7221875  0.93335772] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.15732032 0.16233914 0.47044072 0.7221875  0.93335772] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15732032 0.16022595 0.47044072 0.7221875  0.93335772] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09108018 0.16022595 0.47044072 0.7221875  0.93335772] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.42105263157894735\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.5        0.5        0.5        0.72368421] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.72368421] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.72368421] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.5        0.72368421] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.60006925 0.72368421] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.60006925 0.66838278] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.5        0.55530143 0.66838278] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.52474011 0.55530143 0.66838278] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.5        0.52474011 0.60589046 0.66838278] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.52474011 0.60589046 0.64042569] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.5        0.52474011 0.56958635 0.64042569] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.54480291 0.56958635 0.64042569] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.5        0.54480291 0.60127764 0.64042569] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.5        0.54480291 0.60127764 0.62291209] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.5        0.54480291 0.61095621 0.62291209] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.5        0.54480291 0.61095621 0.79160931] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.5        0.5247595  0.61095621 0.79160931] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27631579 0.39993075 0.5247595  0.61095621 0.79160931] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.33161722 0.39993075 0.5247595  0.61095621 0.79160931] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33161722 0.45577519 0.5247595  0.61095621 0.79160931] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33161722 0.45577519 0.4938981  0.61095621 0.79160931] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33161722 0.40023083 0.4938981  0.61095621 0.79160931] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36231278 0.40023083 0.4938981  0.61095621 0.79160931] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36231278 0.3832675  0.4938981  0.61095621 0.79160931] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20022549 0.3832675  0.4938981  0.61095621 0.79160931] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20022549 0.3832675  0.5462662  0.61095621 0.79160931] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20022549 0.3832675  0.5462662  0.6917747  0.79160931] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20022549 0.3832675  0.5462662  0.6917747  0.88483672] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20022549 0.3832675  0.47334573 0.6917747  0.88483672] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20022549 0.42356565 0.47334573 0.6917747  0.88483672] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20022549 0.42356565 0.57106395 0.6917747  0.88483672] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20022549 0.42356565 0.57106395 0.77814455 0.88483672] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20022549 0.42356565 0.57106395 0.77814455 0.93635714] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20022549 0.42356565 0.50507787 0.77814455 0.93635714] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20022549 0.32365031 0.50507787 0.77814455 0.93635714] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11065093 0.32365031 0.50507787 0.77814455 0.93635714] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11065093 0.32365031 0.42391291 0.77814455 0.93635714] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11065093 0.36850463 0.42391291 0.77814455 0.93635714] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11065093 0.36850463 0.399125   0.77814455 0.93635714] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11065093 0.38220322 0.399125   0.77814455 0.93635714] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11065093 0.38220322 0.39155473 0.77814455 0.93635714] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11065093 0.38638679 0.39155473 0.77814455 0.93635714] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11065093 0.38638679 0.56450281 0.77814455 0.93635714] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11065093 0.38638679 0.56450281 0.84892387 0.93635714] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.11065093 0.38638679 0.56450281 0.84892387 0.89724225] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.11065093 0.38638679 0.56450281 0.72168287 0.89724225] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11065093 0.38638679 0.6348202  0.72168287 0.89724225] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11065093 0.38638679 0.6348202  0.80022259 0.89724225] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11065093 0.38638679 0.6348202  0.80022259 0.94321282] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11065093 0.38638679 0.52367894 0.80022259 0.94321282] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11065093 0.26303127 0.52367894 0.80022259 0.94321282] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.17882108 0.26303127 0.52367894 0.80022259 0.94321282] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17882108 0.22535829 0.52367894 0.80022259 0.94321282] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09882218 0.22535829 0.52367894 0.80022259 0.94321282] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09882218 0.22535829 0.64739584 0.80022259 0.94321282] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.09882218 0.22535829 0.64739584 0.73185273 0.94321282] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09882218 0.22535829 0.45858957 0.73185273 0.94321282] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09882218 0.16875003 0.45858957 0.73185273 0.94321282] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.13010569 0.16875003 0.45858957 0.73185273 0.94321282] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13010569 0.15146177 0.45858957 0.73185273 0.94321282] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.13965973 0.15146177 0.45858957 0.73185273 0.94321282] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13965973 0.14618191 0.45858957 0.73185273 0.94321282] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14257754 0.14618191 0.45858957 0.73185273 0.94321282] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14257754 0.14456943 0.45858957 0.73185273 0.94321282] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07879285 0.14456943 0.45858957 0.73185273 0.94321282] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.4473684210526315\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.5        0.5        0.5        0.73684211] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.73684211] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.73684211] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.5        0.73684211] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.61218837 0.73684211] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.61218837 0.6777956 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5        0.55904651 0.6777956 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.5279694  0.55904651 0.6777956 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.5        0.5279694  0.61529608 0.6777956 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.5279694  0.61529608 0.64819056] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.5        0.5279694  0.57393081 0.64819056] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.54974059 0.57393081 0.64819056] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.5        0.54974059 0.60910648 0.64819056] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.5        0.54974059 0.60910648 0.62967705] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.5        0.54974059 0.61885043 0.62967705] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.5        0.54974059 0.61885043 0.80509318] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.5        0.52617926 0.61885043 0.80509318] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26315789 0.38781163 0.52617926 0.61885043 0.80509318] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.3222044  0.38781163 0.52617926 0.61885043 0.80509318] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3222044  0.45335419 0.52617926 0.61885043 0.80509318] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3222044  0.45335419 0.49168318 0.61885043 0.80509318] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3222044  0.39123061 0.49168318 0.61885043 0.80509318] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35490103 0.39123061 0.49168318 0.61885043 0.80509318] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35490103 0.37402186 0.49168318 0.61885043 0.80509318] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18679001 0.37402186 0.49168318 0.61885043 0.80509318] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18679001 0.37402186 0.5519203  0.61885043 0.80509318] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18679001 0.37402186 0.5519203  0.70707068 0.80509318] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18679001 0.37402186 0.5519203  0.70707068 0.89741747] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18679001 0.37402186 0.46765262 0.70707068 0.89741747] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18679001 0.41837327 0.46765262 0.70707068 0.89741747] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18679001 0.41837327 0.58106117 0.70707068 0.89741747] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18679001 0.41837327 0.58106117 0.79723495 0.89741747] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18679001 0.41837327 0.58106117 0.79723495 0.94600919] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18679001 0.41837327 0.50399848 0.79723495 0.94600919] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18679001 0.30867594 0.50399848 0.79723495 0.94600919] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09831053 0.30867594 0.50399848 0.79723495 0.94600919] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09831053 0.30867594 0.41147728 0.79723495 0.94600919] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09831053 0.35737131 0.41147728 0.79723495 0.94600919] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09831053 0.35737131 0.38584814 0.79723495 0.94600919] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09831053 0.37086033 0.38584814 0.79723495 0.94600919] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09831053 0.37086033 0.37874865 0.79723495 0.94600919] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09831053 0.3745969  0.37874865 0.79723495 0.94600919] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09831053 0.3745969  0.576979   0.79723495 0.94600919] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.09831053 0.3745969  0.576979   0.86770696 0.94600919] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.09831053 0.3745969  0.576979   0.86770696 0.90891866] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.09831053 0.3745969  0.576979   0.72999372 0.90891866] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09831053 0.3745969  0.64945966 0.72999372 0.90891866] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.09831053 0.3745969  0.64945966 0.81474764 0.90891866] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.09831053 0.3745969  0.64945966 0.81474764 0.95206245] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09831053 0.3745969  0.51926151 0.81474764 0.95206245] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09831053 0.24372441 0.51926151 0.81474764 0.95206245] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16719079 0.24372441 0.51926151 0.81474764 0.95206245] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16719079 0.20747165 0.51926151 0.81474764 0.95206245] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08799515 0.20747165 0.51926151 0.81474764 0.95206245] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08799515 0.20747165 0.65922862 0.81474764 0.95206245] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.08799515 0.20747165 0.65922862 0.74108074 0.95206245] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08799515 0.20747165 0.44523848 0.74108074 0.95206245] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08799515 0.15087752 0.44523848 0.74108074 0.95206245] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11778154 0.15087752 0.44523848 0.74108074 0.95206245] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11778154 0.13520047 0.44523848 0.74108074 0.95206245] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12603261 0.13520047 0.44523848 0.74108074 0.95206245] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12603261 0.1308578  0.44523848 0.74108074 0.95206245] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12831823 0.1308578  0.44523848 0.74108074 0.95206245] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12831823 0.12965485 0.44523848 0.74108074 0.95206245] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06753591 0.12965485 0.44523848 0.74108074 0.95206245] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.47368421052631576\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 6 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 5 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 8 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.5 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25 0.5  0.5  0.5  0.75] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.75] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.75] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25 0.5  0.5  0.5  0.75] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25  0.5   0.5   0.625 0.75 ] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25   0.5    0.5    0.625  0.6875] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25   0.5    0.5    0.5625 0.6875] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25    0.5     0.53125 0.5625  0.6875 ] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25    0.5     0.53125 0.625   0.6875 ] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25    0.5     0.53125 0.625   0.65625] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25     0.5      0.53125  0.578125 0.65625 ] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25      0.5       0.5546875 0.578125  0.65625  ] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25      0.5       0.5546875 0.6171875 0.65625  ] | Step: 11 | T: inf | time: 11\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25       0.5        0.5546875  0.6171875  0.63671875] | Step: 12 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25       0.5        0.5546875  0.62695312 0.63671875] | Step: 13 | T: inf | time: 13\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25       0.5        0.5546875  0.62695312 0.81835938] | Step: 14 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25       0.5        0.52734375 0.62695312 0.81835938] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25       0.375      0.52734375 0.62695312 0.81835938] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.3125     0.375      0.52734375 0.62695312 0.81835938] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3125     0.45117188 0.52734375 0.62695312 0.81835938] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3125     0.45117188 0.48925781 0.62695312 0.81835938] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3125     0.38183594 0.48925781 0.62695312 0.81835938] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34716797 0.38183594 0.48925781 0.62695312 0.81835938] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34716797 0.36450195 0.48925781 0.62695312 0.81835938] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17358398 0.36450195 0.48925781 0.62695312 0.81835938] | Step: 8 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17358398 0.36450195 0.55810547 0.62695312 0.81835938] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.17358398 0.36450195 0.55810547 0.72265625 0.81835938] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17358398 0.36450195 0.55810547 0.72265625 0.90917969] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17358398 0.36450195 0.46130371 0.72265625 0.90917969] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.17358398 0.41290283 0.46130371 0.72265625 0.90917969] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17358398 0.41290283 0.59197998 0.72265625 0.90917969] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.17358398 0.41290283 0.59197998 0.81591797 0.90917969] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17358398 0.41290283 0.59197998 0.81591797 0.95458984] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17358398 0.41290283 0.50244141 0.81591797 0.95458984] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17358398 0.29324341 0.50244141 0.81591797 0.95458984] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08679199 0.29324341 0.50244141 0.81591797 0.95458984] | Step: 2 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08679199 0.29324341 0.39784241 0.81591797 0.95458984] | Step: 0 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08679199 0.34554291 0.39784241 0.81591797 0.95458984] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08679199 0.34554291 0.37169266 0.81591797 0.95458984] | Step: 2 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08679199 0.35861778 0.37169266 0.81591797 0.95458984] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08679199 0.35861778 0.36515522 0.81591797 0.95458984] | Step: 4 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08679199 0.3618865  0.36515522 0.81591797 0.95458984] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08679199 0.3618865  0.59053659 0.81591797 0.95458984] | Step: 6 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.08679199 0.3618865  0.59053659 0.88525391 0.95458984] | Step: 7 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.08679199 0.3618865  0.59053659 0.88525391 0.91992188] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.08679199 0.3618865  0.59053659 0.73789525 0.91992188] | Step: 9 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08679199 0.3618865  0.66421592 0.73789525 0.91992188] | Step: 10 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.08679199 0.3618865  0.66421592 0.82890856 0.91992188] | Step: 11 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.08679199 0.3618865  0.66421592 0.82890856 0.95996094] | Step: 12 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08679199 0.3618865  0.51305121 0.82890856 0.95996094] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08679199 0.22433925 0.51305121 0.82890856 0.95996094] | Step: 1 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.15556562 0.22433925 0.51305121 0.82890856 0.95996094] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15556562 0.18995243 0.51305121 0.82890856 0.95996094] | Step: 3 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07778281 0.18995243 0.51305121 0.82890856 0.95996094] | Step: 4 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.07778281 0.18995243 0.67097989 0.82890856 0.95996094] | Step: 0 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.07778281 0.18995243 0.67097989 0.74994422 0.95996094] | Step: 1 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07778281 0.18995243 0.43046616 0.74994422 0.95996094] | Step: 2 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07778281 0.13386762 0.43046616 0.74994422 0.95996094] | Step: 3 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.10582522 0.13386762 0.43046616 0.74994422 0.95996094] | Step: 4 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.10582522 0.11984642 0.43046616 0.74994422 0.95996094] | Step: 5 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11283582 0.11984642 0.43046616 0.74994422 0.95996094] | Step: 6 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11283582 0.11634112 0.43046616 0.74994422 0.95996094] | Step: 7 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11458847 0.11634112 0.43046616 0.74994422 0.95996094] | Step: 8 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11458847 0.11546479 0.43046616 0.74994422 0.95996094] | Step: 9 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05729423 0.11546479 0.43046616 0.74994422 0.95996094] | Step: 10 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "alpha: 0.5\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.48684211 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48718837 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48718837 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48718837 0.5        0.51315789 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48718837 0.5        0.51315789 0.51315789] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48718837 0.5        0.51315789 0.51315789] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48718837 0.5        0.51315789 0.51315789] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.5        0.51315789 0.51315789] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50034626 0.51315789 0.51315789] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50034626 0.51315789 0.51315789] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50034626 0.51315789 0.51282075] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50034626 0.51315789 0.51282075] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50067454 0.51315789 0.51282075] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50067454 0.51315789 0.51282075] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50067454 0.51315789 0.51250111] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50067454 0.51315789 0.51250111] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50098576 0.51315789 0.51250111] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50098576 0.51315789 0.51250111] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50098576 0.51315789 0.51250111] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48787177 0.50098576 0.52596953 0.51250111] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48787177 0.50098576 0.52596953 0.52533003] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50098576 0.52596953 0.52533003] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50061356 0.52596953 0.52533003] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50061356 0.52596953 0.52533003] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48720451 0.48787177 0.50061356 0.52596953 0.52533003] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48720451 0.48787177 0.50061356 0.52596953 0.52533003] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48720451 0.48787177 0.50026069 0.52596953 0.52533003] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.48720451 0.48787177 0.50026069 0.52596953 0.52533003] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48720451 0.48787177 0.50026069 0.52596953 0.52533003] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.48720451 0.47503304 0.50026069 0.52596953 0.52533003] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47438334 0.47503304 0.50026069 0.52596953 0.52533003] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47438334 0.47503304 0.50026069 0.52596953 0.52533003] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47438334 0.47503304 0.50092041 0.52596953 0.52533003] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47438334 0.47503304 0.50092041 0.53844402 0.52533003] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47438334 0.47503304 0.50092041 0.53844402 0.53782134] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47438334 0.47503304 0.50092041 0.53844402 0.53782134] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47438334 0.47503304 0.50092041 0.53844402 0.53782134] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47438334 0.47670175 0.50092041 0.53844402 0.53782134] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47438334 0.47670175 0.50189149 0.53844402 0.53782134] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47438334 0.47670175 0.50189149 0.55059023 0.53782134] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47438334 0.47670175 0.50189149 0.55059023 0.54998394] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47438334 0.47670175 0.50189149 0.55059023 0.54998394] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47438334 0.47670175 0.50116759 0.55059023 0.54998394] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47438334 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46189957 0.46415697 0.50116759 0.55059023 0.54998394] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50116759 0.55059023 0.54998394] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50245223 0.55059023 0.54998394] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50245223 0.55059023 0.54998394] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50245223 0.55059023 0.5487331 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50245223 0.55059023 0.5487331 ] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50367015 0.55059023 0.5487331 ] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46189957 0.46643153 0.50367015 0.5624168  0.5487331 ] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46189957 0.46643153 0.50367015 0.5624168  0.56060855] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50367015 0.5624168  0.56060855] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50257092 0.5624168  0.56060855] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50257092 0.5624168  0.56060855] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46189957 0.46643153 0.50257092 0.5624168  0.56060855] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46189957 0.45415702 0.50257092 0.5624168  0.56060855] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50257092 0.5624168  0.56060855] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50257092 0.5624168  0.56060855] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50257092 0.5624168  0.56060855] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50257092 0.55956786 0.56060855] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44974432 0.45415702 0.50118075 0.55956786 0.56060855] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44974432 0.44220552 0.50118075 0.55956786 0.56060855] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.43790894 0.44220552 0.50118075 0.55956786 0.56060855] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.02631578947368421\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.47368421 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47506925 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47506925 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47506925 0.5        0.52631579 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47506925 0.5        0.52631579 0.52631579] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47506925 0.5        0.52631579 0.52631579] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47506925 0.5        0.52631579 0.52631579] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.5        0.52631579 0.52631579] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50138504 0.52631579 0.52631579] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50138504 0.52631579 0.52631579] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50138504 0.52631579 0.52500364] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50138504 0.52631579 0.52500364] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50262813 0.52631579 0.52500364] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50262813 0.52631579 0.52500364] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50262813 0.52631579 0.52382599] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50262813 0.52631579 0.52382599] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.5037438  0.52631579 0.52382599] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.5037438  0.52631579 0.52382599] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.5037438  0.52631579 0.52382599] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47776644 0.5037438  0.55124654 0.52382599] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47776644 0.5037438  0.55124654 0.54888778] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47776644 0.5037438  0.55124654 0.54888778] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50216172 0.55124654 0.54888778] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50216172 0.55124654 0.54888778] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47518303 0.47776644 0.50216172 0.55124654 0.54888778] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47518303 0.47776644 0.50216172 0.55124654 0.54888778] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47518303 0.47776644 0.50074179 0.55124654 0.54888778] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.47518303 0.47776644 0.50074179 0.55124654 0.54888778] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47518303 0.47776644 0.50074179 0.55124654 0.54888778] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47518303 0.45262084 0.50074179 0.55124654 0.54888778] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.45017339 0.45262084 0.50074179 0.55124654 0.54888778] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.45017339 0.45262084 0.50074179 0.55124654 0.54888778] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.45017339 0.45262084 0.50327579 0.55124654 0.54888778] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.45017339 0.45262084 0.50327579 0.57486514 0.54888778] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.45017339 0.45262084 0.50327579 0.57486514 0.57263052] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45017339 0.45262084 0.50327579 0.57486514 0.57263052] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.45017339 0.45262084 0.50327579 0.57486514 0.57263052] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.45017339 0.45905475 0.50327579 0.57486514 0.57263052] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.45017339 0.45905475 0.50692604 0.57486514 0.57263052] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.45017339 0.45905475 0.50692604 0.59724066 0.57263052] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.45017339 0.45905475 0.50692604 0.59724066 0.59512366] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45017339 0.45905475 0.50692604 0.59724066 0.59512366] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45017339 0.45905475 0.50393906 0.59724066 0.59512366] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.45017339 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42648006 0.43489397 0.50393906 0.59724066 0.59512366] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50393906 0.59724066 0.59512366] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50873824 0.59724066 0.59512366] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50873824 0.59724066 0.59512366] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50873824 0.59724066 0.59057705] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50873824 0.59724066 0.59057705] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42648006 0.44343853 0.51304555 0.59724066 0.59057705] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42648006 0.44343853 0.51304555 0.61843852 0.59057705] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42648006 0.44343853 0.51304555 0.61843852 0.61212563] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42648006 0.44343853 0.51304555 0.61843852 0.61212563] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50848947 0.61843852 0.61212563] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50848947 0.61843852 0.61212563] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42648006 0.44343853 0.50848947 0.61843852 0.61212563] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42648006 0.42009966 0.50848947 0.61843852 0.61212563] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40403374 0.42009966 0.50848947 0.61843852 0.61212563] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40403374 0.42009966 0.50848947 0.61843852 0.61212563] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40403374 0.42009966 0.50848947 0.61843852 0.61212563] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40403374 0.42009966 0.50848947 0.60799963 0.61212563] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40403374 0.42009966 0.5029918  0.60799963 0.61212563] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40403374 0.39798915 0.5029918  0.60799963 0.61212563] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3827688  0.39798915 0.5029918  0.60799963 0.61212563] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.05263157894736842\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.46052632 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46364266 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46364266 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46364266 0.5        0.53947368 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46364266 0.5        0.53947368 0.53947368] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46364266 0.5        0.53947368 0.53947368] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46364266 0.5        0.53947368 0.53947368] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.5        0.53947368 0.53947368] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50311634 0.53947368 0.53947368] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50311634 0.53947368 0.53947368] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50311634 0.53947368 0.53660337] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50311634 0.53947368 0.53660337] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50576006 0.53947368 0.53660337] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50576006 0.53947368 0.53660337] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50576006 0.53947368 0.53416837] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50576006 0.53947368 0.53416837] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50800282 0.53947368 0.53416837] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50800282 0.53947368 0.53416837] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50800282 0.53947368 0.53416837] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46962932 0.50800282 0.57583102 0.53416837] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46962932 0.50800282 0.57583102 0.57094455] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50800282 0.57583102 0.57094455] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50425467 0.57583102 0.57094455] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50425467 0.57583102 0.57094455] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46397855 0.46962932 0.50425467 0.57583102 0.57094455] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46397855 0.46962932 0.50425467 0.57583102 0.57094455] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46397855 0.46962932 0.50107498 0.57583102 0.57094455] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46397855 0.46962932 0.50107498 0.57583102 0.57094455] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46397855 0.46962932 0.50107498 0.57583102 0.57094455] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46397855 0.43255332 0.50107498 0.57583102 0.57094455] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42734867 0.43255332 0.50107498 0.57583102 0.57094455] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42734867 0.43255332 0.50107498 0.57583102 0.57094455] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42734867 0.43255332 0.506591   0.57583102 0.57094455] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42734867 0.43255332 0.506591   0.60931805 0.57094455] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42734867 0.43255332 0.506591   0.60931805 0.60481735] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42734867 0.43255332 0.506591   0.60931805 0.60481735] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42734867 0.43255332 0.506591   0.60931805 0.60481735] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42734867 0.44650843 0.506591   0.60931805 0.60481735] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42734867 0.44650843 0.51434571 0.60931805 0.60481735] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42734867 0.44650843 0.51434571 0.64016136 0.60481735] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42734867 0.44650843 0.51434571 0.64016136 0.63601598] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42734867 0.44650843 0.51434571 0.64016136 0.63601598] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42734867 0.44650843 0.50747752 0.64016136 0.63601598] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42734867 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39361062 0.41125776 0.50747752 0.64016136 0.63601598] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39361062 0.4293291  0.50747752 0.64016136 0.63601598] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39361062 0.4293291  0.5176253  0.64016136 0.63601598] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39361062 0.4293291  0.5176253  0.64016136 0.63601598] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39361062 0.4293291  0.5176253  0.64016136 0.62666935] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39361062 0.4293291  0.5176253  0.64016136 0.62666935] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39361062 0.4293291  0.52623404 0.64016136 0.62666935] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39361062 0.4293291  0.52623404 0.66856967 0.62666935] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39361062 0.4293291  0.52623404 0.66856967 0.65614282] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39361062 0.4293291  0.52623404 0.66856967 0.65614282] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39361062 0.4293291  0.51576377 0.66856967 0.65614282] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39361062 0.4293291  0.51576377 0.66856967 0.65614282] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39361062 0.4293291  0.51576377 0.66856967 0.65614282] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39361062 0.3954347  0.51576377 0.66856967 0.65614282] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36253609 0.3954347  0.51576377 0.66856967 0.65614282] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36253609 0.3954347  0.51576377 0.66856967 0.65614282] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36253609 0.3954347  0.51576377 0.66856967 0.65614282] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36253609 0.3954347  0.51576377 0.64700639 0.65614282] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36253609 0.3954347  0.50366684 0.64700639 0.65614282] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36253609 0.36421617 0.50366684 0.64700639 0.65614282] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33391482 0.36421617 0.50366684 0.64700639 0.65614282] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.07894736842105263\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.44736842 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.45290859 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.45290859 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.45290859 0.5        0.55263158 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.45290859 0.5        0.55263158 0.55263158] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.45290859 0.5        0.55263158 0.55263158] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.45290859 0.5        0.55263158 0.55263158] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.5        0.55263158 0.55263158] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50554017 0.55263158 0.55263158] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50554017 0.55263158 0.55263158] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50554017 0.55263158 0.54767459] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50554017 0.55263158 0.54767459] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50997537 0.55263158 0.54767459] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50997537 0.55263158 0.54767459] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50997537 0.55263158 0.54370625] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50997537 0.55263158 0.54370625] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.51352599 0.55263158 0.54370625] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.51352599 0.55263158 0.54370625] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.51352599 0.55263158 0.54370625] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.46340574 0.51352599 0.59972299 0.54370625] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.46340574 0.51352599 0.59972299 0.59173717] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.46340574 0.51352599 0.59972299 0.59173717] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50656203 0.59972299 0.59173717] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.46340574 0.50656203 0.59972299 0.59173717] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.45359933 0.46340574 0.50656203 0.59972299 0.59173717] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.45359933 0.46340574 0.50656203 0.59972299 0.59173717] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45359933 0.46340574 0.50098701 0.59972299 0.59173717] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.45359933 0.46340574 0.50098701 0.59972299 0.59173717] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.45359933 0.46340574 0.50098701 0.59972299 0.59173717] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.45359933 0.41462619 0.50098701 0.59972299 0.59173717] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40585203 0.41462619 0.50098701 0.59972299 0.59173717] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40585203 0.41462619 0.50098701 0.59972299 0.59173717] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40585203 0.41462619 0.51053966 0.59972299 0.59173717] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40585203 0.41462619 0.51053966 0.64185741 0.59173717] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40585203 0.41462619 0.51053966 0.64185741 0.63471221] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40585203 0.41462619 0.51053966 0.64185741 0.63471221] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40585203 0.41462619 0.51053966 0.64185741 0.63471221] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40585203 0.43854527 0.51053966 0.64185741 0.63471221] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40585203 0.43854527 0.52361045 0.64185741 0.63471221] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40585203 0.43854527 0.52361045 0.67955663 0.63471221] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40585203 0.43854527 0.52361045 0.67955663 0.67316355] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40585203 0.43854527 0.52361045 0.67955663 0.67316355] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40585203 0.43854527 0.51121483 0.67955663 0.67316355] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40585203 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36313076 0.39238261 0.51121483 0.67955663 0.67316355] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36313076 0.42261145 0.51121483 0.67955663 0.67316355] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36313076 0.42261145 0.52826206 0.67955663 0.67316355] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36313076 0.42261145 0.52826206 0.67955663 0.67316355] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36313076 0.42261145 0.52826206 0.67955663 0.65791076] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36313076 0.42261145 0.52826206 0.67955663 0.65791076] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36313076 0.42261145 0.5419093  0.67955663 0.65791076] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36313076 0.42261145 0.5419093  0.71328751 0.65791076] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36313076 0.42261145 0.5419093  0.71328751 0.69392016] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36313076 0.42261145 0.5419093  0.71328751 0.69392016] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36313076 0.42261145 0.5230905  0.71328751 0.69392016] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36313076 0.42261145 0.5230905  0.71328751 0.69392016] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36313076 0.42261145 0.5230905  0.71328751 0.69392016] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36313076 0.37812604 0.5230905  0.71328751 0.69392016] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32490647 0.37812604 0.5230905  0.71328751 0.69392016] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32490647 0.37812604 0.5230905  0.71328751 0.69392016] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32490647 0.37812604 0.5230905  0.71328751 0.69392016] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32490647 0.37812604 0.5230905  0.67800736 0.69392016] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32490647 0.37812604 0.50222903 0.67800736 0.69392016] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32490647 0.3383233  0.50222903 0.67800736 0.69392016] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29070579 0.3383233  0.50222903 0.67800736 0.69392016] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.10526315789473684\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.43421053 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.44286704 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.44286704 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.44286704 0.5        0.56578947 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.44286704 0.5        0.56578947 0.56578947] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.44286704 0.5        0.56578947 0.56578947] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.44286704 0.5        0.56578947 0.56578947] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.5        0.56578947 0.56578947] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.50865651 0.56578947 0.56578947] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.50865651 0.56578947 0.56578947] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.45904104 0.50865651 0.56578947 0.55827198] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.50865651 0.56578947 0.55827198] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.51518486 0.56578947 0.55827198] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.51518486 0.56578947 0.55827198] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.45904104 0.51518486 0.56578947 0.55260262] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.51518486 0.56578947 0.55260262] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52010825 0.56578947 0.55260262] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52010825 0.56578947 0.55260262] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52010825 0.56578947 0.55260262] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.45904104 0.52010825 0.62292244 0.55260262] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.45904104 0.52010825 0.62292244 0.6114707 ] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52010825 0.62292244 0.6114707 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43421053 0.45904104 0.50880592 0.62292244 0.6114707 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.45904104 0.50880592 0.62292244 0.6114707 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44402571 0.45904104 0.50880592 0.62292244 0.6114707 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44402571 0.45904104 0.50880592 0.62292244 0.6114707 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44402571 0.45904104 0.50028221 0.62292244 0.6114707 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44402571 0.45904104 0.50028221 0.62292244 0.6114707 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44402571 0.45904104 0.50028221 0.62292244 0.6114707 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44402571 0.3986409  0.50028221 0.62292244 0.6114707 ] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38560127 0.3986409  0.50028221 0.62292244 0.6114707 ] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38560127 0.3986409  0.50028221 0.62292244 0.6114707 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38560127 0.3986409  0.51491227 0.62292244 0.6114707 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38560127 0.3986409  0.51491227 0.67253791 0.6114707 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38560127 0.3986409  0.51491227 0.67253791 0.66259297] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38560127 0.3986409  0.51491227 0.67253791 0.66259297] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38560127 0.3986409  0.51491227 0.67253791 0.66259297] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38560127 0.43467998 0.51491227 0.67253791 0.66259297] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38560127 0.43467998 0.53434394 0.67253791 0.66259297] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38560127 0.43467998 0.53434394 0.71562502 0.66259297] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38560127 0.43467998 0.53434394 0.71562502 0.70698864] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38560127 0.43467998 0.53434394 0.71562502 0.70698864] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38560127 0.43467998 0.51477254 0.71562502 0.70698864] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38560127 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33486426 0.37748525 0.51477254 0.71562502 0.70698864] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33486426 0.42197732 0.51477254 0.71562502 0.70698864] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33486426 0.42197732 0.54006413 0.71562502 0.70698864] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.33486426 0.42197732 0.54006413 0.71562502 0.70698864] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.33486426 0.42197732 0.54006413 0.71562502 0.68502488] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33486426 0.42197732 0.54006413 0.71562502 0.68502488] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33486426 0.42197732 0.55913791 0.71562502 0.68502488] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33486426 0.42197732 0.55913791 0.75304278 0.68502488] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33486426 0.42197732 0.55913791 0.75304278 0.72646898] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33486426 0.42197732 0.55913791 0.75304278 0.72646898] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33486426 0.42197732 0.52962822 0.75304278 0.72646898] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.33486426 0.42197732 0.52962822 0.75304278 0.72646898] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33486426 0.42197732 0.52962822 0.75304278 0.72646898] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33486426 0.36645399 0.52962822 0.75304278 0.72646898] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29080318 0.36645399 0.52962822 0.75304278 0.72646898] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.29080318 0.36645399 0.52962822 0.75304278 0.72646898] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.29080318 0.36645399 0.52962822 0.75304278 0.72646898] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.29080318 0.36645399 0.52962822 0.70217584 0.72646898] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29080318 0.36645399 0.49820387 0.70217584 0.72646898] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29080318 0.31823636 0.49820387 0.70217584 0.72646898] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2525396  0.31823636 0.49820387 0.70217584 0.72646898] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.13157894736842105\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.42105263 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.43351801 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.43351801 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.43351801 0.5        0.57894737 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.43351801 0.5        0.57894737 0.57894737] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.43351801 0.5        0.57894737 0.57894737] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.43351801 0.5        0.57894737 0.57894737] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.5        0.57894737 0.57894737] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.51246537 0.57894737 0.57894737] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.51246537 0.57894737 0.57894737] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.45648054 0.51246537 0.57894737 0.56845021] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.51246537 0.57894737 0.56845021] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52130509 0.57894737 0.56845021] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52130509 0.57894737 0.56845021] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52130509 0.57894737 0.56100624] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52130509 0.57894737 0.56100624] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52757369 0.57894737 0.56100624] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52757369 0.57894737 0.56100624] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52757369 0.57894737 0.56100624] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.45648054 0.52757369 0.64542936 0.56100624] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.45648054 0.52757369 0.64542936 0.63032105] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.45648054 0.52757369 0.64542936 0.63032105] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42105263 0.45648054 0.51075457 0.64542936 0.63032105] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.45648054 0.51075457 0.64542936 0.63032105] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.4352161  0.45648054 0.51075457 0.64542936 0.63032105] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.4352161  0.45648054 0.51075457 0.64542936 0.63032105] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.4352161  0.45648054 0.49882745 0.64542936 0.63032105] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.4352161  0.45648054 0.49882745 0.64542936 0.63032105] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.4352161  0.45648054 0.49882745 0.64542936 0.63032105] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.4352161  0.38440466 0.49882745 0.64542936 0.63032105] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36649777 0.38440466 0.49882745 0.64542936 0.63032105] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36649777 0.38440466 0.49882745 0.64542936 0.63032105] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36649777 0.38440466 0.51958959 0.64542936 0.63032105] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36649777 0.38440466 0.51958959 0.7014142  0.63032105] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36649777 0.38440466 0.51958959 0.7014142  0.68869141] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36649777 0.38440466 0.51958959 0.7014142  0.68869141] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36649777 0.38440466 0.51958959 0.7014142  0.68869141] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36649777 0.4344588  0.51958959 0.7014142  0.68869141] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36649777 0.4344588  0.54628988 0.7014142  0.68869141] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36649777 0.4344588  0.54628988 0.74855933 0.68869141] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36649777 0.4344588  0.54628988 0.74855933 0.7378454 ] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36649777 0.4344588  0.54628988 0.74855933 0.7378454 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36649777 0.4344588  0.51790165 0.74855933 0.7378454 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36649777 0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3086297  0.36586004 0.51790165 0.74855933 0.7378454 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3086297  0.42628624 0.51790165 0.74855933 0.7378454 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3086297  0.42628624 0.55262961 0.74855933 0.7378454 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.3086297  0.42628624 0.55262961 0.74855933 0.7378454 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.3086297  0.42628624 0.55262961 0.74855933 0.7086008 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3086297  0.42628624 0.55262961 0.74855933 0.7086008 ] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3086297  0.42628624 0.57725664 0.74855933 0.7086008 ] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3086297  0.42628624 0.57725664 0.78826049 0.7086008 ] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3086297  0.42628624 0.57725664 0.78826049 0.7546112 ] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3086297  0.42628624 0.57725664 0.78826049 0.7546112 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3086297  0.42628624 0.53484186 0.78826049 0.7546112 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.3086297  0.42628624 0.53484186 0.78826049 0.7546112 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3086297  0.42628624 0.53484186 0.78826049 0.7546112 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3086297  0.35897789 0.53484186 0.78826049 0.7546112 ] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25989869 0.35897789 0.53484186 0.78826049 0.7546112 ] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25989869 0.35897789 0.53484186 0.78826049 0.7546112 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25989869 0.35897789 0.53484186 0.78826049 0.7546112 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25989869 0.35897789 0.53484186 0.72047902 0.7546112 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25989869 0.35897789 0.49142978 0.72047902 0.7546112 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25989869 0.30229717 0.49142978 0.72047902 0.7546112 ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21886206 0.30229717 0.49142978 0.72047902 0.7546112 ] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.15789473684210525\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.40789474 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.4248615  0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.4248615  0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.4248615  0.5        0.59210526 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.4248615  0.5        0.59210526 0.59210526] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.4248615  0.5        0.59210526 0.59210526] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.4248615  0.5        0.59210526 0.59210526] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.5        0.59210526 0.59210526] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.51696676 0.59210526 0.59210526] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.51696676 0.59210526 0.59210526] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.45566956 0.51696676 0.59210526 0.57826396] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.51696676 0.59210526 0.57826396] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.52825835 0.59210526 0.57826396] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.52825835 0.59210526 0.57826396] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.45566956 0.52825835 0.59210526 0.5690524 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.52825835 0.59210526 0.5690524 ] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.53577304 0.59210526 0.5690524 ] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.53577304 0.59210526 0.5690524 ] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.53577304 0.59210526 0.5690524 ] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.45566956 0.53577304 0.66724377 0.5690524 ] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.45566956 0.53577304 0.66724377 0.64843748] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.45566956 0.53577304 0.66724377 0.64843748] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40789474 0.45566956 0.51221651 0.66724377 0.64843748] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.45566956 0.51221651 0.66724377 0.64843748] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42711191 0.45566956 0.51221651 0.66724377 0.64843748] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42711191 0.45566956 0.51221651 0.66724377 0.64843748] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42711191 0.45566956 0.49653935 0.66724377 0.64843748] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42711191 0.45566956 0.49653935 0.66724377 0.64843748] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42711191 0.45566956 0.49653935 0.66724377 0.64843748] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42711191 0.37173043 0.49653935 0.66724377 0.64843748] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3484334  0.37173043 0.49653935 0.66724377 0.64843748] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3484334  0.37173043 0.49653935 0.66724377 0.64843748] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3484334  0.37173043 0.52452058 0.66724377 0.64843748] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3484334  0.37173043 0.52452058 0.72854097 0.64843748] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3484334  0.37173043 0.52452058 0.72854097 0.713199  ] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3484334  0.37173043 0.52452058 0.72854097 0.713199  ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.3484334  0.37173043 0.52452058 0.72854097 0.713199  ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.3484334  0.43745869 0.52452058 0.72854097 0.713199  ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.3484334  0.43745869 0.55927713 0.72854097 0.713199  ] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3484334  0.43745869 0.55927713 0.77854658 0.713199  ] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.3484334  0.43745869 0.55927713 0.77854658 0.76603076] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.3484334  0.43745869 0.55927713 0.77854658 0.76603076] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.3484334  0.43745869 0.5204375  0.77854658 0.76603076] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.3484334  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.2842483  0.35687419 0.5204375  0.77854658 0.76603076] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.2842483  0.43455068 0.5204375  0.77854658 0.76603076] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.2842483  0.43455068 0.56567836 0.77854658 0.76603076] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.2842483  0.43455068 0.56567836 0.77854658 0.76603076] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.2842483  0.43455068 0.56567836 0.77854658 0.72912374] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.2842483  0.43455068 0.56567836 0.77854658 0.72912374] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.2842483  0.43455068 0.59578672 0.77854658 0.72912374] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2842483  0.43455068 0.59578672 0.81934063 0.72912374] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2842483  0.43455068 0.59578672 0.81934063 0.779022  ] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2842483  0.43455068 0.59578672 0.81934063 0.779022  ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2842483  0.43455068 0.53839807 0.81934063 0.779022  ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.2842483  0.43455068 0.53839807 0.81934063 0.779022  ] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2842483  0.43455068 0.53839807 0.81934063 0.779022  ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2842483  0.35450187 0.53839807 0.81934063 0.779022  ] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23188677 0.35450187 0.53839807 0.81934063 0.779022  ] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.23188677 0.35450187 0.53839807 0.81934063 0.779022  ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.23188677 0.35450187 0.53839807 0.81934063 0.779022  ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.23188677 0.35450187 0.53839807 0.73371244 0.779022  ] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23188677 0.35450187 0.48193546 0.73371244 0.779022  ] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23188677 0.2891989  0.48193546 0.73371244 0.779022  ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18917079 0.2891989  0.48193546 0.73371244 0.779022  ] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.18421052631578946\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.39473684 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.41689751 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.41689751 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.41689751 0.5        0.60526316 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.41689751 0.5        0.60526316 0.60526316] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.41689751 0.5        0.60526316 0.60526316] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.41689751 0.5        0.60526316 0.60526316] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.5        0.60526316 0.60526316] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.52216066 0.60526316 0.60526316] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.52216066 0.60526316 0.60526316] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.45655343 0.52216066 0.60526316 0.5877679 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.52216066 0.60526316 0.5877679 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.53597271 0.60526316 0.5877679 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.53597271 0.60526316 0.5877679 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.45655343 0.53597271 0.60526316 0.57686365] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.53597271 0.60526316 0.57686365] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.54458133 0.60526316 0.57686365] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.54458133 0.60526316 0.57686365] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.54458133 0.60526316 0.57686365] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.45655343 0.54458133 0.68836565 0.57686365] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.45655343 0.54458133 0.68836565 0.66594498] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.45655343 0.54458133 0.68836565 0.66594498] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39473684 0.45655343 0.51303512 0.68836565 0.66594498] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.45655343 0.51303512 0.68836565 0.66594498] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.41964174 0.45655343 0.51303512 0.68836565 0.66594498] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.41964174 0.45655343 0.51303512 0.68836565 0.66594498] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41964174 0.45655343 0.49337336 0.68836565 0.66594498] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41964174 0.45655343 0.49337336 0.68836565 0.66594498] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41964174 0.45655343 0.49337336 0.68836565 0.66594498] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.41964174 0.36043692 0.49337336 0.68836565 0.66594498] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33129611 0.36043692 0.49337336 0.68836565 0.66594498] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33129611 0.36043692 0.49337336 0.68836565 0.66594498] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33129611 0.36043692 0.52970423 0.68836565 0.66594498] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33129611 0.36043692 0.52970423 0.75397288 0.66594498] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33129611 0.36043692 0.52970423 0.75397288 0.73627236] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33129611 0.36043692 0.52970423 0.75397288 0.73627236] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33129611 0.36043692 0.52970423 0.75397288 0.73627236] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33129611 0.4432866  0.52970423 0.75397288 0.73627236] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33129611 0.4432866  0.57319225 0.75397288 0.73627236] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33129611 0.4432866  0.57319225 0.80576807 0.73627236] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33129611 0.4432866  0.57319225 0.80576807 0.79179397] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33129611 0.4432866  0.57319225 0.80576807 0.79179397] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33129611 0.4432866  0.52226675 0.80576807 0.79179397] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33129611 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26154956 0.3499631  0.52226675 0.80576807 0.79179397] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26154956 0.44592204 0.52226675 0.80576807 0.79179397] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26154956 0.44592204 0.57900932 0.80576807 0.79179397] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26154956 0.44592204 0.57900932 0.80576807 0.79179397] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26154956 0.44592204 0.57900932 0.80576807 0.7469972 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26154956 0.44592204 0.57900932 0.80576807 0.7469972 ] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26154956 0.44592204 0.61437519 0.80576807 0.7469972 ] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26154956 0.44592204 0.61437519 0.846659   0.7469972 ] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26154956 0.44592204 0.61437519 0.846659   0.80026095] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26154956 0.44592204 0.61437519 0.846659   0.80026095] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26154956 0.44592204 0.54009611 0.846659   0.80026095] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.26154956 0.44592204 0.54009611 0.846659   0.80026095] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26154956 0.44592204 0.54009611 0.846659   0.80026095] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26154956 0.35204372 0.54009611 0.846659   0.80026095] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2064865  0.35204372 0.54009611 0.846659   0.80026095] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.2064865  0.35204372 0.54009611 0.846659   0.80026095] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.2064865  0.35204372 0.54009611 0.846659   0.80026095] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2064865  0.35204372 0.54009611 0.74252947 0.80026095] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2064865  0.35204372 0.46986251 0.74252947 0.80026095] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2064865  0.27792925 0.46986251 0.74252947 0.80026095] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16301566 0.27792925 0.46986251 0.74252947 0.80026095] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.21052631578947367\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.38157895 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.40962604 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.40962604 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.40962604 0.5        0.61842105 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.40962604 0.5        0.61842105 0.61842105] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.40962604 0.5        0.61842105 0.61842105] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.40962604 0.5        0.61842105 0.61842105] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.5        0.61842105 0.61842105] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.52804709 0.61842105 0.61842105] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.52804709 0.61842105 0.61842105] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.45907749 0.52804709 0.61842105 0.59701669] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.52804709 0.61842105 0.59701669] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.544382   0.61842105 0.59701669] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.544382   0.61842105 0.59701669] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.45907749 0.544382   0.61842105 0.58455058] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.544382   0.61842105 0.58455058] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.55389561 0.61842105 0.58455058] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.55389561 0.61842105 0.58455058] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.55389561 0.61842105 0.58455058] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.45907749 0.55389561 0.70879501 0.58455058] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.45907749 0.55389561 0.70879501 0.6829465 ] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.45907749 0.55389561 0.70879501 0.6829465 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38157895 0.45907749 0.51308377 0.70879501 0.6829465 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.45907749 0.51308377 0.70879501 0.6829465 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.41272483 0.45907749 0.51308377 0.70879501 0.6829465 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.41272483 0.45907749 0.51308377 0.70879501 0.6829465 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41272483 0.45907749 0.48931455 0.70879501 0.6829465 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41272483 0.45907749 0.48931455 0.70879501 0.6829465 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41272483 0.45907749 0.48931455 0.70879501 0.6829465 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.41272483 0.35034861 0.48931455 0.70879501 0.6829465 ] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.31497421 0.35034861 0.48931455 0.70879501 0.6829465 ] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31497421 0.35034861 0.48931455 0.70879501 0.6829465 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31497421 0.35034861 0.53517474 0.70879501 0.6829465 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31497421 0.35034861 0.53517474 0.77776462 0.6829465 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31497421 0.35034861 0.53517474 0.77776462 0.75803812] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31497421 0.35034861 0.53517474 0.77776462 0.75803812] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31497421 0.35034861 0.53517474 0.77776462 0.75803812] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31497421 0.45157872 0.53517474 0.77776462 0.75803812] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31497421 0.45157872 0.58795817 0.77776462 0.75803812] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31497421 0.45157872 0.58795817 0.83039931 0.75803812] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31497421 0.45157872 0.58795817 0.83039931 0.81534488] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31497421 0.45157872 0.58795817 0.83039931 0.81534488] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31497421 0.45157872 0.52330408 0.83039931 0.81534488] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.31497421 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24037505 0.34462586 0.52330408 0.83039931 0.81534488] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24037505 0.45967747 0.52330408 0.83039931 0.81534488] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24037505 0.45967747 0.59247164 0.83039931 0.81534488] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.24037505 0.45967747 0.59247164 0.83039931 0.81534488] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.24037505 0.45967747 0.59247164 0.83039931 0.76255911] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24037505 0.45967747 0.59247164 0.83039931 0.76255911] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24037505 0.45967747 0.63275551 0.83039931 0.76255911] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24037505 0.45967747 0.63275551 0.8705679  0.76255911] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24037505 0.45967747 0.63275551 0.8705679  0.81879511] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24037505 0.45967747 0.63275551 0.8705679  0.81879511] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24037505 0.45967747 0.5398233  0.8705679  0.81879511] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.24037505 0.45967747 0.5398233  0.8705679  0.81879511] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24037505 0.45967747 0.5398233  0.8705679  0.81879511] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24037505 0.35080649 0.5398233  0.8705679  0.81879511] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18344412 0.35080649 0.5398233  0.8705679  0.81879511] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18344412 0.35080649 0.5398233  0.8705679  0.81879511] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.18344412 0.35080649 0.5398233  0.8705679  0.81879511] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18344412 0.35080649 0.5398233  0.74746651 0.81879511] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18344412 0.35080649 0.4554177  0.74746651 0.81879511] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18344412 0.26772074 0.4554177  0.74746651 0.81879511] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13999683 0.26772074 0.4554177  0.74746651 0.81879511] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.23684210526315788\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.36842105 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.40304709 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.40304709 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.40304709 0.5        0.63157895 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.40304709 0.5        0.63157895 0.63157895] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.40304709 0.5        0.63157895 0.63157895] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.40304709 0.5        0.63157895 0.63157895] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.5        0.63157895 0.63157895] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.53462604 0.63157895 0.63157895] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.53462604 0.63157895 0.63157895] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.46318705 0.53462604 0.63157895 0.60606502] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.53462604 0.63157895 0.60606502] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.55342577 0.63157895 0.60606502] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.55342577 0.63157895 0.60606502] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.46318705 0.55342577 0.63157895 0.59221259] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.55342577 0.63157895 0.59221259] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.56363283 0.63157895 0.59221259] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.56363283 0.63157895 0.59221259] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.56363283 0.63157895 0.59221259] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.46318705 0.56363283 0.72853186 0.59221259] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.46318705 0.56363283 0.72853186 0.69952507] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.46318705 0.56363283 0.72853186 0.69952507] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36842105 0.46318705 0.51226131 0.72853186 0.69952507] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.46318705 0.51226131 0.72853186 0.69952507] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40627375 0.46318705 0.51226131 0.72853186 0.69952507] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40627375 0.46318705 0.51226131 0.72853186 0.69952507] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40627375 0.46318705 0.48436985 0.72853186 0.69952507] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40627375 0.46318705 0.48436985 0.72853186 0.69952507] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40627375 0.46318705 0.48436985 0.72853186 0.69952507] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40627375 0.34129572 0.48436985 0.72853186 0.69952507] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29935961 0.34129572 0.48436985 0.72853186 0.69952507] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.29935961 0.34129572 0.48436985 0.72853186 0.69952507] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.29935961 0.34129572 0.54098964 0.72853186 0.69952507] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.29935961 0.34129572 0.54098964 0.79997084 0.69952507] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.29935961 0.34129572 0.54098964 0.79997084 0.77859742] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.29935961 0.34129572 0.54098964 0.79997084 0.77859742] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.29935961 0.34129572 0.54098964 0.79997084 0.77859742] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.29935961 0.4619997  0.54098964 0.79997084 0.77859742] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.29935961 0.4619997  0.603518   0.79997084 0.77859742] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.29935961 0.4619997  0.603518   0.85261009 0.77859742] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.29935961 0.4619997  0.603518   0.85261009 0.83686125] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.29935961 0.4619997  0.603518   0.85261009 0.83686125] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.29935961 0.4619997  0.52347632 0.85261009 0.83686125] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29935961 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22058076 0.34042083 0.52347632 0.85261009 0.83686125] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22058076 0.47520748 0.52347632 0.85261009 0.83686125] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22058076 0.47520748 0.60594604 0.85261009 0.83686125] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.22058076 0.47520748 0.60594604 0.85261009 0.83686125] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.22058076 0.47520748 0.60594604 0.85261009 0.77609409] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22058076 0.47520748 0.60594604 0.85261009 0.77609409] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22058076 0.47520748 0.65072184 0.85261009 0.77609409] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22058076 0.47520748 0.65072184 0.89139691 0.77609409] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22058076 0.47520748 0.65072184 0.89139691 0.8350167 ] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22058076 0.47520748 0.65072184 0.89139691 0.8350167 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22058076 0.47520748 0.53752682 0.89139691 0.8350167 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22058076 0.47520748 0.53752682 0.89139691 0.8350167 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22058076 0.47520748 0.53752682 0.89139691 0.8350167 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22058076 0.35015288 0.53752682 0.89139691 0.8350167 ] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16253319 0.35015288 0.53752682 0.89139691 0.8350167 ] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16253319 0.35015288 0.53752682 0.89139691 0.8350167 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.16253319 0.35015288 0.53752682 0.89139691 0.8350167 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16253319 0.35015288 0.53752682 0.74896427 0.8350167 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16253319 0.35015288 0.43884429 0.74896427 0.8350167 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16253319 0.25800739 0.43884429 0.74896427 0.8350167 ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1197613  0.25800739 0.43884429 0.74896427 0.8350167 ] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.2631578947368421\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.35526316 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.39716066 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.39716066 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.39716066 0.5        0.64473684 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.39716066 0.5        0.64473684 0.64473684] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.39716066 0.5        0.64473684 0.64473684] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.39716066 0.5        0.64473684 0.64473684] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.5        0.64473684 0.64473684] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.54189751 0.64473684 0.64473684] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.54189751 0.64473684 0.64473684] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.46882745 0.54189751 0.64473684 0.61496756] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.54189751 0.64473684 0.61496756] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.56304936 0.64473684 0.61496756] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.56304936 0.64473684 0.61496756] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.46882745 0.56304936 0.64473684 0.59993861] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.56304936 0.64473684 0.59993861] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.57372783 0.64473684 0.59993861] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.57372783 0.64473684 0.59993861] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.57372783 0.64473684 0.59993861] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.46882745 0.57372783 0.74757618 0.59993861] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.46882745 0.57372783 0.74757618 0.71574585] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.46882745 0.57372783 0.74757618 0.71574585] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35526316 0.46882745 0.51048806 0.74757618 0.71574585] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.46882745 0.51048806 0.74757618 0.71574585] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40019668 0.46882745 0.51048806 0.74757618 0.71574585] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40019668 0.46882745 0.51048806 0.74757618 0.71574585] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40019668 0.46882745 0.47856161 0.74757618 0.71574585] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40019668 0.46882745 0.47856161 0.74757618 0.71574585] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40019668 0.46882745 0.47856161 0.74757618 0.71574585] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40019668 0.33311424 0.47856161 0.74757618 0.71574585] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28435027 0.33311424 0.47856161 0.74757618 0.71574585] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28435027 0.33311424 0.47856161 0.74757618 0.71574585] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28435027 0.33311424 0.5472202  0.74757618 0.71574585] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28435027 0.33311424 0.5472202  0.82064623 0.71574585] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28435027 0.33311424 0.5472202  0.82064623 0.79802995] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28435027 0.33311424 0.5472202  0.82064623 0.79802995] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28435027 0.33311424 0.5472202  0.82064623 0.79802995] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28435027 0.47424192 0.5472202  0.82064623 0.79802995] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28435027 0.47424192 0.61982302 0.82064623 0.79802995] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28435027 0.47424192 0.61982302 0.87256443 0.79802995] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28435027 0.47424192 0.61982302 0.87256443 0.85649496] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28435027 0.47424192 0.61982302 0.87256443 0.85649496] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28435027 0.47424192 0.52271249 0.87256443 0.85649496] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28435027 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20203835 0.33696137 0.52271249 0.87256443 0.85649496] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20203835 0.49200436 0.52271249 0.87256443 0.85649496] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20203835 0.49200436 0.61933373 0.87256443 0.85649496] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.20203835 0.49200436 0.61933373 0.87256443 0.85649496] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.20203835 0.49200436 0.61933373 0.87256443 0.78784303] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20203835 0.49200436 0.61933373 0.87256443 0.78784303] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20203835 0.49200436 0.66811274 0.87256443 0.78784303] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20203835 0.49200436 0.66811274 0.90945367 0.78784303] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20203835 0.49200436 0.66811274 0.90945367 0.84925689] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20203835 0.49200436 0.66811274 0.90945367 0.84925689] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20203835 0.49200436 0.53319647 0.90945367 0.84925689] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.20203835 0.49200436 0.53319647 0.90945367 0.84925689] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20203835 0.49200436 0.53319647 0.90945367 0.84925689] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20203835 0.34958204 0.53319647 0.90945367 0.84925689] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.14355357 0.34958204 0.53319647 0.90945367 0.84925689] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.14355357 0.34958204 0.53319647 0.90945367 0.84925689] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.14355357 0.34958204 0.53319647 0.90945367 0.84925689] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.14355357 0.34958204 0.53319647 0.74738557 0.84925689] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14355357 0.34958204 0.4204051  0.74738557 0.84925689] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.14355357 0.24838724 0.4204051  0.74738557 0.84925689] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10199859 0.24838724 0.4204051  0.74738557 0.84925689] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.2894736842105263\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.34210526 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.39196676 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.39196676 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.39196676 0.5        0.65789474 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.39196676 0.5        0.65789474 0.65789474] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.39196676 0.5        0.65789474 0.65789474] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.39196676 0.5        0.65789474 0.65789474] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.5        0.65789474 0.65789474] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.5498615  0.65789474 0.65789474] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.5498615  0.65789474 0.65789474] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.47594402 0.5498615  0.65789474 0.62377898] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.5498615  0.65789474 0.62377898] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.57320386 0.65789474 0.62377898] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.57320386 0.65789474 0.62377898] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.47594402 0.57320386 0.65789474 0.60780789] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.57320386 0.65789474 0.60780789] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.58413145 0.65789474 0.60780789] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.58413145 0.65789474 0.60780789] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.58413145 0.65789474 0.60780789] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.47594402 0.58413145 0.76592798 0.60780789] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.47594402 0.58413145 0.76592798 0.73165803] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.47594402 0.58413145 0.76592798 0.73165803] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34210526 0.47594402 0.50770213 0.76592798 0.73165803] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.47594402 0.50770213 0.76592798 0.73165803] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39439901 0.47594402 0.50770213 0.76592798 0.73165803] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39439901 0.47594402 0.50770213 0.76592798 0.73165803] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39439901 0.47594402 0.47192219 0.76592798 0.73165803] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39439901 0.47594402 0.47192219 0.76592798 0.73165803] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39439901 0.47594402 0.47192219 0.76592798 0.73165803] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39439901 0.32564591 0.47192219 0.76592798 0.73165803] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26985195 0.32564591 0.47192219 0.76592798 0.73165803] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26985195 0.32564591 0.47192219 0.76592798 0.73165803] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26985195 0.32564591 0.55394404 0.76592798 0.73165803] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26985195 0.32564591 0.55394404 0.83984546 0.73165803] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26985195 0.32564591 0.55394404 0.83984546 0.8163976 ] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26985195 0.32564591 0.55394404 0.83984546 0.8163976 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26985195 0.32564591 0.55394404 0.83984546 0.8163976 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26985195 0.48802471 0.55394404 0.83984546 0.8163976 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26985195 0.48802471 0.63682411 0.83984546 0.8163976 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26985195 0.48802471 0.63682411 0.89042058 0.8163976 ] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26985195 0.48802471 0.63682411 0.89042058 0.8743773 ] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26985195 0.48802471 0.63682411 0.89042058 0.8743773 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26985195 0.48802471 0.52093816 0.89042058 0.8743773 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26985195 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18463555 0.33391164 0.52093816 0.89042058 0.8743773 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18463555 0.50965131 0.52093816 0.89042058 0.8743773 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18463555 0.50965131 0.63255052 0.89042058 0.8743773 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.18463555 0.50965131 0.63255052 0.89042058 0.8743773 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.18463555 0.50965131 0.63255052 0.89042058 0.79801095] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18463555 0.50965131 0.63255052 0.89042058 0.79801095] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18463555 0.50965131 0.68480119 0.89042058 0.79801095] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18463555 0.50965131 0.68480119 0.92502461 0.79801095] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18463555 0.50965131 0.68480119 0.92502461 0.86179697] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18463555 0.50965131 0.68480119 0.92502461 0.86179697] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18463555 0.50965131 0.52685414 0.92502461 0.86179697] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18463555 0.50965131 0.52685414 0.92502461 0.86179697] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18463555 0.50965131 0.52685414 0.92502461 0.86179697] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18463555 0.34870879 0.52685414 0.92502461 0.86179697] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12632958 0.34870879 0.52685414 0.92502461 0.86179697] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12632958 0.34870879 0.52685414 0.92502461 0.86179697] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.12632958 0.34870879 0.52685414 0.92502461 0.86179697] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12632958 0.34870879 0.52685414 0.74303014 0.86179697] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12632958 0.34870879 0.4003727  0.74303014 0.86179697] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12632958 0.23859022 0.4003727  0.74303014 0.86179697] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08643603 0.23859022 0.4003727  0.74303014 0.86179697] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.3157894736842105\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.32894737 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.38746537 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.38746537 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.38746537 0.5        0.67105263 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.38746537 0.5        0.67105263 0.67105263] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.38746537 0.5        0.67105263 0.67105263] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.38746537 0.5        0.67105263 0.67105263] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.5        0.67105263 0.67105263] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.55851801 0.67105263 0.67105263] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.55851801 0.67105263 0.67105263] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.48448207 0.55851801 0.67105263 0.63255394] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.55851801 0.67105263 0.63255394] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.58384609 0.67105263 0.63255394] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.58384609 0.67105263 0.63255394] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.48448207 0.58384609 0.67105263 0.61589073] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.58384609 0.67105263 0.61589073] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.59480873 0.67105263 0.61589073] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.59480873 0.67105263 0.61589073] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.59480873 0.67105263 0.61589073] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.48448207 0.59480873 0.78358726 0.61589073] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.48448207 0.59480873 0.78358726 0.74729653] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.48448207 0.59480873 0.78358726 0.74729653] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32894737 0.48448207 0.50385616 0.78358726 0.74729653] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.48448207 0.50385616 0.78358726 0.74729653] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38878459 0.48448207 0.50385616 0.78358726 0.74729653] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38878459 0.48448207 0.50385616 0.78358726 0.74729653] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38878459 0.48448207 0.46448957 0.78358726 0.74729653] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38878459 0.48448207 0.46448957 0.78358726 0.74729653] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38878459 0.48448207 0.46448957 0.78358726 0.74729653] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38878459 0.3187382  0.46448957 0.78358726 0.74729653] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25577933 0.3187382  0.46448957 0.78358726 0.74729653] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25577933 0.3187382  0.46448957 0.78358726 0.74729653] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25577933 0.3187382  0.56123932 0.78358726 0.74729653] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25577933 0.3187382  0.56123932 0.8576232  0.74729653] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25577933 0.3187382  0.56123932 0.8576232  0.83374772] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25577933 0.3187382  0.56123932 0.8576232  0.83374772] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25577933 0.3187382  0.56123932 0.8576232  0.83374772] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25577933 0.50309359 0.56123932 0.8576232  0.83374772] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25577933 0.50309359 0.65446588 0.8576232  0.83374772] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25577933 0.50309359 0.65446588 0.90633105 0.83374772] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25577933 0.50309359 0.65446588 0.90633105 0.8906235 ] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25577933 0.50309359 0.65446588 0.90633105 0.8906235 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25577933 0.50309359 0.51807311 0.90633105 0.8906235 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25577933 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16827588 0.33098263 0.51807311 0.90633105 0.8906235 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16827588 0.52781235 0.51807311 0.90633105 0.8906235 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.16827588 0.52781235 0.64552456 0.90633105 0.8906235 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.16827588 0.52781235 0.64552456 0.90633105 0.8906235 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.16827588 0.52781235 0.64552456 0.90633105 0.80677386] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16827588 0.52781235 0.64552456 0.90633105 0.80677386] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.16827588 0.52781235 0.7006888  0.90633105 0.80677386] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.16827588 0.52781235 0.7006888  0.93837569 0.80677386] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.16827588 0.52781235 0.7006888  0.93837569 0.87287754] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16827588 0.52781235 0.7006888  0.93837569 0.87287754] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16827588 0.52781235 0.51854753 0.93837569 0.87287754] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16827588 0.52781235 0.51854753 0.93837569 0.87287754] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16827588 0.52781235 0.51854753 0.93837569 0.87287754] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16827588 0.34724497 0.51854753 0.93837569 0.87287754] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11070781 0.34724497 0.51854753 0.93837569 0.87287754] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11070781 0.34724497 0.51854753 0.93837569 0.87287754] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.11070781 0.34724497 0.51854753 0.93837569 0.87287754] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11070781 0.34724497 0.51854753 0.73614676 0.87287754] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11070781 0.34724497 0.37902342 0.73614676 0.87287754] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11070781 0.22845064 0.37902342 0.73614676 0.87287754] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07283409 0.22845064 0.37902342 0.73614676 0.87287754] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.3421052631578947\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.31578947 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.38365651 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.38365651 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.38365651 0.5        0.68421053 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.38365651 0.5        0.68421053 0.68421053] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.38365651 0.5        0.68421053 0.68421053] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.38365651 0.5        0.68421053 0.68421053] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.5        0.68421053 0.68421053] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.56786704 0.68421053 0.68421053] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.56786704 0.68421053 0.68421053] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.49438694 0.56786704 0.68421053 0.64134714] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.56786704 0.68421053 0.64134714] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.59493865 0.68421053 0.64134714] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.59493865 0.68421053 0.64134714] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.49438694 0.59493865 0.68421053 0.62424927] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.59493865 0.68421053 0.62424927] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.6057373  0.68421053 0.62424927] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.6057373  0.68421053 0.62424927] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.6057373  0.68421053 0.62424927] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.49438694 0.6057373  0.80055402 0.62424927] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.49438694 0.6057373  0.80055402 0.76268375] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.49438694 0.6057373  0.80055402 0.76268375] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31578947 0.49438694 0.49891442 0.80055402 0.76268375] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.49438694 0.49891442 0.80055402 0.76268375] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38325656 0.49438694 0.49891442 0.80055402 0.76268375] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38325656 0.49438694 0.49891442 0.80055402 0.76268375] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38325656 0.49438694 0.45630363 0.80055402 0.76268375] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38325656 0.49438694 0.45630363 0.80055402 0.76268375] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38325656 0.49438694 0.45630363 0.80055402 0.76268375] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38325656 0.31224438 0.45630363 0.80055402 0.76268375] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24205677 0.31224438 0.45630363 0.80055402 0.76268375] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24205677 0.31224438 0.45630363 0.80055402 0.76268375] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24205677 0.31224438 0.56918052 0.80055402 0.76268375] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24205677 0.31224438 0.56918052 0.87403412 0.76268375] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24205677 0.31224438 0.56918052 0.87403412 0.85011605] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24205677 0.31224438 0.56918052 0.87403412 0.85011605] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.24205677 0.31224438 0.56918052 0.87403412 0.85011605] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.24205677 0.51921955 0.56918052 0.87403412 0.85011605] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.24205677 0.51921955 0.67268308 0.87403412 0.85011605] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24205677 0.51921955 0.67268308 0.9204426  0.85011605] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.24205677 0.51921955 0.67268308 0.9204426  0.90533645] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.24205677 0.51921955 0.67268308 0.9204426  0.90533645] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24205677 0.51921955 0.51403128 0.9204426  0.90533645] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24205677 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15287796 0.32792813 0.51403128 0.9204426  0.90533645] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15287796 0.54622294 0.51403128 0.9204426  0.90533645] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.15287796 0.54622294 0.65819635 0.9204426  0.90533645] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.15287796 0.54622294 0.65819635 0.9204426  0.90533645] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.15287796 0.54622294 0.65819635 0.9204426  0.81428484] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15287796 0.54622294 0.65819635 0.9204426  0.81428484] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.15287796 0.54622294 0.71570263 0.9204426  0.81428484] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15287796 0.54622294 0.71570263 0.94975322 0.81428484] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15287796 0.54622294 0.71570263 0.94975322 0.88270621] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15287796 0.54622294 0.71570263 0.94975322 0.88270621] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15287796 0.54622294 0.50834618 0.94975322 0.88270621] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.15287796 0.54622294 0.50834618 0.94975322 0.88270621] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15287796 0.54622294 0.50834618 0.94975322 0.88270621] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15287796 0.34498291 0.50834618 0.94975322 0.88270621] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0965545  0.34498291 0.50834618 0.94975322 0.88270621] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.0965545  0.34498291 0.50834618 0.94975322 0.88270621] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.0965545  0.34498291 0.50834618 0.94975322 0.88270621] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0965545  0.34498291 0.50834618 0.72694311 0.88270621] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0965545  0.34498291 0.35663345 0.72694311 0.88270621] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0965545  0.21788394 0.35663345 0.72694311 0.88270621] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06098179 0.21788394 0.35663345 0.72694311 0.88270621] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.3684210526315789\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.30263158 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.38054017 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.38054017 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.38054017 0.5        0.69736842 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.38054017 0.5        0.69736842 0.69736842] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.38054017 0.5        0.69736842 0.69736842] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.38054017 0.5        0.69736842 0.69736842] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.5        0.69736842 0.69736842] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.57790859 0.69736842 0.69736842] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.57790859 0.69736842 0.69736842] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.50560395 0.57790859 0.69736842 0.65021322] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.57790859 0.69736842 0.65021322] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.60644989 0.69736842 0.65021322] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.60644989 0.69736842 0.65021322] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.50560395 0.60644989 0.69736842 0.63293822] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.60644989 0.69736842 0.63293822] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.61690581 0.69736842 0.63293822] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.61690581 0.69736842 0.63293822] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.61690581 0.69736842 0.63293822] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.50560395 0.61690581 0.81682825 0.63293822] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.50560395 0.61690581 0.81682825 0.77783103] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.50560395 0.61690581 0.81682825 0.77783103] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30263158 0.50560395 0.49285019 0.81682825 0.77783103] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.50560395 0.49285019 0.81682825 0.77783103] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.37771787 0.50560395 0.49285019 0.81682825 0.77783103] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.37771787 0.50560395 0.49285019 0.81682825 0.77783103] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37771787 0.50560395 0.44740323 0.81682825 0.77783103] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.37771787 0.50560395 0.44740323 0.81682825 0.77783103] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37771787 0.50560395 0.44740323 0.81682825 0.77783103] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.37771787 0.30602344 0.44740323 0.81682825 0.77783103] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22861871 0.30602344 0.44740323 0.81682825 0.77783103] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22861871 0.30602344 0.44740323 0.81682825 0.77783103] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22861871 0.30602344 0.57783525 0.81682825 0.77783103] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22861871 0.30602344 0.57783525 0.88913289 0.77783103] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22861871 0.30602344 0.57783525 0.88913289 0.86552931] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22861871 0.30602344 0.57783525 0.88913289 0.86552931] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22861871 0.30602344 0.57783525 0.88913289 0.86552931] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22861871 0.53619823 0.57783525 0.88913289 0.86552931] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22861871 0.53619823 0.6913987  0.88913289 0.86552931] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22861871 0.53619823 0.6913987  0.93289622 0.86552931] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22861871 0.53619823 0.6913987  0.93289622 0.91860984] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22861871 0.53619823 0.6913987  0.93289622 0.91860984] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22861871 0.53619823 0.50872239 0.93289622 0.91860984] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22861871 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13837448 0.32454103 0.50872239 0.93289622 0.91860984] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.13837448 0.56468124 0.50872239 0.93289622 0.91860984] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.13837448 0.56468124 0.67052007 0.93289622 0.91860984] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.13837448 0.56468124 0.67052007 0.93289622 0.91860984] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.13837448 0.56468124 0.67052007 0.93289622 0.82067967] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.13837448 0.56468124 0.67052007 0.93289622 0.82067967] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.13837448 0.56468124 0.72979359 0.93289622 0.82067967] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13837448 0.56468124 0.72979359 0.95938456 0.82067967] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13837448 0.56468124 0.72979359 0.95938456 0.89146401] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13837448 0.56468124 0.72979359 0.95938456 0.89146401] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13837448 0.56468124 0.49633868 0.95938456 0.89146401] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.13837448 0.56468124 0.49633868 0.95938456 0.89146401] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13837448 0.56468124 0.49633868 0.95938456 0.89146401] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13837448 0.34178075 0.49633868 0.95938456 0.89146401] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08375298 0.34178075 0.49633868 0.95938456 0.89146401] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08375298 0.34178075 0.49633868 0.95938456 0.89146401] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.08375298 0.34178075 0.49633868 0.95938456 0.89146401] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08375298 0.34178075 0.49633868 0.71559358 0.89146401] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08375298 0.34178075 0.3334759  0.71559358 0.89146401] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08375298 0.2068673  0.3334759  0.71559358 0.89146401] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05069259 0.2068673  0.3334759  0.71559358 0.89146401] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.39473684210526316\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.28947368 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.37811634 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.37811634 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.37811634 0.5        0.71052632 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.37811634 0.5        0.71052632 0.71052632] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.37811634 0.5        0.71052632 0.71052632] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.37811634 0.5        0.71052632 0.71052632] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.5        0.71052632 0.71052632] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.58864266 0.71052632 0.71052632] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.58864266 0.71052632 0.71052632] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.51807844 0.58864266 0.71052632 0.65920688] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.58864266 0.71052632 0.65920688] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.61835391 0.71052632 0.65920688] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.61835391 0.71052632 0.65920688] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.51807844 0.61835391 0.71052632 0.64200563] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.61835391 0.71052632 0.64200563] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.62831253 0.71052632 0.64200563] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.62831253 0.71052632 0.64200563] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.62831253 0.71052632 0.64200563] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.51807844 0.62831253 0.83240997 0.64200563] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.51807844 0.62831253 0.83240997 0.7927401 ] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.51807844 0.62831253 0.83240997 0.7927401 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28947368 0.51807844 0.48564354 0.83240997 0.7927401 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.51807844 0.48564354 0.83240997 0.7927401 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.37207152 0.51807844 0.48564354 0.83240997 0.7927401 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.37207152 0.51807844 0.48564354 0.83240997 0.7927401 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37207152 0.51807844 0.43782374 0.83240997 0.7927401 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.37207152 0.51807844 0.43782374 0.83240997 0.7927401 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.37207152 0.51807844 0.43782374 0.83240997 0.7927401 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.37207152 0.29994015 0.43782374 0.83240997 0.7927401 ] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21540983 0.29994015 0.43782374 0.83240997 0.7927401 ] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.21540983 0.29994015 0.43782374 0.83240997 0.7927401 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.21540983 0.29994015 0.58726221 0.83240997 0.7927401 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.21540983 0.29994015 0.58726221 0.90297419 0.7927401 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.21540983 0.29994015 0.58726221 0.90297419 0.88000743] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.21540983 0.29994015 0.58726221 0.90297419 0.88000743] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.21540983 0.29994015 0.58726221 0.90297419 0.88000743] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.21540983 0.55384922 0.58726221 0.90297419 0.88000743] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.21540983 0.55384922 0.71052335 0.90297419 0.88000743] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.21540983 0.55384922 0.71052335 0.94382717 0.88000743] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.21540983 0.55384922 0.71052335 0.94382717 0.93053062] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.21540983 0.55384922 0.71052335 0.94382717 0.93053062] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21540983 0.55384922 0.5020545  0.94382717 0.93053062] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21540983 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12471095 0.32064955 0.5020545  0.94382717 0.93053062] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12471095 0.58304012 0.5020545  0.94382717 0.93053062] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12471095 0.58304012 0.6824655  0.94382717 0.93053062] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.12471095 0.58304012 0.6824655  0.94382717 0.93053062] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.12471095 0.58304012 0.6824655  0.94382717 0.82608214] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12471095 0.58304012 0.6824655  0.94382717 0.82608214] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12471095 0.58304012 0.74293566 0.94382717 0.82608214] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12471095 0.58304012 0.74293566 0.96747889 0.82608214] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12471095 0.58304012 0.74293566 0.96747889 0.89931072] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12471095 0.58304012 0.74293566 0.96747889 0.89931072] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12471095 0.58304012 0.48263052 0.96747889 0.89931072] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12471095 0.58304012 0.48263052 0.96747889 0.89931072] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12471095 0.58304012 0.48263052 0.96747889 0.89931072] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12471095 0.33754955 0.48263052 0.96747889 0.89931072] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07220108 0.33754955 0.48263052 0.96747889 0.89931072] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.07220108 0.33754955 0.48263052 0.96747889 0.89931072] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.07220108 0.33754955 0.48263052 0.96747889 0.89931072] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07220108 0.33754955 0.48263052 0.70224548 0.89931072] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07220108 0.33754955 0.30981812 0.70224548 0.89931072] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07220108 0.19542342 0.30981812 0.70224548 0.89931072] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04180062 0.19542342 0.30981812 0.70224548 0.89931072] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.42105263157894735\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.27631579 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.37638504 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.37638504 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.37638504 0.5        0.72368421 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.37638504 0.5        0.72368421 0.72368421] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.37638504 0.5        0.72368421 0.72368421] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.37638504 0.5        0.72368421 0.72368421] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.5        0.72368421 0.72368421] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.60006925 0.72368421 0.72368421] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.60006925 0.72368421 0.72368421] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.53175572 0.60006925 0.72368421 0.66838278] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.60006925 0.72368421 0.66838278] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63063057 0.72368421 0.66838278] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63063057 0.72368421 0.66838278] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63063057 0.72368421 0.65149363] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63063057 0.72368421 0.65149363] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63996404 0.72368421 0.65149363] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63996404 0.72368421 0.65149363] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63996404 0.72368421 0.65149363] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.53175572 0.63996404 0.84729917 0.65149363] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.53175572 0.63996404 0.84729917 0.80740438] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63996404 0.84729917 0.80740438] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27631579 0.53175572 0.4772793  0.84729917 0.80740438] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.53175572 0.4772793  0.84729917 0.80740438] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36622052 0.53175572 0.4772793  0.84729917 0.80740438] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36622052 0.53175572 0.4772793  0.84729917 0.80740438] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36622052 0.53175572 0.42759511 0.84729917 0.80740438] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36622052 0.53175572 0.42759511 0.84729917 0.80740438] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36622052 0.53175572 0.42759511 0.84729917 0.80740438] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36622052 0.293865   0.42759511 0.84729917 0.80740438] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20238502 0.293865   0.42759511 0.84729917 0.80740438] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20238502 0.293865   0.42759511 0.84729917 0.80740438] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20238502 0.293865   0.59750978 0.84729917 0.80740438] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20238502 0.293865   0.59750978 0.9156127  0.80740438] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20238502 0.293865   0.59750978 0.9156127  0.89356558] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20238502 0.293865   0.59750978 0.9156127  0.89356558] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20238502 0.293865   0.59750978 0.9156127  0.89356558] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20238502 0.57201529 0.59750978 0.9156127  0.89356558] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20238502 0.57201529 0.72995579 0.9156127  0.89356558] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20238502 0.57201529 0.72995579 0.95336491 0.89356558] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20238502 0.57201529 0.72995579 0.95336491 0.94118098] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20238502 0.57201529 0.72995579 0.95336491 0.94118098] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20238502 0.57201529 0.49393729 0.95336491 0.94118098] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20238502 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11184435 0.31611371 0.49393729 0.95336491 0.94118098] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11184435 0.60119978 0.49393729 0.95336491 0.94118098] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11184435 0.60119978 0.69401999 0.95336491 0.94118098] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.11184435 0.60119978 0.69401999 0.95336491 0.94118098] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.11184435 0.60119978 0.69401999 0.95336491 0.83060896] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11184435 0.60119978 0.69401999 0.95336491 0.83060896] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11184435 0.60119978 0.75512558 0.95336491 0.83060896] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11184435 0.60119978 0.75512558 0.97422798 0.83060896] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11184435 0.60119978 0.75512558 0.97422798 0.90638916] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11184435 0.60119978 0.75512558 0.97422798 0.90638916] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11184435 0.60119978 0.46734188 0.97422798 0.90638916] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11184435 0.60119978 0.46734188 0.97422798 0.90638916] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11184435 0.60119978 0.46734188 0.97422798 0.90638916] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11184435 0.33224198 0.46734188 0.97422798 0.90638916] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06180872 0.33224198 0.46734188 0.97422798 0.90638916] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.06180872 0.33224198 0.46734188 0.97422798 0.90638916] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.06180872 0.33224198 0.46734188 0.97422798 0.90638916] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.06180872 0.33224198 0.46734188 0.68702372 0.90638916] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06180872 0.33224198 0.28591915 0.68702372 0.90638916] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06180872 0.18360741 0.28591915 0.68702372 0.90638916] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03415745 0.18360741 0.28591915 0.68702372 0.90638916] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.4473684210526315\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.26315789 0.5        0.5        0.5       ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.5        0.5        0.5       ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.37534626 0.5        0.5        0.5       ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.37534626 0.5        0.5        0.5       ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.37534626 0.5        0.73684211 0.5       ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.37534626 0.5        0.73684211 0.73684211] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.37534626 0.5        0.73684211 0.73684211] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.37534626 0.5        0.73684211 0.73684211] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.5        0.73684211 0.73684211] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.61218837 0.73684211 0.73684211] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.61218837 0.73684211 0.73684211] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.54658113 0.61218837 0.73684211 0.6777956 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.61218837 0.73684211 0.6777956 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.64326548 0.73684211 0.6777956 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.64326548 0.73684211 0.6777956 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.54658113 0.64326548 0.73684211 0.66143922] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.64326548 0.73684211 0.66143922] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.65187409 0.73684211 0.66143922] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.65187409 0.73684211 0.66143922] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.65187409 0.73684211 0.66143922] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.54658113 0.65187409 0.86149584 0.66143922] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.54658113 0.65187409 0.86149584 0.82181012] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.54658113 0.65187409 0.86149584 0.82181012] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26315789 0.54658113 0.46774537 0.86149584 0.82181012] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.54658113 0.46774537 0.86149584 0.82181012] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36006775 0.54658113 0.46774537 0.86149584 0.82181012] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36006775 0.54658113 0.46774537 0.86149584 0.82181012] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36006775 0.54658113 0.41674018 0.86149584 0.82181012] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36006775 0.54658113 0.41674018 0.86149584 0.82181012] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36006775 0.54658113 0.41674018 0.86149584 0.82181012] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36006775 0.28767428 0.41674018 0.86149584 0.82181012] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18950934 0.28767428 0.41674018 0.86149584 0.82181012] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18950934 0.28767428 0.41674018 0.86149584 0.82181012] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18950934 0.28767428 0.60861541 0.86149584 0.82181012] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18950934 0.28767428 0.60861541 0.92710308 0.82181012] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18950934 0.28767428 0.60861541 0.92710308 0.90621585] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18950934 0.28767428 0.60861541 0.92710308 0.90621585] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18950934 0.28767428 0.60861541 0.92710308 0.90621585] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18950934 0.59056161 0.60861541 0.92710308 0.90621585] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18950934 0.59056161 0.74958404 0.92710308 0.90621585] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18950934 0.59056161 0.74958404 0.9616332  0.90621585] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18950934 0.59056161 0.74958404 0.9616332  0.95063992] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18950934 0.59056161 0.74958404 0.9616332  0.95063992] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18950934 0.59056161 0.4842855  0.9616332  0.95063992] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18950934 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09974176 0.3108219  0.4842855  0.9616332  0.95063992] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09974176 0.61910093 0.4842855  0.9616332  0.95063992] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.09974176 0.61910093 0.70519023 0.9616332  0.95063992] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.09974176 0.61910093 0.70519023 0.9616332  0.95063992] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.09974176 0.61910093 0.70519023 0.9616332  0.83437428] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09974176 0.61910093 0.70519023 0.9616332  0.83437428] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.09974176 0.61910093 0.76638267 0.9616332  0.83437428] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.09974176 0.61910093 0.76638267 0.97980695 0.83437428] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.09974176 0.61910093 0.76638267 0.97980695 0.91282857] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09974176 0.61910093 0.76638267 0.97980695 0.91282857] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09974176 0.61910093 0.4506054  0.97980695 0.91282857] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.09974176 0.61910093 0.4506054  0.97980695 0.91282857] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09974176 0.61910093 0.4506054  0.97980695 0.91282857] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09974176 0.3258426  0.4506054  0.97980695 0.91282857] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05249566 0.3258426  0.4506054  0.97980695 0.91282857] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.05249566 0.3258426  0.4506054  0.97980695 0.91282857] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.05249566 0.3258426  0.4506054  0.97980695 0.91282857] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.05249566 0.3258426  0.4506054  0.67003436 0.91282857] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05249566 0.3258426  0.2620271  0.67003436 0.91282857] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05249566 0.1714961  0.2620271  0.67003436 0.91282857] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0276293  0.1714961  0.2620271  0.67003436 0.91282857] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.47368421052631576\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5  0.25 0.5  0.5  0.5 ] | Step: 6 | T: 7 | time: 5\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 7 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 8.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.5  0.5  0.5 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25  0.375 0.5   0.5   0.5  ] | Step: 8 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25  0.375 0.5   0.5   0.5  ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25  0.375 0.5   0.75  0.5  ] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25  0.375 0.5   0.75  0.75 ] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 12.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25  0.375 0.5   0.75  0.75 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25  0.375 0.5   0.75  0.75 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25   0.5625 0.5    0.75   0.75  ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25   0.5625 0.625  0.75   0.75  ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25   0.5625 0.625  0.75   0.75  ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25   0.5625 0.625  0.75   0.6875] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25   0.5625 0.625  0.75   0.6875] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25    0.5625  0.65625 0.75    0.6875 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25    0.5625  0.65625 0.75    0.6875 ] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25     0.5625   0.65625  0.75     0.671875] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25     0.5625   0.65625  0.75     0.671875] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25      0.5625    0.6640625 0.75      0.671875 ] | Step: 11 | T: inf | time: 10\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25      0.5625    0.6640625 0.75      0.671875 ] | Step: 12 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25      0.5625    0.6640625 0.75      0.671875 ] | Step: 13 | T: inf | time: 12\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25      0.5625    0.6640625 0.875     0.671875 ] | Step: 14 | T: 15 | time: 13\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25      0.5625    0.6640625 0.875     0.8359375] | Step: 15 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 16.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25      0.5625    0.6640625 0.875     0.8359375] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25       0.5625     0.45703125 0.875      0.8359375 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25       0.5625     0.45703125 0.875      0.8359375 ] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35351562 0.5625     0.45703125 0.875      0.8359375 ] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35351562 0.5625     0.45703125 0.875      0.8359375 ] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35351562 0.5625     0.40527344 0.875      0.8359375 ] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35351562 0.5625     0.40527344 0.875      0.8359375 ] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35351562 0.5625     0.40527344 0.875      0.8359375 ] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35351562 0.28125    0.40527344 0.875      0.8359375 ] | Step: 8 | T: 9 | time: 7\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17675781 0.28125    0.40527344 0.875      0.8359375 ] | Step: 9 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 10.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17675781 0.28125    0.40527344 0.875      0.8359375 ] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.17675781 0.28125    0.62060547 0.875      0.8359375 ] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17675781 0.28125    0.62060547 0.9375     0.8359375 ] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17675781 0.28125    0.62060547 0.9375     0.91796875] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17675781 0.28125    0.62060547 0.9375     0.91796875] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.17675781 0.28125    0.62060547 0.9375     0.91796875] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17675781 0.609375   0.62060547 0.9375     0.91796875] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.17675781 0.609375   0.76928711 0.9375     0.91796875] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17675781 0.609375   0.76928711 0.96875    0.91796875] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17675781 0.609375   0.76928711 0.96875    0.95898438] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17675781 0.609375   0.76928711 0.96875    0.95898438] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17675781 0.609375   0.47302246 0.96875    0.95898438] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17675781 0.3046875  0.47302246 0.96875    0.95898438] | Step: 2 | T: 3 | time: 1\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 3 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 4.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 0 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 2 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 4 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08837891 0.3046875  0.47302246 0.96875    0.95898438] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08837891 0.63671875 0.47302246 0.96875    0.95898438] | Step: 6 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.08837891 0.63671875 0.71600342 0.96875    0.95898438] | Step: 7 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.08837891 0.63671875 0.71600342 0.96875    0.95898438] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.08837891 0.63671875 0.71600342 0.96875    0.8374939 ] | Step: 9 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08837891 0.63671875 0.71600342 0.96875    0.8374939 ] | Step: 10 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.08837891 0.63671875 0.77674866 0.96875    0.8374939 ] | Step: 11 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.08837891 0.63671875 0.77674866 0.984375   0.8374939 ] | Step: 12 | T: 13 | time: 11\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.08837891 0.63671875 0.77674866 0.984375   0.91874695] | Step: 13 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 14.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08837891 0.63671875 0.77674866 0.984375   0.91874695] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08837891 0.63671875 0.43256378 0.984375   0.91874695] | Step: 1 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08837891 0.63671875 0.43256378 0.984375   0.91874695] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08837891 0.63671875 0.43256378 0.984375   0.91874695] | Step: 3 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08837891 0.31835938 0.43256378 0.984375   0.91874695] | Step: 4 | T: 5 | time: 3\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04418945 0.31835938 0.43256378 0.984375   0.91874695] | Step: 5 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 6.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.04418945 0.31835938 0.43256378 0.984375   0.91874695] | Step: 0 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.04418945 0.31835938 0.43256378 0.984375   0.91874695] | Step: 1 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.04418945 0.31835938 0.43256378 0.65136719 0.91874695] | Step: 2 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 3 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 4 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 5 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 6 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 7 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 8 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.04418945 0.31835938 0.23837662 0.65136719 0.91874695] | Step: 9 | T: inf | time: 8\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04418945 0.15917969 0.23837662 0.65136719 0.91874695] | Step: 10 | T: 11 | time: 9\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02209473 0.15917969 0.23837662 0.65136719 0.91874695] | Step: 11 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 12.0\n",
      "alpha: 0.5\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 92\n",
      "Total Average of Steps Per Episode: 9.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.48684211 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.48684211 0.48684211 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48684211 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48684211 0.48718837 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48718837 0.48718837 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48718837 0.50068341 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48718837 0.50068341 0.51315789 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48718837 0.50068341 0.51315789 0.51315789] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48718837 0.50068341 0.51315789 0.51315789] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48718837 0.50068341 0.51315789 0.51315789] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48718837 0.50101168 0.51315789 0.51315789] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50101168 0.51315789 0.51315789] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50133132 0.51315789 0.51315789] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50133132 0.51284667 0.51315789] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50133132 0.51284667 0.5131497 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50133132 0.51285464 0.5131497 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50163457 0.51285464 0.5131497 ] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50163457 0.51255938 0.5131497 ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50163457 0.51255938 0.51313417] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50163457 0.5125745  0.51313417] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50192246 0.5125745  0.51313417] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50192246 0.51258923 0.51313417] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48787177 0.50192246 0.51258923 0.52594643] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48787177 0.50192246 0.52541583 0.52594643] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.48684211 0.48787177 0.50192246 0.52541583 0.53842152] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50192246 0.52541583 0.53842152] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50192246 0.52541583 0.53842152] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.48684211 0.48787177 0.50155271 0.52541583 0.53842152] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.48684211 0.4882318  0.50155271 0.52541583 0.53842152] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.48687868 0.4882318  0.50155271 0.52541583 0.53842152] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48687868 0.48819619 0.50155271 0.52541583 0.53842152] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.48687868 0.48819619 0.50120122 0.52541583 0.53842152] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.48687868 0.48816152 0.50120122 0.52541583 0.53842152] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47406608 0.48816152 0.50120122 0.52541583 0.53842152] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47406608 0.47531516 0.50120122 0.52541583 0.53842152] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46159066 0.47531516 0.50120122 0.52541583 0.53842152] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46159066 0.47531516 0.50120122 0.52541583 0.53842152] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46159066 0.47531516 0.50120122 0.52541583 0.53842152] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46159066 0.47531516 0.5143275  0.52541583 0.53842152] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46159066 0.47531516 0.5143275  0.53790489 0.53842152] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46159066 0.47531516 0.5143275  0.53790489 0.55056832] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46159066 0.47531516 0.5143275  0.53790489 0.55056832] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46159066 0.47531516 0.5143275  0.53790489 0.55056832] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46159066 0.47531516 0.51494796 0.53790489 0.55056832] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46159066 0.47729551 0.51494796 0.53790489 0.55056832] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46159066 0.47729551 0.52771249 0.53790489 0.55056832] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46159066 0.47729551 0.52771249 0.55006529 0.55056832] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46159066 0.47729551 0.52771249 0.55006529 0.56239547] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46159066 0.47729551 0.52771249 0.55006529 0.56239547] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46159066 0.47729551 0.52771249 0.55006529 0.56239547] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46159066 0.47729551 0.51382532 0.55006529 0.56239547] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46159066 0.4647351  0.51382532 0.55006529 0.56239547] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44944353 0.4647351  0.51382532 0.55006529 0.56239547] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44944353 0.4647351  0.51382532 0.55006529 0.56239547] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44944353 0.4647351  0.51382532 0.55006529 0.56239547] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44944353 0.4647351  0.51253347 0.55006529 0.56239547] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44944353 0.46599295 0.51253347 0.55006529 0.56239547] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44944353 0.46599295 0.51130872 0.55006529 0.56239547] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44944353 0.46718547 0.51130872 0.55006529 0.56239547] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44944353 0.46718547 0.51232863 0.55006529 0.56239547] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44944353 0.469691   0.51232863 0.55006529 0.56239547] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44944353 0.469691   0.5133217  0.55006529 0.56239547] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44944353 0.469691   0.5133217  0.54909835 0.56239547] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44944353 0.469691   0.5133217  0.54909835 0.56204555] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44944353 0.469691   0.5133217  0.54943907 0.56204555] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44944353 0.469691   0.52612902 0.54943907 0.56204555] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44944353 0.469691   0.52612902 0.56129593 0.56204555] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44944353 0.469691   0.52612902 0.56129593 0.57357067] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44944353 0.469691   0.52612902 0.56129593 0.57357067] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44944353 0.469691   0.52612902 0.56129593 0.57357067] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44944353 0.469691   0.52464381 0.56129593 0.57357067] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44944353 0.46915817 0.52464381 0.56129593 0.57357067] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.43761607 0.46915817 0.52464381 0.56129593 0.57357067] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.43761607 0.4568119  0.52464381 0.56129593 0.57357067] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42609986 0.4568119  0.52464381 0.56129593 0.57357067] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42609986 0.4568119  0.52464381 0.56129593 0.57357067] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42609986 0.4568119  0.52464381 0.56129593 0.57357067] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42609986 0.4568119  0.52285876 0.56129593 0.57357067] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42609986 0.4568119  0.52285876 0.55773814 0.57357067] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42609986 0.4568119  0.52112068 0.55773814 0.57357067] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42609986 0.45600369 0.52112068 0.55773814 0.57357067] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.4268868  0.45600369 0.52112068 0.55773814 0.57357067] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.4268868  0.45523746 0.52112068 0.55773814 0.57357067] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42763287 0.45523746 0.52112068 0.55773814 0.57357067] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42763287 0.45451102 0.52112068 0.55773814 0.57357067] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.41637938 0.45451102 0.52112068 0.55773814 0.57357067] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.41637938 0.44255021 0.52112068 0.55773814 0.57357067] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40542202 0.44255021 0.52112068 0.55773814 0.57357067] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.02631578947368421\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.47368421 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.47368421 0.47368421 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47368421 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47368421 0.47506925 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47506925 0.47506925 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47506925 0.50269719 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47506925 0.50269719 0.52631579 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47506925 0.50269719 0.52631579 0.52631579] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47506925 0.50269719 0.52631579 0.52631579] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47506925 0.50269719 0.52631579 0.52631579] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47506925 0.50394027 0.52631579 0.52631579] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50394027 0.52631579 0.52631579] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50511793 0.52631579 0.52631579] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50511793 0.52520011 0.52631579] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50511793 0.52520011 0.52625707] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50511793 0.52525574 0.52625707] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50617781 0.52525574 0.52625707] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50617781 0.52425164 0.52625707] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50617781 0.52425164 0.52615152] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50617781 0.52435163 0.52615152] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50713433 0.52435163 0.52615152] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50713433 0.52444637 0.52615152] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47776644 0.50713433 0.52444637 0.55109091] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47776644 0.50713433 0.5494755  0.55109091] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.47368421 0.47776644 0.50713433 0.5494755  0.57471771] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50713433 0.5494755  0.57471771] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50713433 0.5494755  0.57471771] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.47368421 0.47776644 0.50558865 0.5494755  0.57471771] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.47368421 0.47923077 0.50558865 0.5494755  0.57471771] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.47397613 0.47923077 0.50558865 0.5494755  0.57471771] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47397613 0.47895421 0.50558865 0.5494755  0.57471771] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.47397613 0.47895421 0.50418684 0.5494755  0.57471771] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.47397613 0.4786922  0.50418684 0.5494755  0.57471771] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44903002 0.4786922  0.50418684 0.5494755  0.57471771] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44903002 0.45349788 0.50418684 0.5494755  0.57471771] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42539686 0.45349788 0.50418684 0.5494755  0.57471771] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42539686 0.45349788 0.50418684 0.5494755  0.57471771] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42539686 0.45349788 0.50418684 0.5494755  0.57471771] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42539686 0.45349788 0.53028227 0.5494755  0.57471771] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42539686 0.45349788 0.53028227 0.57318732 0.57471771] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42539686 0.45349788 0.53028227 0.57318732 0.59710099] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42539686 0.45349788 0.53028227 0.57318732 0.59710099] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42539686 0.45349788 0.53028227 0.57318732 0.59710099] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42539686 0.45349788 0.53254043 0.57318732 0.59710099] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42539686 0.46105593 0.53254043 0.57318732 0.59710099] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42539686 0.46105593 0.55714356 0.57318732 0.59710099] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42539686 0.46105593 0.55714356 0.59565114 0.59710099] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42539686 0.46105593 0.55714356 0.59565114 0.6183062 ] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42539686 0.46105593 0.55714356 0.59565114 0.6183062 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42539686 0.46105593 0.55714356 0.59565114 0.6183062 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42539686 0.46105593 0.52782022 0.59565114 0.6183062 ] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42539686 0.43678983 0.52782022 0.59565114 0.6183062 ] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40300755 0.43678983 0.52782022 0.59565114 0.6183062 ] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40300755 0.43678983 0.52782022 0.59565114 0.6183062 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40300755 0.43678983 0.52782022 0.59565114 0.6183062 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40300755 0.43678983 0.52302915 0.59565114 0.6183062 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40300755 0.44132874 0.52302915 0.59565114 0.6183062 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40300755 0.44132874 0.51872913 0.59565114 0.6183062 ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40300755 0.44540245 0.51872913 0.59565114 0.6183062 ] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40300755 0.44540245 0.52277765 0.59565114 0.6183062 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40300755 0.45450265 0.52277765 0.59565114 0.6183062 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40300755 0.45450265 0.5266131  0.59565114 0.6183062 ] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40300755 0.45450265 0.5266131  0.59201756 0.6183062 ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40300755 0.45450265 0.5266131  0.59201756 0.61692259] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40300755 0.45450265 0.5266131  0.59332835 0.61692259] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40300755 0.45450265 0.5515282  0.59332835 0.61692259] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40300755 0.45450265 0.5515282  0.61473212 0.61692259] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40300755 0.45450265 0.5515282  0.61473212 0.63708455] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40300755 0.45450265 0.5515282  0.61473212 0.63708455] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40300755 0.45450265 0.5515282  0.61473212 0.63708455] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40300755 0.45450265 0.54642159 0.61473212 0.63708455] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40300755 0.45179238 0.54642159 0.61473212 0.63708455] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38179663 0.45179238 0.54642159 0.61473212 0.63708455] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38179663 0.42801383 0.54642159 0.61473212 0.63708455] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36170207 0.42801383 0.54642159 0.61473212 0.63708455] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36170207 0.42801383 0.54642159 0.61473212 0.63708455] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36170207 0.42801383 0.54642159 0.61473212 0.63708455] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36170207 0.42801383 0.5401896  0.61473212 0.63708455] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36170207 0.42801383 0.5401896  0.60141475 0.63708455] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36170207 0.42801383 0.53428562 0.60141475 0.63708455] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36170207 0.42452374 0.53428562 0.60141475 0.63708455] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36500847 0.42452374 0.53428562 0.60141475 0.63708455] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36500847 0.42139136 0.53428562 0.60141475 0.63708455] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36797599 0.42139136 0.53428562 0.60141475 0.63708455] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36797599 0.41858002 0.53428562 0.60141475 0.63708455] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34860884 0.41858002 0.53428562 0.60141475 0.63708455] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34860884 0.39654949 0.53428562 0.60141475 0.63708455] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.330261   0.39654949 0.53428562 0.60141475 0.63708455] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.05263157894736842\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.46052632 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.46052632 0.46052632 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46052632 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46052632 0.46364266 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46364266 0.46364266 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46364266 0.50598666 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46364266 0.50598666 0.53947368 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46364266 0.50598666 0.53947368 0.53947368] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46364266 0.50598666 0.53947368 0.53947368] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46364266 0.50598666 0.53947368 0.53947368] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46364266 0.50863037 0.53947368 0.53947368] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.50863037 0.53947368 0.53947368] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51106537 0.53947368 0.53947368] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51106537 0.53723092 0.53947368] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51106537 0.53723092 0.53929662] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51106537 0.537394   0.53929662] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51314395 0.537394   0.53929662] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51314395 0.53547953 0.53929662] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51314395 0.53547953 0.53899527] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51314395 0.53575709 0.53899527] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51492919 0.53575709 0.53899527] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51492919 0.53601273 0.53899527] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46962932 0.51492919 0.53601273 0.57539038] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46962932 0.51492919 0.57264331 0.57539038] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.46052632 0.46962932 0.51492919 0.57264331 0.6089122 ] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51492919 0.57264331 0.6089122 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51492919 0.57264331 0.6089122 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46052632 0.46962932 0.51135289 0.57264331 0.6089122 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.46052632 0.47292329 0.51135289 0.57264331 0.6089122 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.46150502 0.47292329 0.51135289 0.57264331 0.6089122 ] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46150502 0.47202184 0.51135289 0.57264331 0.6089122 ] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.46150502 0.47202184 0.50824781 0.57264331 0.6089122 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.46150502 0.47119157 0.50824781 0.57264331 0.6089122 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42507042 0.47119157 0.50824781 0.57264331 0.6089122 ] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42507042 0.43399223 0.50824781 0.57264331 0.6089122 ] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39151223 0.43399223 0.50824781 0.57264331 0.6089122 ] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39151223 0.43399223 0.50824781 0.57264331 0.6089122 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39151223 0.43399223 0.50824781 0.57264331 0.6089122 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39151223 0.43399223 0.54707035 0.57264331 0.6089122 ] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39151223 0.43399223 0.54707035 0.60638199 0.6089122 ] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39151223 0.43399223 0.54707035 0.60638199 0.63978755] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39151223 0.43399223 0.54707035 0.60638199 0.63978755] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39151223 0.43399223 0.54707035 0.60638199 0.63978755] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39151223 0.43399223 0.55175285 0.60638199 0.63978755] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39151223 0.45023923 0.55175285 0.60638199 0.63978755] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39151223 0.45023923 0.58714078 0.60638199 0.63978755] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39151223 0.45023923 0.58714078 0.6374571  0.63978755] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39151223 0.45023923 0.58714078 0.6374571  0.66822537] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39151223 0.45023923 0.58714078 0.6374571  0.66822537] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39151223 0.45023923 0.58714078 0.6374571  0.66822537] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39151223 0.45023923 0.54078756 0.6374571  0.66822537] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39151223 0.41469403 0.54078756 0.6374571  0.66822537] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36060337 0.41469403 0.54078756 0.6374571  0.66822537] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36060337 0.41469403 0.54078756 0.6374571  0.66822537] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36060337 0.41469403 0.54078756 0.6374571  0.66822537] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36060337 0.41469403 0.53083281 0.6374571  0.66822537] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36060337 0.42386288 0.53083281 0.6374571  0.66822537] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36060337 0.42386288 0.52238781 0.6374571  0.66822537] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36060337 0.43164116 0.52238781 0.6374571  0.66822537] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36060337 0.43164116 0.53147223 0.6374571  0.66822537] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36060337 0.45031887 0.53147223 0.6374571  0.66822537] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36060337 0.45031887 0.53983946 0.6374571  0.66822537] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36060337 0.45031887 0.53983946 0.62975044 0.66822537] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36060337 0.45031887 0.53983946 0.62975044 0.66518788] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36060337 0.45031887 0.53983946 0.63254813 0.66518788] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36060337 0.45031887 0.57616792 0.63254813 0.66518788] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36060337 0.45031887 0.57616792 0.66155749 0.66518788] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36060337 0.45031887 0.57616792 0.66155749 0.69162042] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36060337 0.45031887 0.57616792 0.66155749 0.69162042] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36060337 0.45031887 0.57616792 0.66155749 0.69162042] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36060337 0.45031887 0.56623247 0.66155749 0.69162042] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36060337 0.44323606 0.56623247 0.66155749 0.69162042] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33213468 0.44323606 0.56623247 0.66155749 0.69162042] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33213468 0.40824374 0.56623247 0.66155749 0.69162042] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30591352 0.40824374 0.56623247 0.66155749 0.69162042] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30591352 0.40824374 0.56623247 0.66155749 0.69162042] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30591352 0.40824374 0.56623247 0.66155749 0.69162042] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30591352 0.40824374 0.55375967 0.66155749 0.69162042] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30591352 0.40824374 0.55375967 0.63348034 0.69162042] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.30591352 0.40824374 0.54227157 0.63348034 0.69162042] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30591352 0.40016504 0.54227157 0.63348034 0.69162042] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.31335443 0.40016504 0.54227157 0.63348034 0.69162042] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31335443 0.39331157 0.54227157 0.63348034 0.69162042] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.31966684 0.39331157 0.54227157 0.63348034 0.69162042] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31966684 0.38749751 0.54227157 0.63348034 0.69162042] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29442998 0.38749751 0.54227157 0.63348034 0.69162042] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29442998 0.3569056  0.54227157 0.63348034 0.69162042] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27118551 0.3569056  0.54227157 0.63348034 0.69162042] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.07894736842105263\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.44736842 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.44736842 0.44736842 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.44736842 0.44736842 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.44736842 0.45290859 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.45290859 0.45290859 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.45290859 0.51049716 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.45290859 0.51049716 0.55263158 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.45290859 0.51049716 0.55263158 0.55263158] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.45290859 0.51049716 0.55263158 0.55263158] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.45290859 0.51049716 0.55263158 0.55263158] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.45290859 0.51493236 0.55263158 0.55263158] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.51493236 0.55263158 0.55263158] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.5189007  0.55263158 0.55263158] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.46340574 0.5189007  0.54908096 0.55263158] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.5189007  0.54908096 0.55225783] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.5189007  0.54941537 0.55225783] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52211277 0.54941537 0.55225783] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52211277 0.54654141 0.55225783] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52211277 0.54654141 0.5516561 ] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52211277 0.5470798  0.5516561 ] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52474088 0.5470798  0.5516561 ] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52474088 0.54756151 0.5516561 ] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.46340574 0.52474088 0.54756151 0.5988502 ] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.46340574 0.52474088 0.59518662 0.5988502 ] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.44736842 0.46340574 0.52474088 0.59518662 0.64107649] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52474088 0.59518662 0.64107649] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44736842 0.46340574 0.52474088 0.59518662 0.64107649] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44736842 0.46340574 0.51828455 0.59518662 0.64107649] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.44736842 0.46918246 0.51828455 0.59518662 0.64107649] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.44966464 0.46918246 0.51828455 0.59518662 0.64107649] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44966464 0.46712795 0.51828455 0.59518662 0.64107649] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.44966464 0.46712795 0.51289964 0.59518662 0.64107649] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.44966464 0.46528971 0.51289964 0.59518662 0.64107649] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40233152 0.46528971 0.51289964 0.59518662 0.64107649] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40233152 0.41631184 0.51289964 0.59518662 0.64107649] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35998083 0.41631184 0.51289964 0.59518662 0.64107649] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35998083 0.41631184 0.51289964 0.59518662 0.64107649] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35998083 0.41631184 0.51289964 0.59518662 0.64107649] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35998083 0.41631184 0.56417336 0.59518662 0.64107649] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35998083 0.41631184 0.56417336 0.63779855 0.64107649] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35998083 0.41631184 0.56417336 0.63779855 0.67885791] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35998083 0.41631184 0.56417336 0.63779855 0.67885791] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35998083 0.41631184 0.56417336 0.63779855 0.67885791] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35998083 0.41631184 0.57192338 0.63779855 0.67885791] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35998083 0.44394827 0.57192338 0.63779855 0.67885791] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35998083 0.44394827 0.61698408 0.63779855 0.67885791] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35998083 0.44394827 0.61698408 0.67592502 0.67885791] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35998083 0.44394827 0.61698408 0.67592502 0.71266234] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35998083 0.44394827 0.61698408 0.67592502 0.71266234] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35998083 0.44394827 0.61698408 0.67592502 0.71266234] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35998083 0.44394827 0.55203839 0.67592502 0.71266234] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35998083 0.39721688 0.55203839 0.67592502 0.71266234] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32208811 0.39721688 0.55203839 0.67592502 0.71266234] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32208811 0.39721688 0.55203839 0.67592502 0.71266234] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32208811 0.39721688 0.55203839 0.67592502 0.71266234] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32208811 0.39721688 0.53574139 0.67592502 0.71266234] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32208811 0.4117984  0.53574139 0.67592502 0.71266234] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32208811 0.4117984  0.52269476 0.67592502 0.71266234] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32208811 0.4234717  0.52269476 0.67592502 0.71266234] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32208811 0.4234717  0.53882426 0.67592502 0.71266234] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32208811 0.45391282 0.53882426 0.67592502 0.71266234] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32208811 0.45391282 0.55325592 0.67592502 0.71266234] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32208811 0.45391282 0.55325592 0.66301248 0.71266234] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32208811 0.45391282 0.55325592 0.66301248 0.70743604] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32208811 0.45391282 0.55325592 0.66768865 0.70743604] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32208811 0.45391282 0.60028161 0.66768865 0.70743604] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32208811 0.45391282 0.60028161 0.70266879 0.70743604] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32208811 0.45391282 0.60028161 0.70266879 0.73823225] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32208811 0.45391282 0.60028161 0.70266879 0.73823225] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32208811 0.45391282 0.60028161 0.70266879 0.73823225] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32208811 0.45391282 0.58487437 0.70266879 0.73823225] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32208811 0.44003654 0.58487437 0.70266879 0.73823225] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2881841  0.44003654 0.58487437 0.70266879 0.73823225] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2881841  0.3937169  0.58487437 0.70266879 0.73823225] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25784893 0.3937169  0.58487437 0.70266879 0.73823225] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25784893 0.3937169  0.58487437 0.70266879 0.73823225] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25784893 0.3937169  0.58487437 0.70266879 0.73823225] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25784893 0.3937169  0.56475253 0.70266879 0.73823225] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25784893 0.3937169  0.56475253 0.65584565 0.73823225] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25784893 0.3937169  0.54674878 0.65584565 0.73823225] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25784893 0.37941501 0.54674878 0.65584565 0.73823225] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.27064536 0.37941501 0.54674878 0.65584565 0.73823225] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27064536 0.36796557 0.54674878 0.65584565 0.73823225] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.28088959 0.36796557 0.54674878 0.65584565 0.73823225] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28088959 0.35879968 0.54674878 0.65584565 0.73823225] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25132227 0.35879968 0.54674878 0.65584565 0.73823225] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25132227 0.32103129 0.54674878 0.65584565 0.73823225] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22486729 0.32103129 0.54674878 0.65584565 0.73823225] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.10526315789473684\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.43421053 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.43421053 0.43421053 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.43421053 0.43421053 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.43421053 0.44286704 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.44286704 0.44286704 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.44286704 0.516174   0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.44286704 0.516174   0.56578947 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.44286704 0.516174   0.56578947 0.56578947] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.44286704 0.516174   0.56578947 0.56578947] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.44286704 0.516174   0.56578947 0.56578947] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.44286704 0.52270236 0.56578947 0.56578947] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52270236 0.56578947 0.56578947] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52837171 0.56578947 0.56578947] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52837171 0.56086608 0.56578947] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52837171 0.56086608 0.56514166] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52837171 0.56142866 0.56514166] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.53272131 0.56142866 0.56514166] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.45904104 0.53272131 0.55765138 0.56514166] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.53272131 0.55765138 0.5641561 ] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.53272131 0.55850726 0.5641561 ] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.43421053 0.45904104 0.5361142  0.55850726 0.5641561 ] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.43421053 0.45904104 0.5361142  0.55925053 0.5641561 ] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.45904104 0.5361142  0.55925053 0.62150398] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.45904104 0.5361142  0.61724388 0.62150398] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.43421053 0.45904104 0.5361142  0.61724388 0.67130609] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.45904104 0.5361142  0.61724388 0.67130609] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43421053 0.45904104 0.5361142  0.61724388 0.67130609] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43421053 0.45904104 0.52597299 0.61724388 0.67130609] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.43421053 0.46784788 0.52597299 0.61724388 0.67130609] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.43863649 0.46784788 0.52597299 0.61724388 0.67130609] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43863649 0.46400427 0.52597299 0.61724388 0.67130609] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.43863649 0.46400427 0.51781922 0.61724388 0.67130609] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.43863649 0.46066641 0.51781922 0.61724388 0.67130609] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38092117 0.46066641 0.51781922 0.61724388 0.67130609] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38092117 0.40005241 0.51781922 0.61724388 0.67130609] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33079996 0.40005241 0.51781922 0.61724388 0.67130609] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33079996 0.40005241 0.51781922 0.61724388 0.67130609] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33079996 0.40005241 0.51781922 0.61724388 0.67130609] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33079996 0.40005241 0.58126406 0.61724388 0.67130609] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33079996 0.40005241 0.58126406 0.66760653 0.67130609] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33079996 0.40005241 0.58126406 0.66760653 0.71455529] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33079996 0.40005241 0.58126406 0.66760653 0.71455529] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.33079996 0.40005241 0.58126406 0.66760653 0.71455529] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.33079996 0.40005241 0.59262491 0.66760653 0.71455529] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.33079996 0.44143436 0.59262491 0.66760653 0.71455529] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33079996 0.44143436 0.64622689 0.66760653 0.71455529] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33079996 0.44143436 0.64622689 0.71134251 0.71455529] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.33079996 0.44143436 0.64622689 0.71134251 0.7521138 ] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.33079996 0.44143436 0.64622689 0.71134251 0.7521138 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.33079996 0.44143436 0.64622689 0.71134251 0.7521138 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33079996 0.44143436 0.56119704 0.71134251 0.7521138 ] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.33079996 0.3833509  0.56119704 0.71134251 0.7521138 ] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28727365 0.3833509  0.56119704 0.71134251 0.7521138 ] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28727365 0.3833509  0.56119704 0.71134251 0.7521138 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28727365 0.3833509  0.56119704 0.71134251 0.7521138 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28727365 0.3833509  0.53779623 0.71134251 0.7521138 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28727365 0.40367265 0.53779623 0.71134251 0.7521138 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28727365 0.40367265 0.52014839 0.71134251 0.7521138 ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28727365 0.41899841 0.52014839 0.71134251 0.7521138 ] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28727365 0.41899841 0.54530551 0.71134251 0.7521138 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28727365 0.46282938 0.54530551 0.71134251 0.7521138 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28727365 0.46282938 0.56715249 0.71134251 0.7521138 ] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28727365 0.46282938 0.56715249 0.69237014 0.7521138 ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28727365 0.46282938 0.56715249 0.69237014 0.74425279] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28727365 0.46282938 0.56715249 0.6991968  0.74425279] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28727365 0.46282938 0.62410611 0.6991968  0.74425279] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28727365 0.46282938 0.62410611 0.73877617 0.74425279] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28727365 0.46282938 0.62410611 0.73877617 0.77790374] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28727365 0.46282938 0.62410611 0.73877617 0.77790374] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28727365 0.46282938 0.62410611 0.73877617 0.77790374] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.28727365 0.46282938 0.60288548 0.73877617 0.77790374] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28727365 0.43972994 0.60288548 0.73877617 0.77790374] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24947448 0.43972994 0.60288548 0.73877617 0.77790374] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24947448 0.38187074 0.60288548 0.73877617 0.77790374] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21664889 0.38187074 0.60288548 0.73877617 0.77790374] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.21664889 0.38187074 0.60288548 0.73877617 0.77790374] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.21664889 0.38187074 0.60288548 0.73877617 0.77790374] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.21664889 0.38187074 0.5738046  0.73877617 0.77790374] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21664889 0.38187074 0.5738046  0.67007521 0.77790374] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.21664889 0.38187074 0.54855014 0.67007521 0.77790374] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.21664889 0.36013102 0.54855014 0.67007521 0.77790374] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.23552812 0.36013102 0.54855014 0.67007521 0.77790374] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23552812 0.3437359  0.54855014 0.67007521 0.77790374] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.24976599 0.3437359  0.54855014 0.67007521 0.77790374] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.24976599 0.33137144 0.54855014 0.67007521 0.77790374] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21690204 0.33137144 0.54855014 0.67007521 0.77790374] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21690204 0.28776994 0.54855014 0.67007521 0.77790374] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1883623  0.28776994 0.54855014 0.67007521 0.77790374] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.13157894736842105\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.42105263 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.42105263 0.42105263 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.42105263 0.42105263 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.42105263 0.43351801 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.43351801 0.43351801 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.43351801 0.52296253 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.43351801 0.52296253 0.57894737 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.43351801 0.52296253 0.57894737 0.57894737] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.43351801 0.52296253 0.57894737 0.57894737] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.43351801 0.52296253 0.57894737 0.57894737] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.43351801 0.53180224 0.57894737 0.57894737] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.53180224 0.57894737 0.57894737] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.53924621 0.57894737 0.57894737] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.45648054 0.53924621 0.57267876 0.57894737] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.53924621 0.57267876 0.57795759] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.53924621 0.57351226 0.57795759] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54465664 0.57351226 0.57795759] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54465664 0.56895611 0.57795759] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54465664 0.56895611 0.5765363 ] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54465664 0.57015298 0.5765363 ] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54868238 0.57015298 0.5765363 ] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54868238 0.57116088 0.5765363 ] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.45648054 0.54868238 0.57116088 0.64339899] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.45648054 0.54868238 0.63887232 0.64339899] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.42105263 0.45648054 0.54868238 0.63887232 0.69970441] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54868238 0.63887232 0.69970441] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42105263 0.45648054 0.54868238 0.63887232 0.69970441] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42105263 0.45648054 0.53412419 0.63887232 0.69970441] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.42105263 0.46874006 0.53412419 0.63887232 0.69970441] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42858223 0.46874006 0.53412419 0.63887232 0.69970441] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42858223 0.46239935 0.53412419 0.63887232 0.69970441] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42858223 0.46239935 0.52279922 0.63887232 0.69970441] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42858223 0.4570598  0.52279922 0.63887232 0.69970441] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36091135 0.4570598  0.52279922 0.63887232 0.69970441] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36091135 0.38489247 0.52279922 0.63887232 0.69970441] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30392535 0.38489247 0.52279922 0.63887232 0.69970441] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30392535 0.38489247 0.52279922 0.63887232 0.69970441] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30392535 0.38489247 0.52279922 0.63887232 0.69970441] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30392535 0.38489247 0.59814671 0.63887232 0.69970441] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30392535 0.38489247 0.59814671 0.69589248 0.69970441] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30392535 0.38489247 0.59814671 0.69589248 0.74711951] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30392535 0.38489247 0.59814671 0.69589248 0.74711951] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30392535 0.38489247 0.59814671 0.69589248 0.74711951] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30392535 0.38489247 0.61358025 0.69589248 0.74711951] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30392535 0.44208621 0.61358025 0.69589248 0.74711951] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30392535 0.44208621 0.6745939  0.69589248 0.74711951] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30392535 0.44208621 0.6745939  0.74390945 0.74711951] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30392535 0.44208621 0.6745939  0.74390945 0.78704801] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30392535 0.44208621 0.6745939  0.74390945 0.78704801] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30392535 0.44208621 0.6745939  0.74390945 0.78704801] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30392535 0.44208621 0.56807907 0.74390945 0.78704801] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30392535 0.37228312 0.56807907 0.74390945 0.78704801] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25593713 0.37228312 0.56807907 0.74390945 0.78704801] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25593713 0.37228312 0.56807907 0.74390945 0.78704801] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25593713 0.37228312 0.56807907 0.74390945 0.78704801] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25593713 0.37228312 0.53716392 0.74390945 0.78704801] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25593713 0.39831693 0.53716392 0.74390945 0.78704801] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25593713 0.39831693 0.51524071 0.74390945 0.78704801] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25593713 0.41677858 0.51524071 0.74390945 0.78704801] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25593713 0.41677858 0.5513463  0.74390945 0.78704801] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25593713 0.47524218 0.5513463  0.74390945 0.78704801] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25593713 0.47524218 0.58175101 0.74390945 0.78704801] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25593713 0.47524218 0.58175101 0.71830549 0.78704801] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25593713 0.47524218 0.58175101 0.71830549 0.77619392] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25593713 0.47524218 0.58175101 0.72744577 0.77619392] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25593713 0.47524218 0.64779033 0.72744577 0.77619392] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25593713 0.47524218 0.64779033 0.77048065 0.77619392] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25593713 0.47524218 0.64779033 0.77048065 0.81153173] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25593713 0.47524218 0.64779033 0.77048065 0.81153173] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25593713 0.47524218 0.64779033 0.77048065 0.81153173] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25593713 0.47524218 0.62054588 0.77048065 0.81153173] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25593713 0.44061506 0.62054588 0.77048065 0.81153173] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21552601 0.44061506 0.62054588 0.77048065 0.81153173] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21552601 0.37104426 0.62054588 0.77048065 0.81153173] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18149558 0.37104426 0.62054588 0.77048065 0.81153173] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18149558 0.37104426 0.62054588 0.77048065 0.81153173] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.18149558 0.37104426 0.62054588 0.77048065 0.81153173] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18149558 0.37104426 0.58115089 0.77048065 0.81153173] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18149558 0.37104426 0.58115089 0.67748301 0.81153173] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18149558 0.37104426 0.54797616 0.67748301 0.81153173] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18149558 0.34111553 0.54797616 0.67748301 0.81153173] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.20669873 0.34111553 0.54797616 0.67748301 0.81153173] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20669873 0.31989182 0.54797616 0.67748301 0.81153173] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22457133 0.31989182 0.54797616 0.67748301 0.81153173] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22457133 0.30484122 0.54797616 0.67748301 0.81153173] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1891127  0.30484122 0.54797616 0.67748301 0.81153173] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1891127  0.25670839 0.54797616 0.67748301 0.81153173] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1592528  0.25670839 0.54797616 0.67748301 0.81153173] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.15789473684210525\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.40789474 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.40789474 0.40789474 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.40789474 0.40789474 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.40789474 0.4248615  0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.4248615  0.4248615  0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.4248615  0.53080806 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.4248615  0.53080806 0.59210526 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.4248615  0.53080806 0.59210526 0.59210526] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.4248615  0.53080806 0.59210526 0.59210526] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.4248615  0.53080806 0.59210526 0.59210526] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.4248615  0.54209965 0.59210526 0.59210526] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.54209965 0.59210526 0.59210526] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55131121 0.59210526 0.59210526] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55131121 0.58459057 0.59210526] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55131121 0.58459057 0.59072098] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55131121 0.58571986 0.59072098] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55764965 0.58571986 0.59072098] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55764965 0.58054903 0.59072098] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55764965 0.58054903 0.5888472 ] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.55764965 0.58207764 0.5888472 ] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.40789474 0.45566956 0.56214954 0.58207764 0.5888472 ] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.40789474 0.45566956 0.56214954 0.58332466 0.5888472 ] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.45566956 0.56214954 0.58332466 0.66458587] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.45566956 0.56214954 0.66008065 0.66458587] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.40789474 0.45566956 0.56214954 0.66008065 0.72637268] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.45566956 0.56214954 0.66008065 0.72637268] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40789474 0.45566956 0.56214954 0.66008065 0.72637268] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40789474 0.45566956 0.54253481 0.66008065 0.72637268] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.40789474 0.47167105 0.54253481 0.66008065 0.72637268] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.41964301 0.47167105 0.54253481 0.66008065 0.72637268] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41964301 0.46208694 0.54253481 0.66008065 0.72637268] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41964301 0.46208694 0.52771546 0.66008065 0.72637268] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41964301 0.45426832 0.52771546 0.66008065 0.72637268] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34234035 0.45426832 0.52771546 0.66008065 0.72637268] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34234035 0.37058731 0.52771546 0.66008065 0.72637268] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27927765 0.37058731 0.52771546 0.66008065 0.72637268] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27927765 0.37058731 0.52771546 0.66008065 0.72637268] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27927765 0.37058731 0.52771546 0.66008065 0.72637268] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27927765 0.37058731 0.61471525 0.66008065 0.72637268] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27927765 0.37058731 0.61471525 0.72269737 0.72637268] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27927765 0.37058731 0.61471525 0.72269737 0.77677772] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27927765 0.37058731 0.61471525 0.72269737 0.77677772] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27927765 0.37058731 0.61471525 0.72269737 0.77677772] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27927765 0.37058731 0.63460669 0.72269737 0.77677772] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27927765 0.44541186 0.63460669 0.72269737 0.77677772] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27927765 0.44541186 0.70191598 0.72269737 0.77677772] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27927765 0.44541186 0.70191598 0.77377943 0.77677772] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27927765 0.44541186 0.70191598 0.77377943 0.81789761] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27927765 0.44541186 0.70191598 0.77377943 0.81789761] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27927765 0.44541186 0.70191598 0.77377943 0.81789761] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27927765 0.44541186 0.57261567 0.77377943 0.81789761] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27927765 0.36336231 0.57261567 0.77377943 0.81789761] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22783177 0.36336231 0.57261567 0.77377943 0.81789761] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22783177 0.36336231 0.57261567 0.77377943 0.81789761] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22783177 0.36336231 0.57261567 0.77377943 0.81789761] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22783177 0.36336231 0.534069   0.77377943 0.81789761] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22783177 0.39480828 0.534069   0.77377943 0.81789761] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22783177 0.39480828 0.50841571 0.77377943 0.81789761] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.22783177 0.41573596 0.50841571 0.77377943 0.81789761] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22783177 0.41573596 0.5572985  0.77377943 0.81789761] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22783177 0.48981837 0.5572985  0.77377943 0.81789761] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.22783177 0.48981837 0.59717657 0.77377943 0.81789761] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.22783177 0.48981837 0.59717657 0.74124733 0.81789761] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.22783177 0.48981837 0.59717657 0.74124733 0.80377782] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.22783177 0.48981837 0.59717657 0.7527661  0.80377782] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22783177 0.48981837 0.67138088 0.7527661  0.80377782] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22783177 0.48981837 0.67138088 0.79830919 0.80377782] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.22783177 0.48981837 0.67138088 0.79830919 0.83992401] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.22783177 0.48981837 0.67138088 0.79830919 0.83992401] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22783177 0.48981837 0.67138088 0.79830919 0.83992401] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.22783177 0.48981837 0.63793516 0.79830919 0.83992401] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.22783177 0.44155768 0.63793516 0.79830919 0.83992401] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18586276 0.44155768 0.63793516 0.79830919 0.83992401] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18586276 0.36021811 0.63793516 0.79830919 0.83992401] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15162488 0.36021811 0.63793516 0.79830919 0.83992401] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15162488 0.36021811 0.63793516 0.79830919 0.83992401] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.15162488 0.36021811 0.63793516 0.79830919 0.83992401] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15162488 0.36021811 0.58677675 0.79830919 0.83992401] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15162488 0.36021811 0.58677675 0.67918313 0.83992401] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.15162488 0.36021811 0.54504227 0.67918313 0.83992401] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15162488 0.32179304 0.54504227 0.67918313 0.83992401] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18297165 0.32179304 0.54504227 0.67918313 0.83992401] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18297165 0.29622068 0.54504227 0.67918313 0.83992401] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.20383331 0.29622068 0.54504227 0.67918313 0.83992401] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20383331 0.27920195 0.54504227 0.67918313 0.83992401] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16628507 0.27920195 0.54504227 0.67918313 0.83992401] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16628507 0.22777001 0.54504227 0.67918313 0.83992401] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13565361 0.22777001 0.54504227 0.67918313 0.83992401] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.18421052631578946\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.39473684 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.39473684 0.39473684 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.39473684 0.39473684 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.39473684 0.41689751 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.41689751 0.41689751 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.41689751 0.53965593 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.41689751 0.53965593 0.60526316 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.41689751 0.53965593 0.60526316 0.60526316] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.41689751 0.53965593 0.60526316 0.60526316] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.41689751 0.53965593 0.60526316 0.60526316] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.41689751 0.55346798 0.60526316 0.60526316] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.55346798 0.60526316 0.60526316] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.56437222 0.60526316 0.60526316] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.45655343 0.56437222 0.59665454 0.60526316] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.56437222 0.59665454 0.60345082] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.56437222 0.59808534 0.60345082] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57146972 0.59808534 0.60345082] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57146972 0.59248205 0.60345082] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57146972 0.59248205 0.6011416 ] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57146972 0.59430511 0.6011416 ] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57627717 0.59430511 0.6011416 ] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57627717 0.59574437 0.6011416 ] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.45655343 0.57627717 0.59574437 0.68511179] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.45655343 0.57627717 0.68085082 0.68511179] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.39473684 0.45655343 0.57627717 0.68085082 0.75140405] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57627717 0.68085082 0.75140405] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39473684 0.45655343 0.57627717 0.68085082 0.75140405] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39473684 0.45655343 0.55107217 0.68085082 0.75140405] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.39473684 0.47645212 0.55107217 0.68085082 0.75140405] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.41194006 0.47645212 0.55107217 0.68085082 0.75140405] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41194006 0.46287063 0.55107217 0.68085082 0.75140405] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41194006 0.46287063 0.53250343 0.68085082 0.75140405] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41194006 0.4521484  0.53250343 0.68085082 0.75140405] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32521583 0.4521484  0.53250343 0.68085082 0.75140405] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32521583 0.35695927 0.53250343 0.68085082 0.75140405] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25674934 0.35695927 0.53250343 0.68085082 0.75140405] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25674934 0.35695927 0.53250343 0.68085082 0.75140405] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25674934 0.35695927 0.53250343 0.68085082 0.75140405] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25674934 0.35695927 0.63092376 0.68085082 0.75140405] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25674934 0.35695927 0.63092376 0.74804012 0.75140405] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25674934 0.35695927 0.63092376 0.74804012 0.80374004] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25674934 0.35695927 0.63092376 0.74804012 0.80374004] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25674934 0.35695927 0.63092376 0.74804012 0.80374004] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25674934 0.35695927 0.65557984 0.74804012 0.80374004] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25674934 0.45101838 0.65557984 0.74804012 0.80374004] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25674934 0.45101838 0.72808934 0.74804012 0.80374004] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25674934 0.45101838 0.72808934 0.80108431 0.80374004] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25674934 0.45101838 0.72808934 0.80108431 0.84505792] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25674934 0.45101838 0.72808934 0.80108431 0.84505792] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25674934 0.45101838 0.72808934 0.80108431 0.84505792] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25674934 0.45101838 0.57480738 0.80108431 0.84505792] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25674934 0.35606714 0.57480738 0.80108431 0.84505792] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20269685 0.35606714 0.57480738 0.80108431 0.84505792] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20269685 0.35606714 0.57480738 0.80108431 0.84505792] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20269685 0.35606714 0.57480738 0.80108431 0.84505792] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20269685 0.35606714 0.5287568  0.80108431 0.84505792] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20269685 0.39242286 0.5287568  0.80108431 0.84505792] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20269685 0.39242286 0.50005492 0.80108431 0.84505792] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20269685 0.41508224 0.50005492 0.80108431 0.84505792] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20269685 0.41508224 0.56342953 0.80108431 0.84505792] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20269685 0.50560344 0.56342953 0.80108431 0.84505792] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.20269685 0.50560344 0.61346211 0.80108431 0.84505792] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.20269685 0.50560344 0.61346211 0.7615849  0.84505792] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20269685 0.50560344 0.61346211 0.7615849  0.82748465] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20269685 0.50560344 0.61346211 0.77545853 0.82748465] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20269685 0.50560344 0.69483851 0.77545853 0.82748465] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20269685 0.50560344 0.69483851 0.82273042 0.82748465] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20269685 0.50560344 0.69483851 0.82273042 0.86380367] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20269685 0.50560344 0.69483851 0.82273042 0.86380367] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20269685 0.50560344 0.69483851 0.82273042 0.86380367] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.20269685 0.50560344 0.65499955 0.82273042 0.86380367] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20269685 0.44183363 0.65499955 0.82273042 0.86380367] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16002383 0.44183363 0.65499955 0.82273042 0.86380367] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16002383 0.34881602 0.65499955 0.82273042 0.86380367] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1263346  0.34881602 0.65499955 0.82273042 0.86380367] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.1263346  0.34881602 0.65499955 0.82273042 0.86380367] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.1263346  0.34881602 0.65499955 0.82273042 0.86380367] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.1263346  0.34881602 0.59053986 0.82273042 0.86380367] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1263346  0.34881602 0.59053986 0.67612077 0.86380367] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.1263346  0.34881602 0.53965063 0.67612077 0.86380367] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1263346  0.30197783 0.53965063 0.67612077 0.86380367] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16331212 0.30197783 0.53965063 0.67612077 0.86380367] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16331212 0.27278505 0.53965063 0.67612077 0.86380367] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18635905 0.27278505 0.53965063 0.67612077 0.86380367] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18635905 0.2545901  0.53965063 0.67612077 0.86380367] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.14712557 0.2545901  0.53965063 0.67612077 0.86380367] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.14712557 0.20099219 0.53965063 0.67612077 0.86380367] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11615177 0.20099219 0.53965063 0.67612077 0.86380367] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.21052631578947367\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.38157895 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.38157895 0.38157895 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.38157895 0.38157895 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.38157895 0.40962604 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.40962604 0.40962604 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.40962604 0.54945145 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.40962604 0.54945145 0.61842105 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.40962604 0.54945145 0.61842105 0.61842105] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.40962604 0.54945145 0.61842105 0.61842105] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.40962604 0.54945145 0.61842105 0.61842105] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.40962604 0.56578636 0.61842105 0.61842105] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.56578636 0.61842105 0.61842105] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.57825247 0.61842105 0.61842105] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.45907749 0.57825247 0.60890744 0.61842105] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.57825247 0.60890744 0.61616783] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.57825247 0.61062701 0.61616783] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.58592012 0.61062701 0.61616783] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.45907749 0.58592012 0.60477538 0.61616783] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.58592012 0.60477538 0.61346962] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.58592012 0.60683454 0.61346962] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.38157895 0.45907749 0.59087354 0.60683454 0.61346962] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.38157895 0.45907749 0.59087354 0.608406   0.61346962] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.45907749 0.59087354 0.608406   0.70501629] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.45907749 0.59087354 0.70115195 0.70501629] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.38157895 0.45907749 0.59087354 0.70115195 0.77488085] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.45907749 0.59087354 0.70115195 0.77488085] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.38157895 0.45907749 0.59087354 0.70115195 0.77488085] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.38157895 0.45907749 0.55965868 0.70115195 0.77488085] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.38157895 0.48289935 0.55965868 0.70115195 0.77488085] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40557589 0.48289935 0.55965868 0.70115195 0.77488085] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40557589 0.4645859  0.55965868 0.70115195 0.77488085] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40557589 0.4645859  0.53714144 0.70115195 0.77488085] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40557589 0.45060984 0.53714144 0.70115195 0.77488085] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30951844 0.45060984 0.53714144 0.70115195 0.77488085] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30951844 0.34388646 0.53714144 0.70115195 0.77488085] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23621144 0.34388646 0.53714144 0.70115195 0.77488085] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.23621144 0.34388646 0.53714144 0.70115195 0.77488085] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.23621144 0.34388646 0.53714144 0.70115195 0.77488085] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.23621144 0.34388646 0.64676584 0.70115195 0.77488085] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.23621144 0.34388646 0.64676584 0.77193175 0.77488085] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.23621144 0.34388646 0.64676584 0.77193175 0.82819854] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.23621144 0.34388646 0.64676584 0.77193175 0.82819854] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.23621144 0.34388646 0.64676584 0.77193175 0.82819854] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.23621144 0.34388646 0.6764104  0.77193175 0.82819854] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.23621144 0.45859195 0.6764104  0.77193175 0.82819854] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.23621144 0.45859195 0.75305004 0.77193175 0.82819854] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.23621144 0.45859195 0.75305004 0.82594792 0.82819854] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.23621144 0.45859195 0.75305004 0.82594792 0.86888836] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.23621144 0.45859195 0.75305004 0.82594792 0.86888836] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.23621144 0.45859195 0.75305004 0.82594792 0.86888836] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23621144 0.45859195 0.57469608 0.82594792 0.86888836] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23621144 0.34997807 0.57469608 0.82594792 0.86888836] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18026663 0.34997807 0.57469608 0.82594792 0.86888836] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18026663 0.34997807 0.57469608 0.82594792 0.86888836] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18026663 0.34997807 0.57469608 0.82594792 0.86888836] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18026663 0.34997807 0.5214734  0.82594792 0.86888836] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18026663 0.39059538 0.5214734  0.82594792 0.86888836] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18026663 0.39059538 0.49047597 0.82594792 0.86888836] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18026663 0.41425131 0.49047597 0.82594792 0.86888836] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18026663 0.41425131 0.56992985 0.82594792 0.86888836] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18026663 0.52192851 0.56992985 0.82594792 0.86888836] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.18026663 0.52192851 0.63056571 0.82594792 0.86888836] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.18026663 0.52192851 0.63056571 0.77967318 0.86888836] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18026663 0.52192851 0.63056571 0.77967318 0.84775845] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18026663 0.52192851 0.63056571 0.79579864 0.84775845] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18026663 0.52192851 0.71806331 0.79579864 0.84775845] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18026663 0.52192851 0.71806331 0.84416212 0.84775845] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18026663 0.52192851 0.71806331 0.84416212 0.88381566] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18026663 0.52192851 0.71806331 0.84416212 0.88381566] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18026663 0.52192851 0.71806331 0.84416212 0.88381566] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.18026663 0.52192851 0.67161033 0.84416212 0.88381566] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18026663 0.44100859 0.67161033 0.84416212 0.88381566] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1375719  0.44100859 0.67161033 0.84416212 0.88381566] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1375719  0.33655919 0.67161033 0.84416212 0.88381566] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10498908 0.33655919 0.67161033 0.84416212 0.88381566] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.10498908 0.33655919 0.67161033 0.84416212 0.88381566] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.10498908 0.33655919 0.67161033 0.84416212 0.88381566] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.10498908 0.33655919 0.59225611 0.84416212 0.88381566] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.10498908 0.33655919 0.59225611 0.66909482 0.88381566] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.10498908 0.33655919 0.53169631 0.66909482 0.88381566] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.10498908 0.28171363 0.53169631 0.66909482 0.88381566] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.1468449  0.28171363 0.53169631 0.66909482 0.88381566] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1468449  0.24977104 0.53169631 0.66909482 0.88381566] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.17122214 0.24977104 0.53169631 0.66909482 0.88381566] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17122214 0.23116735 0.53169631 0.66909482 0.88381566] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13066953 0.23116735 0.53169631 0.66909482 0.88381566] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13066953 0.17641719 0.53169631 0.66909482 0.88381566] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09972148 0.17641719 0.53169631 0.66909482 0.88381566] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.23684210526315788\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.36842105 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.36842105 0.36842105 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.36842105 0.36842105 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.36842105 0.40304709 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.40304709 0.40304709 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.40304709 0.56013996 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.40304709 0.56013996 0.63157895 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.40304709 0.56013996 0.63157895 0.63157895] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.40304709 0.56013996 0.63157895 0.63157895] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.40304709 0.56013996 0.63157895 0.63157895] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.40304709 0.5789397  0.63157895 0.63157895] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.5789397  0.63157895 0.63157895] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.59279213 0.63157895 0.63157895] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.46318705 0.59279213 0.62137189 0.63157895] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.59279213 0.62137189 0.62889288] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.59279213 0.6233511  0.62889288] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60083396 0.6233511  0.62889288] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60083396 0.61742554 0.62889288] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60083396 0.61742554 0.62587516] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60083396 0.61964912 0.62587516] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60578532 0.61964912 0.62587516] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60578532 0.62128755 0.62587516] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.46318705 0.60578532 0.62128755 0.72432906] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.46318705 0.60578532 0.72094872 0.72432906] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.36842105 0.46318705 0.60578532 0.72094872 0.79687405] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60578532 0.72094872 0.79687405] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.36842105 0.46318705 0.60578532 0.72094872 0.79687405] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.36842105 0.46318705 0.56825946 0.72094872 0.79687405] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.36842105 0.49083769 0.56825946 0.72094872 0.79687405] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40063596 0.49083769 0.56825946 0.72094872 0.79687405] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40063596 0.46710039 0.56825946 0.72094872 0.79687405] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40063596 0.46710039 0.54163865 0.72094872 0.79687405] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40063596 0.44960975 0.54163865 0.72094872 0.79687405] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29520544 0.44960975 0.54163865 0.72094872 0.79687405] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.29520544 0.33129139 0.54163865 0.72094872 0.79687405] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2175198  0.33129139 0.54163865 0.72094872 0.79687405] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.2175198  0.33129139 0.54163865 0.72094872 0.79687405] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.2175198  0.33129139 0.54163865 0.72094872 0.79687405] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2175198  0.33129139 0.66226006 0.72094872 0.79687405] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2175198  0.33129139 0.66226006 0.79438327 0.79687405] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2175198  0.33129139 0.66226006 0.79438327 0.85032825] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2175198  0.33129139 0.66226006 0.79438327 0.85032825] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.2175198  0.33129139 0.66226006 0.79438327 0.85032825] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.2175198  0.33129139 0.69702933 0.79438327 0.85032825] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.2175198  0.46788004 0.69702933 0.79438327 0.85032825] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2175198  0.46788004 0.77675845 0.79438327 0.85032825] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2175198  0.46788004 0.77675845 0.84849294 0.85032825] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.2175198  0.46788004 0.77675845 0.84849294 0.88971555] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.2175198  0.46788004 0.77675845 0.84849294 0.88971555] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.2175198  0.46788004 0.77675845 0.84849294 0.88971555] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2175198  0.46788004 0.57234833 0.84849294 0.88971555] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.2175198  0.34475371 0.57234833 0.84849294 0.88971555] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.16027775 0.34475371 0.57234833 0.84849294 0.88971555] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16027775 0.34475371 0.57234833 0.84849294 0.88971555] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16027775 0.34475371 0.57234833 0.84849294 0.88971555] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16027775 0.34475371 0.51245501 0.84849294 0.88971555] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16027775 0.38888563 0.51245501 0.84849294 0.88971555] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16027775 0.38888563 0.47993675 0.84849294 0.88971555] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.16027775 0.41284645 0.47993675 0.84849294 0.88971555] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16027775 0.41284645 0.57692522 0.84849294 0.88971555] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.16027775 0.53833832 0.57692522 0.84849294 0.88971555] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.16027775 0.53833832 0.64839041 0.84849294 0.88971555] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.16027775 0.53833832 0.64839041 0.79583438 0.88971555] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.16027775 0.53833832 0.64839041 0.79583438 0.86500998] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.16027775 0.53833832 0.64839041 0.81403848 0.86500998] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.16027775 0.53833832 0.74091925 0.81403848 0.86500998] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.16027775 0.53833832 0.74091925 0.86297572 0.86500998] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.16027775 0.53833832 0.74091925 0.86297572 0.90053367] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.16027775 0.53833832 0.74091925 0.86297572 0.90053367] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16027775 0.53833832 0.74091925 0.86297572 0.90053367] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.16027775 0.53833832 0.68760848 0.86297572 0.90053367] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.16027775 0.4388487  0.68760848 0.86297572 0.90053367] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11809939 0.4388487  0.68760848 0.86297572 0.90053367] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11809939 0.3233622  0.68760848 0.86297572 0.90053367] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0870206  0.3233622  0.68760848 0.86297572 0.90053367] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.0870206  0.3233622  0.68760848 0.86297572 0.90053367] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.0870206  0.3233622  0.68760848 0.86297572 0.90053367] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0870206  0.3233622  0.59175419 0.86297572 0.90053367] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0870206  0.3233622  0.59175419 0.65877701 0.90053367] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.0870206  0.3233622  0.52112472 0.65877701 0.90053367] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0870206  0.26116704 0.52112472 0.65877701 0.90053367] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.13284861 0.26116704 0.52112472 0.65877701 0.90053367] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13284861 0.22739903 0.52112472 0.65877701 0.90053367] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.1577303  0.22739903 0.52112472 0.65877701 0.90053367] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1577303  0.20906516 0.52112472 0.65877701 0.90053367] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11622233 0.20906516 0.52112472 0.65877701 0.90053367] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11622233 0.15404801 0.52112472 0.65877701 0.90053367] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08563751 0.15404801 0.52112472 0.65877701 0.90053367] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.2631578947368421\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.35526316 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.35526316 0.35526316 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.35526316 0.35526316 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.35526316 0.39716066 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.39716066 0.39716066 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.39716066 0.57166679 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.39716066 0.57166679 0.64473684 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.39716066 0.57166679 0.64473684 0.64473684] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.39716066 0.57166679 0.64473684 0.64473684] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.39716066 0.57166679 0.64473684 0.64473684] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.39716066 0.59281865 0.64473684 0.64473684] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.59281865 0.64473684 0.64473684] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.6078476  0.64473684 0.64473684] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.46882745 0.6078476  0.63405838 0.64473684] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.6078476  0.63405838 0.64164571] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.6078476  0.63625471 0.64164571] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.61607071 0.63625471 0.64164571] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.46882745 0.61607071 0.63041197 0.64164571] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.61607071 0.63041197 0.63839384] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.61607071 0.63272251 0.63839384] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.35526316 0.46882745 0.62089097 0.63272251 0.63839384] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.35526316 0.46882745 0.62089097 0.63436421 0.63839384] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.46882745 0.62089097 0.63436421 0.7430693 ] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.46882745 0.62089097 0.74020615 0.7430693 ] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.35526316 0.46882745 0.62089097 0.74020615 0.81744398] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.46882745 0.62089097 0.74020615 0.81744398] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.35526316 0.46882745 0.62089097 0.74020615 0.81744398] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.35526316 0.46882745 0.57687258 0.74020615 0.81744398] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.35526316 0.50010367 0.57687258 0.74020615 0.81744398] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39719068 0.50010367 0.57687258 0.74020615 0.81744398] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39719068 0.47031307 0.57687258 0.74020615 0.81744398] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39719068 0.47031307 0.54602641 0.74020615 0.81744398] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39719068 0.44914606 0.54602641 0.74020615 0.81744398] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28221443 0.44914606 0.54602641 0.74020615 0.81744398] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28221443 0.3191301  0.54602641 0.74020615 0.81744398] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20052078 0.3191301  0.54602641 0.74020615 0.81744398] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20052078 0.3191301  0.54602641 0.74020615 0.81744398] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20052078 0.3191301  0.54602641 0.74020615 0.81744398] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20052078 0.3191301  0.67743982 0.74020615 0.81744398] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20052078 0.3191301  0.67743982 0.81540963 0.81744398] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20052078 0.3191301  0.67743982 0.81540963 0.87028914] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20052078 0.3191301  0.67743982 0.81540963 0.87028914] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.20052078 0.3191301  0.67743982 0.81540963 0.87028914] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.20052078 0.3191301  0.71737845 0.81540963 0.87028914] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.20052078 0.47867614 0.71737845 0.81540963 0.87028914] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20052078 0.47867614 0.79918995 0.81540963 0.87028914] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20052078 0.47867614 0.79918995 0.86884369 0.87028914] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.20052078 0.47867614 0.79918995 0.86884369 0.90783702] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.20052078 0.47867614 0.79918995 0.86884369 0.90783702] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.20052078 0.47867614 0.79918995 0.86884369 0.90783702] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20052078 0.47867614 0.56784549 0.86884369 0.90783702] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.20052078 0.34011199 0.56784549 0.86884369 0.90783702] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.14247529 0.34011199 0.56784549 0.86884369 0.90783702] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.14247529 0.34011199 0.56784549 0.86884369 0.90783702] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.14247529 0.34011199 0.56784549 0.86884369 0.90783702] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.14247529 0.34011199 0.50192264 0.86884369 0.90783702] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.14247529 0.38695191 0.50192264 0.86884369 0.90783702] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.14247529 0.38695191 0.46864164 0.86884369 0.90783702] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.14247529 0.41059894 0.46864164 0.86884369 0.90783702] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.14247529 0.41059894 0.5844896  0.86884369 0.90783702] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.14247529 0.55453628 0.5844896  0.86884369 0.90783702] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.14247529 0.55453628 0.66680262 0.86884369 0.90783702] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.14247529 0.55453628 0.66680262 0.81035812 0.90783702] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.14247529 0.55453628 0.66680262 0.81035812 0.87961944] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.14247529 0.55453628 0.66680262 0.83040745 0.87961944] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.14247529 0.55453628 0.7632545  0.83040745 0.87961944] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.14247529 0.55453628 0.7632545  0.87950003 0.87961944] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.14247529 0.55453628 0.7632545  0.87950003 0.91446645] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.14247529 0.55453628 0.7632545  0.87950003 0.91446645] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14247529 0.55453628 0.7632545  0.87950003 0.91446645] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14247529 0.55453628 0.70283607 0.87950003 0.91446645] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14247529 0.43525547 0.70283607 0.87950003 0.91446645] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10123244 0.43525547 0.70283607 0.87950003 0.91446645] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10123244 0.30926046 0.70283607 0.87950003 0.91446645] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07192831 0.30926046 0.70283607 0.87950003 0.91446645] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.07192831 0.30926046 0.70283607 0.87950003 0.91446645] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.07192831 0.30926046 0.70283607 0.87950003 0.91446645] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07192831 0.30926046 0.58890629 0.87950003 0.91446645] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07192831 0.30926046 0.58890629 0.64572927 0.91446645] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.07192831 0.30926046 0.50795618 0.64572927 0.91446645] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07192831 0.24055905 0.50795618 0.64572927 0.91446645] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12074248 0.24055905 0.50795618 0.64572927 0.91446645] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12074248 0.20587531 0.50795618 0.64572927 0.91446645] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.14538619 0.20587531 0.50795618 0.64572927 0.91446645] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.14538619 0.1883653  0.50795618 0.64572927 0.91446645] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10330071 0.1883653  0.50795618 0.64572927 0.91446645] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10330071 0.1338385  0.50795618 0.64572927 0.91446645] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07339788 0.1338385  0.50795618 0.64572927 0.91446645] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.2894736842105263\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.34210526 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.34210526 0.34210526 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.34210526 0.34210526 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.34210526 0.39196676 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.39196676 0.39196676 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.39196676 0.58397726 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.39196676 0.58397726 0.65789474 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.39196676 0.58397726 0.65789474 0.65789474] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.39196676 0.58397726 0.65789474 0.65789474] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.39196676 0.58397726 0.65789474 0.65789474] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.39196676 0.60731962 0.65789474 0.65789474] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.60731962 0.65789474 0.65789474] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.62329071 0.65789474 0.65789474] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.47594402 0.62329071 0.64696715 0.65789474] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.62329071 0.64696715 0.65444392] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.62329071 0.64932823 0.65444392] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63151309 0.64932823 0.65444392] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63151309 0.6437024  0.65444392] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63151309 0.6437024  0.65105186] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63151309 0.64602328 0.65105186] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63609525 0.64602328 0.65105186] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63609525 0.64761125 0.65105186] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.47594402 0.63609525 0.64761125 0.76124601] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.47594402 0.63609525 0.75889191 0.76124601] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.34210526 0.47594402 0.63609525 0.75889191 0.83664201] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63609525 0.75889191 0.83664201] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.34210526 0.47594402 0.63609525 0.75889191 0.83664201] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.34210526 0.47594402 0.58552118 0.75889191 0.83664201] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.34210526 0.51054733 0.58552118 0.75889191 0.83664201] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39529749 0.51054733 0.58552118 0.75889191 0.83664201] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39529749 0.47415264 0.58552118 0.75889191 0.83664201] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39529749 0.47415264 0.55035217 0.75889191 0.83664201] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39529749 0.44925102 0.55035217 0.75889191 0.83664201] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27046671 0.44925102 0.55035217 0.75889191 0.83664201] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27046671 0.30738228 0.55035217 0.75889191 0.83664201] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18505617 0.30738228 0.55035217 0.75889191 0.83664201] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18505617 0.30738228 0.55035217 0.75889191 0.83664201] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18505617 0.30738228 0.55035217 0.75889191 0.83664201] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18505617 0.30738228 0.69234622 0.75889191 0.83664201] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18505617 0.30738228 0.69234622 0.83503131 0.83664201] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18505617 0.30738228 0.69234622 0.83503131 0.88822874] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18505617 0.30738228 0.69234622 0.83503131 0.88822874] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.18505617 0.30738228 0.69234622 0.83503131 0.88822874] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.18505617 0.30738228 0.73740467 0.83503131 0.88822874] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.18505617 0.49080748 0.73740467 0.83503131 0.88822874] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18505617 0.49080748 0.82032951 0.83503131 0.88822874] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18505617 0.49080748 0.82032951 0.88712668 0.88822874] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.18505617 0.49080748 0.82032951 0.88712668 0.92352493] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.18505617 0.49080748 0.82032951 0.88712668 0.92352493] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.18505617 0.49080748 0.82032951 0.88712668 0.92352493] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18505617 0.49080748 0.56127809 0.88712668 0.92352493] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.18505617 0.33581564 0.56127809 0.88712668 0.92352493] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12661738 0.33581564 0.56127809 0.88712668 0.92352493] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12661738 0.33581564 0.56127809 0.88712668 0.92352493] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12661738 0.33581564 0.56127809 0.88712668 0.92352493] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12661738 0.33581564 0.49007942 0.88712668 0.92352493] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12661738 0.38453052 0.49007942 0.88712668 0.92352493] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12661738 0.38453052 0.45674819 0.88712668 0.92352493] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12661738 0.4073361  0.45674819 0.88712668 0.92352493] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12661738 0.4073361  0.59265719 0.88712668 0.92352493] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12661738 0.5703431  0.59265719 0.88712668 0.92352493] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.12661738 0.5703431  0.68564755 0.88712668 0.92352493] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.12661738 0.5703431  0.68564755 0.8235017  0.92352493] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12661738 0.5703431  0.68564755 0.8235017  0.89193864] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12661738 0.5703431  0.68564755 0.84511336 0.89193864] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12661738 0.5703431  0.78491675 0.84511336 0.89193864] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12661738 0.5703431  0.78491675 0.89402493 0.89193864] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12661738 0.5703431  0.78491675 0.89402493 0.92606328] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12661738 0.5703431  0.78491675 0.89402493 0.92606328] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12661738 0.5703431  0.78491675 0.89402493 0.92606328] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12661738 0.5703431  0.71715665 0.89402493 0.92606328] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12661738 0.43021919 0.71715665 0.89402493 0.92606328] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08663294 0.43021919 0.71715665 0.89402493 0.92606328] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08663294 0.2943605  0.71715665 0.89402493 0.92606328] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05927517 0.2943605  0.71715665 0.89402493 0.92606328] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.05927517 0.2943605  0.71715665 0.89402493 0.92606328] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.05927517 0.2943605  0.71715665 0.89402493 0.92606328] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.05927517 0.2943605  0.58364207 0.89402493 0.92606328] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05927517 0.2943605  0.58364207 0.63041974 0.92606328] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.05927517 0.2943605  0.49229    0.63041974 0.92606328] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05927517 0.22012302 0.49229    0.63041974 0.92606328] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11006923 0.22012302 0.49229    0.63041974 0.92606328] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11006923 0.18536919 0.49229    0.63041974 0.92606328] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.13384817 0.18536919 0.49229    0.63041974 0.92606328] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13384817 0.1690994  0.49229    0.63041974 0.92606328] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09158032 0.1690994  0.49229    0.63041974 0.92606328] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09158032 0.11569959 0.49229    0.63041974 0.92606328] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06266022 0.11569959 0.49229    0.63041974 0.92606328] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.3157894736842105\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.32894737 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.32894737 0.32894737 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.32894737 0.32894737 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.32894737 0.38746537 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.38746537 0.38746537 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.38746537 0.59701669 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.38746537 0.59701669 0.67105263 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.38746537 0.59701669 0.67105263 0.67105263] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.38746537 0.59701669 0.67105263 0.67105263] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.38746537 0.59701669 0.67105263 0.67105263] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.38746537 0.62234478 0.67105263 0.67105263] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.62234478 0.67105263 0.67105263] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.63900799 0.67105263 0.67105263] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.48448207 0.63900799 0.66008999 0.67105263] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.63900799 0.66008999 0.66730225] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.63900799 0.66255734 0.66730225] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.64706435 0.66255734 0.66730225] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.48448207 0.64706435 0.65725711 0.66730225] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.64706435 0.65725711 0.66386576] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.64706435 0.65951796 0.66386576] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.32894737 0.48448207 0.6513248  0.65951796 0.66386576] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.32894737 0.48448207 0.6513248  0.66100537 0.66386576] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.48448207 0.6513248  0.66100537 0.77885905] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.48448207 0.6513248  0.77697721 0.77885905] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.32894737 0.48448207 0.6513248  0.77697721 0.85451253] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.48448207 0.6513248  0.77697721 0.85451253] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.32894737 0.48448207 0.6513248  0.77697721 0.85451253] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.32894737 0.48448207 0.59424702 0.77697721 0.85451253] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.32894737 0.52203324 0.59424702 0.77697721 0.85451253] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39500306 0.52203324 0.59424702 0.77697721 0.85451253] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39500306 0.47857554 0.59424702 0.77697721 0.85451253] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39500306 0.47857554 0.5546752  0.77697721 0.85451253] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39500306 0.44998496 0.5546752  0.77697721 0.85451253] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25987043 0.44998496 0.5546752  0.77697721 0.85451253] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25987043 0.29604273 0.5546752  0.77697721 0.85451253] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17096739 0.29604273 0.5546752  0.77697721 0.85451253] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17096739 0.29604273 0.5546752  0.77697721 0.85451253] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.17096739 0.29604273 0.5546752  0.77697721 0.85451253] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17096739 0.29604273 0.70702316 0.77697721 0.85451253] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17096739 0.29604273 0.70702316 0.85327448 0.85451253] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17096739 0.29604273 0.70702316 0.85327448 0.90428456] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17096739 0.29604273 0.70702316 0.85327448 0.90428456] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.17096739 0.29604273 0.70702316 0.85327448 0.90428456] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.17096739 0.29604273 0.75705651 0.85327448 0.90428456] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.17096739 0.50412547 0.75705651 0.85327448 0.90428456] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17096739 0.50412547 0.84016875 0.85327448 0.90428456] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17096739 0.50412547 0.84016875 0.90347005 0.90428456] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.17096739 0.50412547 0.84016875 0.90347005 0.93702932] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.17096739 0.50412547 0.84016875 0.90347005 0.93702932] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.17096739 0.50412547 0.84016875 0.90347005 0.93702932] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17096739 0.50412547 0.5527426  0.90347005 0.93702932] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.17096739 0.33166149 0.5527426  0.90347005 0.93702932] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11247855 0.33166149 0.5527426  0.90347005 0.93702932] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11247855 0.33166149 0.5527426  0.90347005 0.93702932] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11247855 0.33166149 0.5527426  0.90347005 0.93702932] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11247855 0.33166149 0.47710959 0.90347005 0.93702932] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11247855 0.38142005 0.47710959 0.90347005 0.93702932] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11247855 0.38142005 0.44437369 0.90347005 0.93702932] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11247855 0.40295682 0.44437369 0.90347005 0.93702932] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11247855 0.40295682 0.60143298 0.90347005 0.93702932] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11247855 0.58566583 0.60143298 0.90347005 0.93702932] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.11247855 0.58566583 0.70476145 0.90347005 0.93702932] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.11247855 0.58566583 0.70476145 0.8354908  0.93702932] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11247855 0.58566583 0.70476145 0.8354908  0.90229245] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11247855 0.58566583 0.70476145 0.85834399 0.90229245] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11247855 0.58566583 0.80576411 0.85834399 0.90229245] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11247855 0.58566583 0.80576411 0.90680526 0.90229245] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11247855 0.58566583 0.80576411 0.90680526 0.93571872] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11247855 0.58566583 0.80576411 0.90680526 0.93571872] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11247855 0.58566583 0.80576411 0.90680526 0.93571872] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11247855 0.58566583 0.73046733 0.90680526 0.93571872] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11247855 0.42378597 0.73046733 0.90680526 0.93571872] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07399904 0.42378597 0.73046733 0.90680526 0.93571872] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07399904 0.27880656 0.73046733 0.90680526 0.93571872] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04868358 0.27880656 0.73046733 0.90680526 0.93571872] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.04868358 0.27880656 0.73046733 0.90680526 0.93571872] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.04868358 0.27880656 0.73046733 0.90680526 0.93571872] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.04868358 0.27880656 0.57595181 0.90680526 0.93571872] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.04868358 0.27880656 0.57595181 0.61323732 0.93571872] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.04868358 0.27880656 0.47429685 0.61323732 0.93571872] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.04868358 0.20008028 0.47429685 0.61323732 0.93571872] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.10047719 0.20008028 0.47429685 0.61323732 0.93571872] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.10047719 0.16600554 0.47429685 0.61323732 0.93571872] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.12289478 0.16600554 0.47429685 0.61323732 0.93571872] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12289478 0.15125712 0.47429685 0.61323732 0.93571872] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08085183 0.15125712 0.47429685 0.61323732 0.93571872] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08085183 0.09951126 0.47429685 0.61323732 0.93571872] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05319199 0.09951126 0.47429685 0.61323732 0.93571872] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.3421052631578947\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.31578947 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.31578947 0.31578947 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.31578947 0.31578947 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.31578947 0.38365651 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.38365651 0.38365651 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.38365651 0.61073043 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.38365651 0.61073043 0.68421053 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.38365651 0.61073043 0.68421053 0.68421053] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.38365651 0.61073043 0.68421053 0.68421053] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.38365651 0.61073043 0.68421053 0.68421053] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.38365651 0.63780204 0.68421053 0.68421053] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.63780204 0.68421053 0.68421053] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.65489991 0.68421053 0.68421053] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.49438694 0.65489991 0.67341188 0.68421053] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.65489991 0.67341188 0.68023208] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.65489991 0.67592458 0.68023208] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66264584 0.67592458 0.68023208] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66264584 0.67103241 0.68023208] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66264584 0.67103241 0.67684273] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66264584 0.67317305 0.67684273] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66652429 0.67317305 0.67684273] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66652429 0.67452504 0.67684273] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.49438694 0.66652429 0.67452504 0.79590067] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.49438694 0.66652429 0.79443687 0.79590067] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.31578947 0.49438694 0.66652429 0.79443687 0.87109516] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66652429 0.79443687 0.87109516] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.31578947 0.49438694 0.66652429 0.79443687 0.87109516] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.31578947 0.49438694 0.60310526 0.79443687 0.87109516] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.31578947 0.53444106 0.60310526 0.79443687 0.87109516] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39634532 0.53444106 0.60310526 0.79443687 0.87109516] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39634532 0.48356368 0.60310526 0.79443687 0.87109516] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39634532 0.48356368 0.55906363 0.79443687 0.87109516] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39634532 0.4514306  0.55906363 0.79443687 0.87109516] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25032336 0.4514306  0.55906363 0.79443687 0.87109516] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25032336 0.28511406 0.55906363 0.79443687 0.87109516] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15809896 0.28511406 0.55906363 0.79443687 0.87109516] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15809896 0.28511406 0.55906363 0.79443687 0.87109516] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.15809896 0.28511406 0.55906363 0.79443687 0.87109516] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15809896 0.28511406 0.72151387 0.79443687 0.87109516] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15809896 0.28511406 0.72151387 0.87017065 0.87109516] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15809896 0.28511406 0.72151387 0.87017065 0.91858642] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15809896 0.28511406 0.72151387 0.87017065 0.91858642] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.15809896 0.28511406 0.72151387 0.87017065 0.91858642] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.15809896 0.28511406 0.77628216 0.87017065 0.91858642] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.15809896 0.51849861 0.77628216 0.87017065 0.91858642] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15809896 0.51849861 0.85870452 0.87017065 0.91858642] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15809896 0.51849861 0.85870452 0.91800252 0.91858642] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.15809896 0.51849861 0.85870452 0.91800252 0.94858089] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.15809896 0.51849861 0.85870452 0.91800252 0.94858089] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.15809896 0.51849861 0.85870452 0.91800252 0.94858089] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15809896 0.51849861 0.5423397  0.91800252 0.94858089] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.15809896 0.32747281 0.5423397  0.91800252 0.94858089] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.09985198 0.32747281 0.5423397  0.91800252 0.94858089] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09985198 0.32747281 0.5423397  0.91800252 0.94858089] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09985198 0.32747281 0.5423397  0.91800252 0.94858089] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09985198 0.32747281 0.46317821 0.91800252 0.94858089] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09985198 0.37746954 0.46317821 0.91800252 0.94858089] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09985198 0.37746954 0.43160133 0.91800252 0.94858089] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.09985198 0.39741283 0.43160133 0.91800252 0.94858089] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09985198 0.39741283 0.61080177 0.91800252 0.94858089] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.09985198 0.60047475 0.61080177 0.91800252 0.94858089] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.09985198 0.60047475 0.72398099 0.91800252 0.94858089] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.09985198 0.60047475 0.72398099 0.8465209  0.94858089] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.09985198 0.60047475 0.72398099 0.8465209  0.91097985] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.09985198 0.60047475 0.72398099 0.87026893 0.91097985] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.09985198 0.60047475 0.82567221 0.87026893 0.91097985] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.09985198 0.60047475 0.82567221 0.91806459 0.91097985] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.09985198 0.60047475 0.82567221 0.91806459 0.94377674] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.09985198 0.60047475 0.82567221 0.91806459 0.94377674] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09985198 0.60047475 0.82567221 0.91806459 0.94377674] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.09985198 0.60047475 0.74270472 0.91806459 0.94377674] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09985198 0.41603478 0.74270472 0.91806459 0.94377674] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06306441 0.41603478 0.74270472 0.91806459 0.94377674] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06306441 0.26275881 0.74270472 0.91806459 0.94377674] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03983015 0.26275881 0.74270472 0.91806459 0.94377674] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.03983015 0.26275881 0.74270472 0.91806459 0.94377674] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.03983015 0.26275881 0.74270472 0.91806459 0.94377674] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.03983015 0.26275881 0.56588254 0.91806459 0.94377674] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.03983015 0.26275881 0.56588254 0.59450453 0.94377674] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.03983015 0.26275881 0.45420538 0.59450453 0.94377674] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.03983015 0.1806272  0.45420538 0.59450453 0.94377674] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.09170275 0.1806272  0.45420538 0.59450453 0.94377674] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09170275 0.14786556 0.45420538 0.59450453 0.94377674] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.11239431 0.14786556 0.45420538 0.59450453 0.94377674] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11239431 0.1347972  0.45420538 0.59450453 0.94377674] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07098588 0.1347972  0.45420538 0.59450453 0.94377674] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07098588 0.08513508 0.45420538 0.59450453 0.94377674] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04483319 0.08513508 0.45420538 0.59450453 0.94377674] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.3684210526315789\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.30263158 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.30263158 0.30263158 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.30263158 0.30263158 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.30263158 0.38054017 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.38054017 0.38054017 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.38054017 0.62506378 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.38054017 0.62506378 0.69736842 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.38054017 0.62506378 0.69736842 0.69736842] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.38054017 0.62506378 0.69736842 0.69736842] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.38054017 0.62506378 0.69736842 0.69736842] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.38054017 0.65360509 0.69736842 0.69736842] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.65360509 0.69736842 0.69736842] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67088009 0.69736842 0.69736842] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67088009 0.6869125  0.69736842] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67088009 0.6869125  0.69324108] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67088009 0.68941063 0.69324108] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67819477 0.68941063 0.69324108] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67819477 0.68498332 0.69324108] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67819477 0.68498332 0.68998144] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.67819477 0.68695626 0.68998144] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.30263158 0.50560395 0.68165325 0.68695626 0.68998144] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.30263158 0.50560395 0.68165325 0.68815041 0.68998144] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.50560395 0.68165325 0.68815041 0.81235719] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.50560395 0.68165325 0.81124893 0.81235719] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.30263158 0.50560395 0.68165325 0.81124893 0.88642672] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.50560395 0.68165325 0.81124893 0.88642672] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.30263158 0.50560395 0.68165325 0.81124893 0.88642672] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.30263158 0.50560395 0.61216011 0.81124893 0.88642672] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.30263158 0.54766559 0.61216011 0.81124893 0.88642672] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.39935553 0.54766559 0.61216011 0.81124893 0.88642672] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39935553 0.48912215 0.61216011 0.81124893 0.88642672] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.39935553 0.48912215 0.56359249 0.81124893 0.88642672] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.39935553 0.45368796 0.56359249 0.81124893 0.88642672] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24171519 0.45368796 0.56359249 0.81124893 0.88642672] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.24171519 0.27460061 0.56359249 0.81124893 0.88642672] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1463013  0.27460061 0.56359249 0.81124893 0.88642672] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.1463013  0.27460061 0.56359249 0.81124893 0.88642672] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.1463013  0.27460061 0.56359249 0.81124893 0.88642672] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.1463013  0.27460061 0.73585861 0.81124893 0.88642672] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.1463013  0.27460061 0.73585861 0.88575593 0.88642672] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.1463013  0.27460061 0.73585861 0.88575593 0.93125828] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.1463013  0.27460061 0.73585861 0.88575593 0.93125828] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.1463013  0.27460061 0.73585861 0.88575593 0.93125828] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.1463013  0.27460061 0.79502861 0.88575593 0.93125828] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.1463013  0.53380758 0.79502861 0.88575593 0.93125828] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.1463013  0.53380758 0.87593837 0.88575593 0.93125828] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.1463013  0.53380758 0.87593837 0.93085227 0.93125828] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.1463013  0.53380758 0.87593837 0.93085227 0.95839317] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.1463013  0.53380758 0.87593837 0.93085227 0.95839317] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.1463013  0.53380758 0.87593837 0.93085227 0.95839317] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1463013  0.53380758 0.53017322 0.93085227 0.95839317] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.1463013  0.32309406 0.53017322 0.93085227 0.95839317] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.08855079 0.32309406 0.53017322 0.93085227 0.95839317] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08855079 0.32309406 0.53017322 0.93085227 0.95839317] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08855079 0.32309406 0.53017322 0.93085227 0.95839317] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08855079 0.32309406 0.44843145 0.93085227 0.95839317] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08855079 0.37256935 0.44843145 0.93085227 0.95839317] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08855079 0.37256935 0.41848588 0.93085227 0.95839317] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.08855079 0.39069429 0.41848588 0.93085227 0.95839317] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08855079 0.39069429 0.62073577 0.93085227 0.95839317] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.08855079 0.61478595 0.62073577 0.93085227 0.95839317] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.08855079 0.61478595 0.74315018 0.93085227 0.95839317] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.08855079 0.61478595 0.74315018 0.85675934 0.95839317] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.08855079 0.61478595 0.74315018 0.85675934 0.91827455] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.08855079 0.61478595 0.74315018 0.88104166 0.91827455] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.08855079 0.61478595 0.84453827 0.88104166 0.91827455] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.08855079 0.61478595 0.84453827 0.9279989  0.91827455] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.08855079 0.61478595 0.84453827 0.9279989  0.9505346 ] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.08855079 0.61478595 0.84453827 0.9279989  0.9505346 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08855079 0.61478595 0.84453827 0.9279989  0.9505346 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08855079 0.61478595 0.75384657 0.9279989  0.9505346 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08855079 0.40706155 0.75384657 0.9279989  0.9505346 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05359653 0.40706155 0.75384657 0.9279989  0.9505346 ] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05359653 0.24637936 0.75384657 0.9279989  0.9505346 ] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03244    0.24637936 0.75384657 0.9279989  0.9505346 ] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.03244    0.24637936 0.75384657 0.9279989  0.9505346 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.03244    0.24637936 0.75384657 0.9279989  0.9505346 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.03244    0.24637936 0.55353056 0.9279989  0.9505346 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.03244    0.24637936 0.55353056 0.57448881 0.9505346 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.03244    0.24637936 0.43228667 0.57448881 0.9505346 ] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.03244    0.16192961 0.43228667 0.57448881 0.9505346 ] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08355432 0.16192961 0.43228667 0.57448881 0.9505346 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08355432 0.130992   0.43228667 0.57448881 0.9505346 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.10227972 0.130992   0.43228667 0.57448881 0.9505346 ] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.10227972 0.1196582  0.43228667 0.57448881 0.9505346 ] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06190615 0.1196582  0.43228667 0.57448881 0.9505346 ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.06190615 0.0724247  0.43228667 0.57448881 0.9505346 ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03746951 0.0724247  0.43228667 0.57448881 0.9505346 ] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.39473684210526316\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.28947368 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.28947368 0.28947368 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.28947368 0.28947368 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.28947368 0.37811634 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.37811634 0.37811634 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.37811634 0.63996209 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.37811634 0.63996209 0.71052632 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.37811634 0.63996209 0.71052632 0.71052632] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.37811634 0.63996209 0.71052632 0.71052632] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.37811634 0.63996209 0.71052632 0.71052632] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.37811634 0.66967335 0.71052632 0.71052632] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.66967335 0.71052632 0.71052632] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.6868746  0.71052632 0.71052632] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.51807844 0.6868746  0.7005677  0.71052632] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.6868746  0.7005677  0.70633321] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.6868746  0.70299528 0.70633321] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69366225 0.70299528 0.70633321] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69366225 0.69906559 0.70633321] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69366225 0.69906559 0.70327316] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69366225 0.7008372  0.70327316] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69668328 0.7008372  0.70327316] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69668328 0.70186286 0.70327316] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.51807844 0.69668328 0.70186286 0.82821078] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.51807844 0.69668328 0.82739429 0.82821078] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.28947368 0.51807844 0.69668328 0.82739429 0.90054308] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69668328 0.82739429 0.90054308] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.28947368 0.51807844 0.69668328 0.82739429 0.90054308] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.28947368 0.51807844 0.62148124 0.82739429 0.90054308] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.28947368 0.56161646 0.62148124 0.82739429 0.90054308] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.40406012 0.56161646 0.62148124 0.82739429 0.90054308] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40406012 0.49527695 0.62148124 0.82739429 0.90054308] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.40406012 0.49527695 0.56834259 0.82739429 0.90054308] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.40406012 0.45686986 0.56834259 0.82739429 0.90054308] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23392954 0.45686986 0.56834259 0.82739429 0.90054308] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.23392954 0.2645036  0.56834259 0.82739429 0.90054308] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13543289 0.2645036  0.56834259 0.82739429 0.90054308] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.13543289 0.2645036  0.56834259 0.82739429 0.90054308] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.13543289 0.2645036  0.56834259 0.82739429 0.90054308] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13543289 0.2645036  0.75009308 0.82739429 0.90054308] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13543289 0.2645036  0.75009308 0.90007038 0.90054308] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13543289 0.2645036  0.75009308 0.90007038 0.94241968] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13543289 0.2645036  0.75009308 0.90007038 0.94241968] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.13543289 0.2645036  0.75009308 0.90007038 0.94241968] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.13543289 0.2645036  0.81324142 0.90007038 0.94241968] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.13543289 0.54994195 0.81324142 0.90007038 0.94241968] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13543289 0.54994195 0.89187661 0.90007038 0.94241968] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13543289 0.54994195 0.89187661 0.94214601 0.94241968] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.13543289 0.54994195 0.89187661 0.94214601 0.96666402] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.13543289 0.54994195 0.89187661 0.94214601 0.96666402] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.13543289 0.54994195 0.89187661 0.94214601 0.96666402] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13543289 0.54994195 0.51634962 0.94214601 0.96666402] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.13543289 0.31838745 0.51634962 0.94214601 0.96666402] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.07840852 0.31838745 0.51634962 0.94214601 0.96666402] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07840852 0.31838745 0.51634962 0.94214601 0.96666402] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.07840852 0.31838745 0.51634962 0.94214601 0.96666402] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07840852 0.31838745 0.43299712 0.94214601 0.96666402] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.07840852 0.36664415 0.43299712 0.94214601 0.96666402] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07840852 0.36664415 0.40505903 0.94214601 0.96666402] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.07840852 0.38281884 0.40505903 0.94214601 0.96666402] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.07840852 0.38281884 0.63120092 0.94214601 0.96666402] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.07840852 0.62864839 0.63120092 0.94214601 0.96666402] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.07840852 0.62864839 0.76212517 0.94214601 0.96666402] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.07840852 0.62864839 0.76212517 0.86634776 0.96666402] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.07840852 0.62864839 0.76212517 0.86634776 0.9244256 ] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.07840852 0.62864839 0.76212517 0.89080159 0.9244256 ] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.07840852 0.62864839 0.86228299 0.89080159 0.9244256 ] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.07840852 0.62864839 0.86228299 0.93677987 0.9244256 ] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.07840852 0.62864839 0.86228299 0.93677987 0.9562464 ] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.07840852 0.62864839 0.86228299 0.93677987 0.9562464 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07840852 0.62864839 0.86228299 0.93677987 0.9562464 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.07840852 0.62864839 0.76391053 0.93677987 0.9562464 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07840852 0.39696844 0.76391053 0.93677987 0.9562464 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0453944  0.39696844 0.76391053 0.93677987 0.9562464 ] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0453944  0.22982384 0.76391053 0.93677987 0.9562464 ] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02628097 0.22982384 0.76391053 0.93677987 0.9562464 ] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.02628097 0.22982384 0.76391053 0.93677987 0.9562464 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.02628097 0.22982384 0.76391053 0.93677987 0.9562464 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.02628097 0.22982384 0.53903192 0.93677987 0.9562464 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.02628097 0.22982384 0.53903192 0.55341191 0.9562464 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.02628097 0.22982384 0.40883904 0.55341191 0.9562464 ] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.02628097 0.14412158 0.40883904 0.55341191 0.9562464 ] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.07589807 0.14412158 0.40883904 0.55341191 0.9562464 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.07589807 0.11539589 0.40883904 0.55341191 0.9562464 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.09252873 0.11539589 0.40883904 0.55341191 0.9562464 ] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.09252873 0.10576761 0.40883904 0.55341191 0.9562464 ] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05356926 0.10576761 0.40883904 0.55341191 0.9562464 ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05356926 0.06123388 0.40883904 0.55341191 0.9562464 ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03101378 0.06123388 0.40883904 0.55341191 0.9562464 ] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.42105263157894735\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.27631579 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.27631579 0.27631579 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.27631579 0.27631579 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.27631579 0.37638504 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.37638504 0.37638504 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.37638504 0.65537068 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.37638504 0.65537068 0.72368421 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.37638504 0.65537068 0.72368421 0.72368421] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.37638504 0.65537068 0.72368421 0.72368421] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.37638504 0.65537068 0.72368421 0.72368421] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.37638504 0.685932   0.72368421 0.72368421] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.685932   0.72368421 0.72368421] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70282115 0.72368421 0.72368421] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70282115 0.71435073 0.72368421] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70282115 0.71435073 0.71950871] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70282115 0.71665825 0.71950871] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70901143 0.71665825 0.71950871] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70901143 0.7132373  0.71950871] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70901143 0.7132373  0.71670308] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.70901143 0.71478778 0.71670308] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.27631579 0.53175572 0.71159559 0.71478778 0.71670308] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.27631579 0.53175572 0.71159559 0.71564463 0.71670308] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.53175572 0.71159559 0.71564463 0.84344118] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.53175572 0.71159559 0.84285624 0.84344118] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.27631579 0.53175572 0.71159559 0.84285624 0.91348065] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.53175572 0.71159559 0.84285624 0.91348065] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.27631579 0.53175572 0.71159559 0.84285624 0.91348065] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.27631579 0.53175572 0.63114091 0.84285624 0.91348065] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.27631579 0.57621752 0.63114091 0.84285624 0.91348065] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.41048235 0.57621752 0.63114091 0.84285624 0.91348065] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41048235 0.50207284 0.63114091 0.84285624 0.91348065] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41048235 0.50207284 0.57339993 0.84285624 0.91348065] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41048235 0.46109815 0.57339993 0.84285624 0.91348065] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22684551 0.46109815 0.57339993 0.84285624 0.91348065] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22684551 0.2548174  0.57339993 0.84285624 0.91348065] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12536199 0.2548174  0.57339993 0.84285624 0.91348065] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12536199 0.2548174  0.57339993 0.84285624 0.91348065] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12536199 0.2548174  0.57339993 0.84285624 0.91348065] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12536199 0.2548174  0.76424733 0.84285624 0.91348065] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12536199 0.2548174  0.76424733 0.9131574  0.91348065] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12536199 0.2548174  0.76424733 0.9131574  0.95218667] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12536199 0.2548174  0.76424733 0.9131574  0.95218667] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.12536199 0.2548174  0.76424733 0.9131574  0.95218667] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.12536199 0.2548174  0.83086499 0.9131574  0.95218667] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.12536199 0.56679839 0.83086499 0.9131574  0.95218667] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12536199 0.56679839 0.90653065 0.9131574  0.95218667] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12536199 0.56679839 0.90653065 0.95200803 0.95218667] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.12536199 0.56679839 0.90653065 0.95200803 0.97357685] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.12536199 0.56679839 0.90653065 0.95200803 0.97357685] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.12536199 0.56679839 0.90653065 0.95200803 0.97357685] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12536199 0.56679839 0.50097747 0.95200803 0.97357685] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.12536199 0.31323069 0.50097747 0.95200803 0.97357685] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.069279   0.31323069 0.50097747 0.95200803 0.97357685] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.069279   0.31323069 0.50097747 0.95200803 0.97357685] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.069279   0.31323069 0.50097747 0.95200803 0.97357685] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.069279   0.31323069 0.41698549 0.95200803 0.97357685] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.069279   0.35964731 0.41698549 0.95200803 0.97357685] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.069279   0.35964731 0.3913342  0.95200803 0.97357685] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.069279   0.37382302 0.3913342  0.95200803 0.97357685] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.069279   0.37382302 0.64216197 0.95200803 0.97357685] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.069279   0.64213394 0.64216197 0.95200803 0.97357685] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.069279   0.64213394 0.78077731 0.95200803 0.97357685] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.069279   0.64213394 0.78077731 0.87540482 0.97357685] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.069279   0.64213394 0.78077731 0.87540482 0.92965778] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.069279   0.64213394 0.78077731 0.89967588 0.92965778] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.069279   0.64213394 0.87885062 0.89967588 0.92965778] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.069279   0.64213394 0.87885062 0.94455772 0.92965778] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.069279   0.64213394 0.87885062 0.94455772 0.96112667] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.069279   0.64213394 0.87885062 0.94455772 0.96112667] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.069279   0.64213394 0.87885062 0.94455772 0.96112667] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.069279   0.64213394 0.77295105 0.94455772 0.96112667] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.069279   0.38585673 0.77295105 0.94455772 0.96112667] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03828576 0.38585673 0.77295105 0.94455772 0.96112667] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03828576 0.21323661 0.77295105 0.94455772 0.96112667] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02115792 0.21323661 0.77295105 0.94455772 0.96112667] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.02115792 0.21323661 0.77295105 0.94455772 0.96112667] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.02115792 0.21323661 0.77295105 0.94455772 0.96112667] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.02115792 0.21323661 0.52255249 0.94455772 0.96112667] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.02115792 0.21323661 0.52255249 0.53145781 0.96112667] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.02115792 0.21323661 0.38417433 0.53145781 0.96112667] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.02115792 0.12730667 0.38417433 0.53145781 0.96112667] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.06864552 0.12730667 0.38417433 0.53145781 0.96112667] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06864552 0.10106353 0.38417433 0.53145781 0.96112667] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.08314831 0.10106353 0.38417433 0.53145781 0.96112667] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.08314831 0.09304882 0.38417433 0.53145781 0.96112667] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04595038 0.09304882 0.38417433 0.53145781 0.96112667] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.04595038 0.05142172 0.38417433 0.53145781 0.96112667] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02539363 0.05142172 0.38417433 0.53145781 0.96112667] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.4473684210526315\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.5        0.26315789 0.5        0.5       ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5        0.26315789 0.26315789 0.5        0.5       ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.26315789 0.26315789 0.5        0.5       ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.26315789 0.37534626 0.5        0.5       ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.37534626 0.37534626 0.5        0.5       ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.37534626 0.67123487 0.5        0.5       ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.37534626 0.67123487 0.73684211 0.5       ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.37534626 0.67123487 0.73684211 0.73684211] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.37534626 0.67123487 0.73684211 0.73684211] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.37534626 0.67123487 0.73684211 0.73684211] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.37534626 0.70231198 0.73684211 0.73684211] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.70231198 0.73684211 0.73684211] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.71866836 0.73684211 0.73684211] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.54658113 0.71866836 0.72823349 0.73684211] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.71866836 0.72823349 0.73276434] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.71866836 0.73037968 0.73276434] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72421583 0.73037968 0.73276434] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72421583 0.72745996 0.73276434] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72421583 0.72745996 0.73025174] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72421583 0.72878238 0.73025174] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72637893 0.72878238 0.73025174] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72637893 0.72947839 0.73025174] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.54658113 0.72637893 0.72947839 0.85802723] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.54658113 0.72637893 0.85762021 0.85802723] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.26315789 0.54658113 0.72637893 0.85762021 0.92527749] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72637893 0.85762021 0.92527749] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.26315789 0.54658113 0.72637893 0.85762021 0.92527749] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.26315789 0.54658113 0.64121155 0.85762021 0.92527749] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.26315789 0.59140607 0.64121155 0.85762021 0.92527749] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.41864387 0.59140607 0.64121155 0.85762021 0.92527749] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41864387 0.50957134 0.64121155 0.85762021 0.92527749] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.41864387 0.50957134 0.57885567 0.85762021 0.92527749] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.41864387 0.46650044 0.57885567 0.85762021 0.92527749] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22033888 0.46650044 0.57885567 0.85762021 0.92527749] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.22033888 0.24552655 0.57885567 0.85762021 0.92527749] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11596783 0.24552655 0.57885567 0.85762021 0.92527749] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11596783 0.24552655 0.57885567 0.85762021 0.92527749] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11596783 0.24552655 0.57885567 0.85762021 0.92527749] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11596783 0.24552655 0.77834509 0.85762021 0.92527749] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11596783 0.24552655 0.77834509 0.92506327 0.92527749] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11596783 0.24552655 0.77834509 0.92506327 0.96067236] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11596783 0.24552655 0.77834509 0.92506327 0.96067236] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.11596783 0.24552655 0.77834509 0.92506327 0.96067236] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.11596783 0.24552655 0.84784317 0.92506327 0.96067236] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.11596783 0.58427983 0.84784317 0.92506327 0.96067236] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11596783 0.58427983 0.91991746 0.92506327 0.96067236] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11596783 0.58427983 0.91991746 0.96055961 0.96067236] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.11596783 0.58427983 0.91991746 0.96055961 0.97930124] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.11596783 0.58427983 0.91991746 0.96055961 0.97930124] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.11596783 0.58427983 0.91991746 0.96055961 0.97930124] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11596783 0.58427983 0.48416708 0.96055961 0.97930124] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.11596783 0.3075157  0.48416708 0.96055961 0.97930124] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0610357  0.3075157  0.48416708 0.96055961 0.97930124] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0610357  0.3075157  0.48416708 0.96055961 0.97930124] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.0610357  0.3075157  0.48416708 0.96055961 0.97930124] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0610357  0.3075157  0.40049011 0.96055961 0.97930124] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.0610357  0.35155621 0.40049011 0.96055961 0.97930124] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0610357  0.35155621 0.3773109  0.96055961 0.97930124] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.0610357  0.3637558  0.3773109  0.96055961 0.97930124] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.0610357  0.3637558  0.6535866  0.96055961 0.97930124] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.0610357  0.65532996 0.6535866  0.96055961 0.97930124] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.0610357  0.65532996 0.79899487 0.96055961 0.97930124] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.0610357  0.65532996 0.79899487 0.88402895 0.97930124] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.0610357  0.65532996 0.79899487 0.88402895 0.93417226] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.0610357  0.65532996 0.79899487 0.90778104 0.93417226] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.0610357  0.65532996 0.89420783 0.90778104 0.93417226] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.0610357  0.65532996 0.89420783 0.95146371 0.93417226] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.0610357  0.65532996 0.89420783 0.95146371 0.96535382] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0610357  0.65532996 0.89420783 0.95146371 0.96535382] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0610357  0.65532996 0.89420783 0.95146371 0.96535382] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.0610357  0.65532996 0.78105515 0.95146371 0.96535382] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0610357  0.37382215 0.78105515 0.95146371 0.96535382] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03212405 0.37382215 0.78105515 0.95146371 0.96535382] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03212405 0.1967485  0.78105515 0.95146371 0.96535382] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.0169074  0.1967485  0.78105515 0.95146371 0.96535382] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.0169074  0.1967485  0.78105515 0.95146371 0.96535382] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.0169074  0.1967485  0.78105515 0.95146371 0.96535382] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.0169074  0.1967485  0.50427832 0.95146371 0.96535382] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0169074  0.1967485  0.50427832 0.50877914 0.96535382] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.0169074  0.1967485  0.3586063  0.50877914 0.96535382] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.0169074  0.11156061 0.3586063  0.50877914 0.96535382] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.06174313 0.11156061 0.3586063  0.50877914 0.96535382] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06174313 0.08796286 0.3586063  0.50877914 0.96535382] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.074163   0.08796286 0.3586063  0.50877914 0.96535382] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.074163   0.08142608 0.3586063  0.50877914 0.96535382] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03903316 0.08142608 0.3586063  0.50877914 0.96535382] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03903316 0.04285583 0.3586063  0.50877914 0.96535382] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02054377 0.04285583 0.3586063  0.50877914 0.96535382] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.47368421052631576\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n",
      "---------------------------\n",
      "Episode 1\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.5 0.5 0.5 0.5 0.5] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5  0.5  0.25 0.5  0.5 ] | Step: 6 | T: 7 | time: 4\n",
      "Step: 7 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.5  0.25 0.25 0.5  0.5 ] | Step: 7 | T: 7 | time: 5\n",
      "Step: 8 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 8 | T: 7 | time: 6\n",
      "Episode: 1 Finished | Average Steps: 9.0\n",
      "---------------------------\n",
      "Episode 2\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 5 | T: inf | time: 3\n",
      "Action: 1\n",
      "Step: 6 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25 0.25 0.25 0.5  0.5 ] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25  0.25  0.375 0.5   0.5  ] | Step: 8 | T: inf | time: 6\n",
      "Action: 0\n",
      "Step: 9 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25  0.375 0.375 0.5   0.5  ] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25   0.375  0.6875 0.5    0.5   ] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25   0.375  0.6875 0.75   0.5   ] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25   0.375  0.6875 0.75   0.75  ] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 2 Finished | Average Steps: 13.0\n",
      "---------------------------\n",
      "Episode 3\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25   0.375  0.6875 0.75   0.75  ] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25   0.375  0.6875 0.75   0.75  ] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25    0.375   0.71875 0.75    0.75   ] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25    0.5625  0.71875 0.75    0.75   ] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25     0.5625   0.734375 0.75     0.75    ] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25      0.5625    0.734375  0.7421875 0.75     ] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25       0.5625     0.734375   0.7421875  0.74609375] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25       0.5625     0.734375   0.74414062 0.74609375] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25       0.5625     0.73925781 0.74414062 0.74609375] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.25       0.5625     0.73925781 0.74169922 0.74609375] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.25       0.5625     0.73925781 0.74169922 0.74389648] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25       0.5625     0.73925781 0.74279785 0.74389648] | Step: 11 | T: inf | time: 9\n",
      "Action: 1\n",
      "Step: 12 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.25       0.5625     0.74102783 0.74279785 0.74389648] | Step: 12 | T: inf | time: 10\n",
      "Action: 0\n",
      "Step: 13 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.25       0.5625     0.74102783 0.74334717 0.74389648] | Step: 13 | T: inf | time: 11\n",
      "Action: 0\n",
      "Step: 14 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25       0.5625     0.74102783 0.74334717 0.87194824] | Step: 14 | T: 15 | time: 12\n",
      "Step: 15 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25       0.5625     0.74102783 0.87167358 0.87194824] | Step: 15 | T: 15 | time: 13\n",
      "Step: 16 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.25       0.5625     0.74102783 0.87167358 0.93597412] | Step: 16 | T: 15 | time: 14\n",
      "Episode: 3 Finished | Average Steps: 17.0\n",
      "---------------------------\n",
      "Episode 4\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.25       0.5625     0.74102783 0.87167358 0.93597412] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.25       0.5625     0.74102783 0.87167358 0.93597412] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.25       0.5625     0.65176392 0.87167358 0.93597412] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.25       0.60713196 0.65176392 0.87167358 0.93597412] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.42856598 0.60713196 0.65176392 0.87167358 0.93597412] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42856598 0.51784897 0.65176392 0.87167358 0.93597412] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.42856598 0.51784897 0.58480644 0.87167358 0.93597412] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.42856598 0.47320747 0.58480644 0.87167358 0.93597412] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21428299 0.47320747 0.58480644 0.87167358 0.93597412] | Step: 8 | T: 9 | time: 6\n",
      "Step: 9 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.21428299 0.23660374 0.58480644 0.87167358 0.93597412] | Step: 9 | T: 9 | time: 7\n",
      "Step: 10 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10714149 0.23660374 0.58480644 0.87167358 0.93597412] | Step: 10 | T: 9 | time: 8\n",
      "Episode: 4 Finished | Average Steps: 11.0\n",
      "---------------------------\n",
      "Episode 5\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.10714149 0.23660374 0.58480644 0.87167358 0.93597412] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.10714149 0.23660374 0.58480644 0.87167358 0.93597412] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.10714149 0.23660374 0.79240322 0.87167358 0.93597412] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.10714149 0.23660374 0.79240322 0.93583679 0.93597412] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.10714149 0.23660374 0.79240322 0.93583679 0.96798706] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 5 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 6\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.10714149 0.23660374 0.79240322 0.93583679 0.96798706] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.10714149 0.23660374 0.79240322 0.93583679 0.96798706] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.10714149 0.23660374 0.86412001 0.93583679 0.96798706] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.10714149 0.6022954  0.86412001 0.93583679 0.96798706] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.10714149 0.6022954  0.93206    0.93583679 0.96798706] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.10714149 0.6022954  0.93206    0.9679184  0.96798706] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.10714149 0.6022954  0.93206    0.9679184  0.98399353] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 6 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 7\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.10714149 0.6022954  0.93206    0.9679184  0.98399353] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.10714149 0.6022954  0.93206    0.9679184  0.98399353] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10714149 0.6022954  0.46603    0.9679184  0.98399353] | Step: 2 | T: 3 | time: 0\n",
      "Step: 3 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.10714149 0.3011477  0.46603    0.9679184  0.98399353] | Step: 3 | T: 3 | time: 1\n",
      "Step: 4 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.05357075 0.3011477  0.46603    0.9679184  0.98399353] | Step: 4 | T: 3 | time: 2\n",
      "Episode: 7 Finished | Average Steps: 5.0\n",
      "---------------------------\n",
      "Episode 8\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.05357075 0.3011477  0.46603    0.9679184  0.98399353] | Step: 0 | T: inf | time: -2\n",
      "Action: 0\n",
      "Step: 1 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.05357075 0.3011477  0.46603    0.9679184  0.98399353] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.05357075 0.3011477  0.38358885 0.9679184  0.98399353] | Step: 2 | T: inf | time: 0\n",
      "Action: 0\n",
      "Step: 3 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.05357075 0.34236827 0.38358885 0.9679184  0.98399353] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.05357075 0.34236827 0.36297856 0.9679184  0.98399353] | Step: 4 | T: inf | time: 2\n",
      "Action: 0\n",
      "Step: 5 | State: [0 2] | Action: 0 | Next State: [0 3] | Reward: 0 | State Values: [0.05357075 0.35267342 0.36297856 0.9679184  0.98399353] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.05357075 0.35267342 0.66544848 0.9679184  0.98399353] | Step: 6 | T: inf | time: 4\n",
      "Action: 0\n",
      "Step: 7 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.05357075 0.66833347 0.66544848 0.9679184  0.98399353] | Step: 7 | T: inf | time: 5\n",
      "Action: 1\n",
      "Step: 8 | State: [0 5] | Action: 1 | Next State: [0 4] | Reward: 0 | State Values: [0.05357075 0.66833347 0.81668344 0.9679184  0.98399353] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.05357075 0.66833347 0.81668344 0.89230092 0.98399353] | Step: 9 | T: inf | time: 7\n",
      "Action: 0\n",
      "Step: 10 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.05357075 0.66833347 0.81668344 0.89230092 0.93814722] | Step: 10 | T: inf | time: 8\n",
      "Action: 0\n",
      "Step: 11 | State: [0 4] | Action: 0 | Next State: [0 5] | Reward: 0 | State Values: [0.05357075 0.66833347 0.81668344 0.91522407 0.93814722] | Step: 11 | T: inf | time: 9\n",
      "Action: 0\n",
      "Step: 12 | State: [0 5] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.05357075 0.66833347 0.90834172 0.91522407 0.93814722] | Step: 12 | T: 13 | time: 10\n",
      "Step: 13 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.05357075 0.66833347 0.90834172 0.95761204 0.93814722] | Step: 13 | T: 13 | time: 11\n",
      "Step: 14 | State: [0 6] | Action: 0 | Next State: [0 6] | Reward: 1 | State Values: [0.05357075 0.66833347 0.90834172 0.95761204 0.96907361] | Step: 14 | T: 13 | time: 12\n",
      "Episode: 8 Finished | Average Steps: 15.0\n",
      "---------------------------\n",
      "Episode 9\n",
      "Action: 1\n",
      "Step: 0 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.05357075 0.66833347 0.90834172 0.95761204 0.96907361] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05357075 0.66833347 0.90834172 0.95761204 0.96907361] | Step: 1 | T: inf | time: -1\n",
      "Action: 0\n",
      "Step: 2 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.05357075 0.66833347 0.7883376  0.95761204 0.96907361] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05357075 0.36095211 0.7883376  0.95761204 0.96907361] | Step: 3 | T: inf | time: 1\n",
      "Action: 1\n",
      "Step: 4 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02678537 0.36095211 0.7883376  0.95761204 0.96907361] | Step: 4 | T: 5 | time: 2\n",
      "Step: 5 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.02678537 0.18047606 0.7883376  0.95761204 0.96907361] | Step: 5 | T: 5 | time: 3\n",
      "Step: 6 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.01339269 0.18047606 0.7883376  0.95761204 0.96907361] | Step: 6 | T: 5 | time: 4\n",
      "Episode: 9 Finished | Average Steps: 7.0\n",
      "---------------------------\n",
      "Episode 10\n",
      "Action: 0\n",
      "Step: 0 | State: [0 3] | Action: 0 | Next State: [0 4] | Reward: 0 | State Values: [0.01339269 0.18047606 0.7883376  0.95761204 0.96907361] | Step: 0 | T: inf | time: -2\n",
      "Action: 1\n",
      "Step: 1 | State: [0 4] | Action: 1 | Next State: [0 3] | Reward: 0 | State Values: [0.01339269 0.18047606 0.7883376  0.95761204 0.96907361] | Step: 1 | T: inf | time: -1\n",
      "Action: 1\n",
      "Step: 2 | State: [0 3] | Action: 1 | Next State: [0 2] | Reward: 0 | State Values: [0.01339269 0.18047606 0.48440683 0.95761204 0.96907361] | Step: 2 | T: inf | time: 0\n",
      "Action: 1\n",
      "Step: 3 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.01339269 0.18047606 0.48440683 0.48550236 0.96907361] | Step: 3 | T: inf | time: 1\n",
      "Action: 0\n",
      "Step: 4 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.01339269 0.18047606 0.33244144 0.48550236 0.96907361] | Step: 4 | T: inf | time: 2\n",
      "Action: 1\n",
      "Step: 5 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.01339269 0.09693437 0.33244144 0.48550236 0.96907361] | Step: 5 | T: inf | time: 3\n",
      "Action: 0\n",
      "Step: 6 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.05516353 0.09693437 0.33244144 0.48550236 0.96907361] | Step: 6 | T: inf | time: 4\n",
      "Action: 1\n",
      "Step: 7 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.05516353 0.07604895 0.33244144 0.48550236 0.96907361] | Step: 7 | T: inf | time: 5\n",
      "Action: 0\n",
      "Step: 8 | State: [0 1] | Action: 0 | Next State: [0 2] | Reward: 0 | State Values: [0.06560624 0.07604895 0.33244144 0.48550236 0.96907361] | Step: 8 | T: inf | time: 6\n",
      "Action: 1\n",
      "Step: 9 | State: [0 2] | Action: 1 | Next State: [0 1] | Reward: 0 | State Values: [0.06560624 0.07082759 0.33244144 0.48550236 0.96907361] | Step: 9 | T: inf | time: 7\n",
      "Action: 1\n",
      "Step: 10 | State: [0 1] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03280312 0.07082759 0.33244144 0.48550236 0.96907361] | Step: 10 | T: 11 | time: 8\n",
      "Step: 11 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.03280312 0.0354138  0.33244144 0.48550236 0.96907361] | Step: 11 | T: 11 | time: 9\n",
      "Step: 12 | State: [0 0] | Action: 1 | Next State: [0 0] | Reward: 0 | State Values: [0.01640156 0.0354138  0.33244144 0.48550236 0.96907361] | Step: 12 | T: 11 | time: 10\n",
      "Episode: 10 Finished | Average Steps: 13.0\n",
      "alpha: 0.5\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 102\n",
      "Total Average of Steps Per Episode: 10.2\n",
      "Episode: 1 Finished | Average Steps: 7.0\n",
      "Episode: 2 Finished | Average Steps: 11.0\n",
      "Episode: 3 Finished | Average Steps: 15.0\n",
      "Episode: 4 Finished | Average Steps: 9.0\n",
      "Episode: 5 Finished | Average Steps: 3.0\n",
      "Episode: 6 Finished | Average Steps: 5.0\n",
      "Episode: 7 Finished | Average Steps: 3.0\n",
      "Episode: 8 Finished | Average Steps: 13.0\n",
      "Episode: 9 Finished | Average Steps: 5.0\n",
      "Episode: 10 Finished | Average Steps: 11.0\n",
      "Total number of episodes: 10\n",
      "Total number of steps: 82\n",
      "Total Average of Steps Per Episode: 8.2\n"
     ]
    }
   ],
   "source": [
    "ns = [1, 2, 3]\n",
    "alphas = np.linspace(0, 0.5, num=20)\n",
    "rms10int0 = np.zeros([len(ns), len(alphas)])\n",
    "rms10int1 = np.zeros([len(ns), len(alphas)])\n",
    "\n",
    "for i, n in enumerate(ns):\n",
    "    for j, alpha in enumerate(alphas):\n",
    "\n",
    "        env.seed(7)\n",
    "        state_values = agent.initialize_state_values((env.observation_space[0],env.observation_space[1]))\n",
    "        history0 = agent.n_step_td_estimating(env, state_values, episodes=10, n=n, alpha=alpha, debug=True)\n",
    "\n",
    "        rmsint0 = np.sqrt((history0 - v_star) ** 2).mean()\n",
    "        rms10int0[i, j] = rmsint0\n",
    "        \n",
    "        env.seed(7)\n",
    "        state_values = agent.initialize_state_values((env.observation_space[0],env.observation_space[1]))\n",
    "        history1 = agent.sum_td_errors_estimating(env, state_values, episodes=10, n=n, alpha=alpha, debug=False)\n",
    "\n",
    "        rmsint1 = np.sqrt((history1 - v_star) ** 2).mean()\n",
    "        rms10int1[i, j] = rmsint1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "21d07ddd-ff98-4b99-8714-5ded2ab2f4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matplotlib.rcParams['figure.figsize'] = [10, 10]\n",
    "\n",
    "plt.figure()\n",
    "plt.title(f\"RMS Mean\")\n",
    "plt.xlabel(r\"$\\alpha$\"); plt.ylim([0, 0.55])\n",
    "plt.ylabel(\"RMS Mean Error Over First 10 Episodes\")\n",
    "for i, n in enumerate(ns):\n",
    "    plt.plot(alphas, rms10int0[i, :], 'o-', label=f'Online (n={n})')\n",
    "for i, n in enumerate(ns):\n",
    "    plt.plot(alphas, rms10int1[i, :], 'x-', label=f'TD Error Sum (n={n})')\n",
    "plt.legend(loc=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ca136b-640a-4c75-99f5-5a55d41e1671",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2042b305-deed-4180-867b-bc97cb8c1301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "toc-showcode": true,
  "toc-showmarkdowntxt": true,
  "toc-showtags": true
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
